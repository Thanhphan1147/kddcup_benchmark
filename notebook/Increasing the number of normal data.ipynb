{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning Isolation Forest on specific dataset sizes\n",
    "* Dataset       : KDDCUP99 100%\n",
    "* Subset        : SA\n",
    "* Total size    :  \n",
    "* Features      : 41\n",
    "* Key attribute : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
      "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
      "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
      "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
      "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
      "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
      "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
      "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
      "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
      "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
      "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
      "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
      "       'dst_host_srv_rerror_rate', 'target'],\n",
      "      dtype='object')\n",
      "[[0 'tcp' 'http' 'SF' 162 4528 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 2 2 0.0\n",
      "  0.0 0.0 0.0 1.0 0.0 0.0 1 1 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 'normal.']]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('kddcup.data', delimiter=',')\n",
    "df.columns = sa_columns + [\"target\"]\n",
    "print(f\"{df.columns}\")\n",
    "print(np.array(df.head(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc',\n",
    "           'Precision': make_scorer(precision_score, pos_label=1), \n",
    "           'Recall': make_scorer(recall_score, pos_label=-1),\n",
    "           'F1': make_scorer(f1_score, average='weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3377\n"
     ]
    }
   ],
   "source": [
    "dfsf = df[df[\"logged_in\"]== 1]\n",
    "print(len(dfsf)- len(dfsf.loc[dfsf[\"target\"]=='normal.']))\n",
    "dfsf = dfsf[sf_columns + [\"target\"]] \n",
    "# print(dfsf.head(1))\n",
    "# Split the dataset into 2 classes for consistent anomaly_rate when sampling\n",
    "dfsf_normal = dfsf.loc[dfsf[\"target\"]=='normal.']\n",
    "dfsf_attack = dfsf.loc[dfsf[\"target\"]!='normal.']\n",
    "# print(f\"A sample normal frame: \\t {dfsf_normal.head(1)}\")\n",
    "# print(\"-----------------\")\n",
    "# print(f\"A sample attack frame: \\t {dfsf_attack.head(1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(contamination, max_samples, n_estimators, random_state, silent=True):\n",
    "    highest_score = 0\n",
    "    highest_score_c = 0\n",
    "    for c in contamination:\n",
    "        s = datetime.datetime.now()\n",
    "        y_pred = IsolationForest(random_state= random_state, n_jobs=-1, max_samples = max_samples, n_estimators = n_estimators, contamination=c).fit(x_train).predict(x_test)\n",
    "        t = datetime.datetime.now() - s\n",
    "        p, r, f, s = map(lambda x: x[0], precision_recall_fscore_support(y_test, y_pred, labels=[-1]))\n",
    "        # p = tp / (tp + fp)\n",
    "        f = f1_score(y_test, y_pred, average = \"macro\")\n",
    "        r = recall_score(y_test, y_pred, pos_label = -1)\n",
    "        a = roc_auc_score(y_test, y_pred)\n",
    "        if a > highest_score: highest_score = a; highest_score_c = c\n",
    "        \n",
    "        yp = np.array(y_pred)\n",
    "        yt = np.array(y_test)\n",
    "        \n",
    "        prediction = yp[np.where(yt == -1)]\n",
    "\n",
    "        tp = len(yp[np.where(prediction == -1)])\n",
    "        \n",
    "        fp = tp / p - tp\n",
    "        # predicted true\n",
    "        positives = yp[np.where(yp == -1)]\n",
    "        if not silent:\n",
    "            print(f\"Finished trainning in {t} seconds\")\n",
    "            print(f\"contamination: {c} \\t tp: {tp}/support: {s}/predicted: {len(positives)} -> fp = {len(positives) - tp}\")\n",
    "            print(f\"AUC : {a:.1%} \\t precision: {p:.3} \\t recall: {r:.3} \\t f1: {f}\")\n",
    "            print(\"--------------------\")\n",
    "    return (highest_score_c, y_pred, f, len(positives) - tp, tp, p, r, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_auc = []\n",
    "stat_f1 = []\n",
    "stat_r = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration 1\n",
    "* frac_oulier = 0.1\n",
    "* frac_normal = 0.1\n",
    "* r = 0.01\n",
    "* random_state = 1\n",
    "* IF random_state = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 0.5% out of 70307 records\n",
      "Finished trainning in 0:00:02.892635 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 78/support: 97/predicted: 791 -> fp = 713\n",
      "AUC : 88.2% \t precision: 0.0986 \t recall: 0.804 \t f1: 0.5771566961813854\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.069755 seconds\n",
      "contamination: 0.065 \t tp: 78/support: 97/predicted: 1104 -> fp = 1026\n",
      "AUC : 87.3% \t precision: 0.0707 \t recall: 0.804 \t f1: 0.5495569584570217\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.648308 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 79/support: 97/predicted: 1419 -> fp = 1340\n",
      "AUC : 86.9% \t precision: 0.0557 \t recall: 0.814 \t f1: 0.5319253134529817\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.135841 seconds\n",
      "contamination: 0.105 \t tp: 97/support: 97/predicted: 1733 -> fp = 1636\n",
      "AUC : 95.3% \t precision: 0.056 \t recall: 1.0 \t f1: 0.5284585913563995\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.086275 seconds\n",
      "contamination: 0.125 \t tp: 97/support: 97/predicted: 2102 -> fp = 2005\n",
      "AUC : 94.3% \t precision: 0.0461 \t recall: 1.0 \t f1: 0.5136906894618173\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.270874 seconds\n",
      "contamination: 0.145 \t tp: 97/support: 97/predicted: 2441 -> fp = 2344\n",
      "AUC : 93.3% \t precision: 0.0397 \t recall: 1.0 \t f1: 0.5022857858563086\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.017564 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 97/support: 97/predicted: 2823 -> fp = 2726\n",
      "AUC : 92.2% \t precision: 0.0344 \t recall: 1.0 \t f1: 0.49093463381216634\n",
      "--------------------\n",
      "Finished trainning in 0:00:02.928843 seconds\n",
      "contamination: 0.185 \t tp: 97/support: 97/predicted: 3149 -> fp = 3052\n",
      "AUC : 91.3% \t precision: 0.0308 \t recall: 1.0 \t f1: 0.48205793597442925\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.541767 seconds\n",
      "contamination: 0.205 \t tp: 97/support: 97/predicted: 3521 -> fp = 3424\n",
      "AUC : 90.2% \t precision: 0.0275 \t recall: 1.0 \t f1: 0.4725232286058293\n",
      "--------------------\n",
      "Finished trainning in 0:00:02.983961 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 97/support: 97/predicted: 3853 -> fp = 3756\n",
      "AUC : 89.3% \t precision: 0.0252 \t recall: 1.0 \t f1: 0.46437237030630607\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.539960 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 97/support: 97/predicted: 4167 -> fp = 4070\n",
      "AUC : 88.4% \t precision: 0.0233 \t recall: 1.0 \t f1: 0.4568696676520268\n",
      "--------------------\n",
      "Finished trainning in 0:00:02.923145 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 97/support: 97/predicted: 4538 -> fp = 4441\n",
      "AUC : 87.3% \t precision: 0.0214 \t recall: 1.0 \t f1: 0.44816976977894085\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.101007 seconds\n",
      "contamination: 0.285 \t tp: 97/support: 97/predicted: 4921 -> fp = 4824\n",
      "AUC : 86.2% \t precision: 0.0197 \t recall: 1.0 \t f1: 0.4392932456694525\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.217382 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 97/support: 97/predicted: 5258 -> fp = 5161\n",
      "AUC : 85.2% \t precision: 0.0184 \t recall: 1.0 \t f1: 0.4315170465649262\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.255763 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 97/support: 97/predicted: 5580 -> fp = 5483\n",
      "AUC : 84.3% \t precision: 0.0174 \t recall: 1.0 \t f1: 0.42408177380203255\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.158993 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 97/support: 97/predicted: 5928 -> fp = 5831\n",
      "AUC : 83.3% \t precision: 0.0164 \t recall: 1.0 \t f1: 0.41601032693460155\n",
      "--------------------\n",
      "Finished trainning in 0:00:02.991705 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 97/support: 97/predicted: 6327 -> fp = 6230\n",
      "AUC : 82.2% \t precision: 0.0153 \t recall: 1.0 \t f1: 0.40667637544380864\n",
      "--------------------\n",
      "Finished trainning in 0:00:02.860531 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 97/support: 97/predicted: 6680 -> fp = 6583\n",
      "AUC : 81.2% \t precision: 0.0145 \t recall: 1.0 \t f1: 0.39832129353397283\n",
      "--------------------\n",
      "Time for IF fitting: 57.094\n",
      "1 0.105 0.25 100\n",
      "Finished trainning in 0:00:05.842625 seconds\n",
      "contamination: 0.04 \t tp: 70/support: 86/predicted: 703 -> fp = 633\n",
      "AUC : 88.9% \t precision: 0.0996 \t recall: 0.814 \t f1: 0.5792771516248902\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.700042 seconds\n",
      "contamination: 0.06 \t tp: 70/support: 86/predicted: 1036 -> fp = 966\n",
      "AUC : 87.9% \t precision: 0.0676 \t recall: 0.814 \t f1: 0.5479609942451145\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.440413 seconds\n",
      "contamination: 0.07999999999999999 \t tp: 70/support: 86/predicted: 1384 -> fp = 1314\n",
      "AUC : 86.9% \t precision: 0.0506 \t recall: 0.814 \t f1: 0.5278767367296047\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.844437 seconds\n",
      "contamination: 0.09999999999999999 \t tp: 70/support: 86/predicted: 1698 -> fp = 1628\n",
      "AUC : 86.0% \t precision: 0.0412 \t recall: 0.814 \t f1: 0.5146047643556214\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.845839 seconds\n",
      "contamination: 0.12 \t tp: 85/support: 86/predicted: 2078 -> fp = 1993\n",
      "AUC : 93.7% \t precision: 0.0409 \t recall: 0.988 \t f1: 0.5090578335786513\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.139847 seconds\n",
      "contamination: 0.13999999999999999 \t tp: 85/support: 86/predicted: 2401 -> fp = 2316\n",
      "AUC : 92.8% \t precision: 0.0354 \t recall: 0.988 \t f1: 0.49871380032814966\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.275757 seconds\n",
      "contamination: 0.15999999999999998 \t tp: 85/support: 86/predicted: 2752 -> fp = 2667\n",
      "AUC : 91.8% \t precision: 0.0309 \t recall: 0.988 \t f1: 0.4886708081165718\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.879761 seconds\n",
      "contamination: 0.18 \t tp: 85/support: 86/predicted: 3066 -> fp = 2981\n",
      "AUC : 90.9% \t precision: 0.0277 \t recall: 0.988 \t f1: 0.48037616700352165\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.278613 seconds\n",
      "contamination: 0.19999999999999998 \t tp: 85/support: 86/predicted: 3418 -> fp = 3333\n",
      "AUC : 89.9% \t precision: 0.0249 \t recall: 0.988 \t f1: 0.4715881646432513\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.893635 seconds\n",
      "contamination: 0.21999999999999997 \t tp: 85/support: 86/predicted: 3753 -> fp = 3668\n",
      "AUC : 88.9% \t precision: 0.0226 \t recall: 0.988 \t f1: 0.46355903346982535\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.087942 seconds\n",
      "contamination: 0.23999999999999996 \t tp: 85/support: 86/predicted: 4118 -> fp = 4033\n",
      "AUC : 87.9% \t precision: 0.0206 \t recall: 0.988 \t f1: 0.4550492107678048\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.864904 seconds\n",
      "contamination: 0.25999999999999995 \t tp: 86/support: 86/predicted: 4510 -> fp = 4424\n",
      "AUC : 87.4% \t precision: 0.0191 \t recall: 1.0 \t f1: 0.4463249870938405\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.092690 seconds\n",
      "contamination: 0.27999999999999997 \t tp: 86/support: 86/predicted: 4873 -> fp = 4787\n",
      "AUC : 86.3% \t precision: 0.0176 \t recall: 1.0 \t f1: 0.4380741153464369\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.927615 seconds\n",
      "contamination: 0.29999999999999993 \t tp: 86/support: 86/predicted: 5266 -> fp = 5180\n",
      "AUC : 85.2% \t precision: 0.0163 \t recall: 1.0 \t f1: 0.429161840343577\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.829155 seconds\n",
      "contamination: 0.31999999999999995 \t tp: 86/support: 86/predicted: 5619 -> fp = 5533\n",
      "AUC : 84.2% \t precision: 0.0153 \t recall: 1.0 \t f1: 0.42113242671587586\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.858806 seconds\n",
      "contamination: 0.3399999999999999 \t tp: 86/support: 86/predicted: 5947 -> fp = 5861\n",
      "AUC : 83.2% \t precision: 0.0145 \t recall: 1.0 \t f1: 0.41362308477782417\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.892811 seconds\n",
      "contamination: 0.35999999999999993 \t tp: 86/support: 86/predicted: 6295 -> fp = 6209\n",
      "AUC : 82.3% \t precision: 0.0137 \t recall: 1.0 \t f1: 0.4055812196995332\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.898079 seconds\n",
      "contamination: 0.035 \t tp: 75/support: 84/predicted: 610 -> fp = 535\n",
      "AUC : 93.1% \t precision: 0.123 \t recall: 0.893 \t f1: 0.6001759547468476\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.523003 seconds\n",
      "contamination: 0.05500000000000001 \t tp: 75/support: 84/predicted: 947 -> fp = 872\n",
      "AUC : 92.2% \t precision: 0.0792 \t recall: 0.893 \t f1: 0.5598357263659598\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.958082 seconds\n",
      "contamination: 0.07500000000000001 \t tp: 76/support: 84/predicted: 1293 -> fp = 1217\n",
      "AUC : 91.8% \t precision: 0.0588 \t recall: 0.905 \t f1: 0.5370588061141501\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:00:15.777343 seconds\n",
      "contamination: 0.09500000000000001 \t tp: 76/support: 84/predicted: 1635 -> fp = 1559\n",
      "AUC : 90.8% \t precision: 0.0465 \t recall: 0.905 \t f1: 0.5207782232776419\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.610792 seconds\n",
      "contamination: 0.11500000000000002 \t tp: 84/support: 84/predicted: 2010 -> fp = 1926\n",
      "AUC : 94.5% \t precision: 0.0418 \t recall: 1.0 \t f1: 0.5109857565561964\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.290061 seconds\n",
      "contamination: 0.135 \t tp: 84/support: 84/predicted: 2345 -> fp = 2261\n",
      "AUC : 93.5% \t precision: 0.0358 \t recall: 1.0 \t f1: 0.5000366780193869\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.558998 seconds\n",
      "contamination: 0.15500000000000003 \t tp: 84/support: 84/predicted: 2695 -> fp = 2611\n",
      "AUC : 92.5% \t precision: 0.0312 \t recall: 1.0 \t f1: 0.48990237592756486\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.846068 seconds\n",
      "contamination: 0.17500000000000002 \t tp: 84/support: 84/predicted: 3033 -> fp = 2949\n",
      "AUC : 91.6% \t precision: 0.0277 \t recall: 1.0 \t f1: 0.48092408071358056\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.755853 seconds\n",
      "contamination: 0.19500000000000003 \t tp: 84/support: 84/predicted: 3398 -> fp = 3314\n",
      "AUC : 90.5% \t precision: 0.0247 \t recall: 1.0 \t f1: 0.4718065622080664\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.403476 seconds\n",
      "contamination: 0.21500000000000005 \t tp: 84/support: 84/predicted: 3728 -> fp = 3644\n",
      "AUC : 89.6% \t precision: 0.0225 \t recall: 1.0 \t f1: 0.4639028199406969\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.876105 seconds\n",
      "contamination: 0.23500000000000004 \t tp: 84/support: 84/predicted: 4067 -> fp = 3983\n",
      "AUC : 88.6% \t precision: 0.0207 \t recall: 1.0 \t f1: 0.4560003685657576\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.825912 seconds\n",
      "contamination: 0.255 \t tp: 84/support: 84/predicted: 4416 -> fp = 4332\n",
      "AUC : 87.6% \t precision: 0.019 \t recall: 1.0 \t f1: 0.4480070463887258\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.921337 seconds\n",
      "contamination: 0.275 \t tp: 84/support: 84/predicted: 4764 -> fp = 4680\n",
      "AUC : 86.6% \t precision: 0.0176 \t recall: 1.0 \t f1: 0.44011429949171915\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.439795 seconds\n",
      "contamination: 0.29500000000000004 \t tp: 84/support: 84/predicted: 5124 -> fp = 5040\n",
      "AUC : 85.6% \t precision: 0.0164 \t recall: 1.0 \t f1: 0.43197755960729306\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.943664 seconds\n",
      "contamination: 0.31500000000000006 \t tp: 84/support: 84/predicted: 5476 -> fp = 5392\n",
      "AUC : 84.6% \t precision: 0.0153 \t recall: 1.0 \t f1: 0.4240083664635501\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.229788 seconds\n",
      "contamination: 0.3350000000000001 \t tp: 84/support: 84/predicted: 5839 -> fp = 5755\n",
      "AUC : 83.6% \t precision: 0.0144 \t recall: 1.0 \t f1: 0.4157419900479748\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.512075 seconds\n",
      "contamination: 0.3550000000000001 \t tp: 84/support: 84/predicted: 6176 -> fp = 6092\n",
      "AUC : 82.6% \t precision: 0.0136 \t recall: 1.0 \t f1: 0.40799872001019044\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.035262 seconds\n",
      "contamination: 0.3750000000000001 \t tp: 84/support: 84/predicted: 6508 -> fp = 6424\n",
      "AUC : 81.6% \t precision: 0.0129 \t recall: 1.0 \t f1: 0.4002856076000226\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.423353 seconds\n",
      "contamination: 0.39500000000000013 \t tp: 84/support: 84/predicted: 6830 -> fp = 6746\n",
      "AUC : 80.7% \t precision: 0.0123 \t recall: 1.0 \t f1: 0.39270875245119935\n",
      "--------------------\n",
      "Time for IF fitting: 290.292\n",
      "3 0.11500000000000002 0.25 500\n",
      "Finished trainning in 0:00:03.265150 seconds\n",
      "contamination: 0.030000000000000002 \t tp: 55/support: 65/predicted: 542 -> fp = 487\n",
      "AUC : 90.9% \t precision: 0.101 \t recall: 0.846 \t f1: 0.5834164559333705\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.212910 seconds\n",
      "contamination: 0.05 \t tp: 56/support: 65/predicted: 874 -> fp = 818\n",
      "AUC : 90.7% \t precision: 0.0641 \t recall: 0.862 \t f1: 0.5475525699871\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.798617 seconds\n",
      "contamination: 0.07 \t tp: 56/support: 65/predicted: 1250 -> fp = 1194\n",
      "AUC : 89.7% \t precision: 0.0448 \t recall: 0.862 \t f1: 0.5248102033595227\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.464910 seconds\n",
      "contamination: 0.09 \t tp: 65/support: 65/predicted: 1576 -> fp = 1511\n",
      "AUC : 95.7% \t precision: 0.0412 \t recall: 1.0 \t f1: 0.5170665033204119\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.228958 seconds\n",
      "contamination: 0.11 \t tp: 65/support: 65/predicted: 1922 -> fp = 1857\n",
      "AUC : 94.7% \t precision: 0.0338 \t recall: 1.0 \t f1: 0.5047179385880385\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.251789 seconds\n",
      "contamination: 0.13 \t tp: 65/support: 65/predicted: 2277 -> fp = 2212\n",
      "AUC : 93.7% \t precision: 0.0285 \t recall: 1.0 \t f1: 0.49404687606219344\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.252416 seconds\n",
      "contamination: 0.15 \t tp: 65/support: 65/predicted: 2645 -> fp = 2580\n",
      "AUC : 92.6% \t precision: 0.0246 \t recall: 1.0 \t f1: 0.4842244212110473\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.234158 seconds\n",
      "contamination: 0.17 \t tp: 65/support: 65/predicted: 2988 -> fp = 2923\n",
      "AUC : 91.7% \t precision: 0.0218 \t recall: 1.0 \t f1: 0.475762357208766\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.266635 seconds\n",
      "contamination: 0.19 \t tp: 65/support: 65/predicted: 3315 -> fp = 3250\n",
      "AUC : 90.7% \t precision: 0.0196 \t recall: 1.0 \t f1: 0.4680883257234991\n",
      "--------------------\n",
      "Finished trainning in 0:00:02.997880 seconds\n",
      "contamination: 0.21 \t tp: 65/support: 65/predicted: 3676 -> fp = 3611\n",
      "AUC : 89.7% \t precision: 0.0177 \t recall: 1.0 \t f1: 0.45989882929421216\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.027715 seconds\n",
      "contamination: 0.23 \t tp: 65/support: 65/predicted: 4011 -> fp = 3946\n",
      "AUC : 88.7% \t precision: 0.0162 \t recall: 1.0 \t f1: 0.4524615830970363\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.108837 seconds\n",
      "contamination: 0.25 \t tp: 65/support: 65/predicted: 4375 -> fp = 4310\n",
      "AUC : 87.7% \t precision: 0.0149 \t recall: 1.0 \t f1: 0.44447619625877094\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.278472 seconds\n",
      "contamination: 0.27 \t tp: 65/support: 65/predicted: 4711 -> fp = 4646\n",
      "AUC : 86.7% \t precision: 0.0138 \t recall: 1.0 \t f1: 0.4371399015619277\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.212838 seconds\n",
      "contamination: 0.29000000000000004 \t tp: 65/support: 65/predicted: 5035 -> fp = 4970\n",
      "AUC : 85.8% \t precision: 0.0129 \t recall: 1.0 \t f1: 0.4300605968080984\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.194755 seconds\n",
      "contamination: 0.31000000000000005 \t tp: 65/support: 65/predicted: 5445 -> fp = 5380\n",
      "AUC : 84.6% \t precision: 0.0119 \t recall: 1.0 \t f1: 0.42105324380470394\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.679773 seconds\n",
      "contamination: 0.33 \t tp: 65/support: 65/predicted: 5803 -> fp = 5738\n",
      "AUC : 83.6% \t precision: 0.0112 \t recall: 1.0 \t f1: 0.41311213004475855\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.217826 seconds\n",
      "contamination: 0.35000000000000003 \t tp: 65/support: 65/predicted: 6187 -> fp = 6122\n",
      "AUC : 82.5% \t precision: 0.0105 \t recall: 1.0 \t f1: 0.40448704743317515\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.737784 seconds\n",
      "contamination: 0.37000000000000005 \t tp: 65/support: 65/predicted: 6550 -> fp = 6485\n",
      "AUC : 81.5% \t precision: 0.00992 \t recall: 1.0 \t f1: 0.39620969800723826\n",
      "--------------------\n",
      "Finished trainning in 0:00:03.402746 seconds\n",
      "contamination: 0.39 \t tp: 65/support: 65/predicted: 6919 -> fp = 6854\n",
      "AUC : 80.4% \t precision: 0.00939 \t recall: 1.0 \t f1: 0.38765274529824445\n",
      "--------------------\n",
      "Time for IF fitting: 63.319\n",
      "4 0.09 0.5 100\n",
      "Finished trainning in 0:00:06.475552 seconds\n",
      "contamination: 0.025 \t tp: 81/support: 92/predicted: 517 -> fp = 436\n",
      "AUC : 92.8% \t precision: 0.157 \t recall: 0.88 \t f1: 0.6265351041370326\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.309977 seconds\n",
      "contamination: 0.045 \t tp: 81/support: 92/predicted: 876 -> fp = 795\n",
      "AUC : 91.7% \t precision: 0.0925 \t recall: 0.88 \t f1: 0.5718892345375541\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.569590 seconds\n",
      "contamination: 0.065 \t tp: 82/support: 92/predicted: 1212 -> fp = 1130\n",
      "AUC : 91.3% \t precision: 0.0677 \t recall: 0.891 \t f1: 0.5460444400141367\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:00:06.434194 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 82/support: 92/predicted: 1558 -> fp = 1476\n",
      "AUC : 90.3% \t precision: 0.0526 \t recall: 0.891 \t f1: 0.5275205131544674\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.749480 seconds\n",
      "contamination: 0.10499999999999998 \t tp: 92/support: 92/predicted: 1867 -> fp = 1775\n",
      "AUC : 94.9% \t precision: 0.0493 \t recall: 1.0 \t f1: 0.5202267818798704\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.558963 seconds\n",
      "contamination: 0.12499999999999997 \t tp: 92/support: 92/predicted: 2233 -> fp = 2141\n",
      "AUC : 93.9% \t precision: 0.0412 \t recall: 1.0 \t f1: 0.5069615279173901\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.047146 seconds\n",
      "contamination: 0.145 \t tp: 92/support: 92/predicted: 2591 -> fp = 2499\n",
      "AUC : 92.9% \t precision: 0.0355 \t recall: 1.0 \t f1: 0.4958094836261647\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.459541 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 92/support: 92/predicted: 2890 -> fp = 2798\n",
      "AUC : 92.0% \t precision: 0.0318 \t recall: 1.0 \t f1: 0.48736675930255163\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.221155 seconds\n",
      "contamination: 0.18499999999999997 \t tp: 92/support: 92/predicted: 3258 -> fp = 3166\n",
      "AUC : 90.9% \t precision: 0.0282 \t recall: 1.0 \t f1: 0.47768907318519965\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.256639 seconds\n",
      "contamination: 0.20499999999999996 \t tp: 92/support: 92/predicted: 3559 -> fp = 3467\n",
      "AUC : 90.1% \t precision: 0.0258 \t recall: 1.0 \t f1: 0.470172070320493\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.412613 seconds\n",
      "contamination: 0.22499999999999995 \t tp: 92/support: 92/predicted: 3966 -> fp = 3874\n",
      "AUC : 88.9% \t precision: 0.0232 \t recall: 1.0 \t f1: 0.4603802967341442\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.364311 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 92/support: 92/predicted: 4320 -> fp = 4228\n",
      "AUC : 87.9% \t precision: 0.0213 \t recall: 1.0 \t f1: 0.45208636343072955\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.528005 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 92/support: 92/predicted: 4656 -> fp = 4564\n",
      "AUC : 86.9% \t precision: 0.0198 \t recall: 1.0 \t f1: 0.44432560283156997\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.936157 seconds\n",
      "contamination: 0.285 \t tp: 92/support: 92/predicted: 5021 -> fp = 4929\n",
      "AUC : 85.9% \t precision: 0.0183 \t recall: 1.0 \t f1: 0.4359554687217254\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.416594 seconds\n",
      "contamination: 0.305 \t tp: 92/support: 92/predicted: 5332 -> fp = 5240\n",
      "AUC : 85.0% \t precision: 0.0173 \t recall: 1.0 \t f1: 0.428835180339873\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.401552 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 92/support: 92/predicted: 5687 -> fp = 5595\n",
      "AUC : 84.0% \t precision: 0.0162 \t recall: 1.0 \t f1: 0.4206856667390736\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.079392 seconds\n",
      "contamination: 0.345 \t tp: 92/support: 92/predicted: 5996 -> fp = 5904\n",
      "AUC : 83.1% \t precision: 0.0153 \t recall: 1.0 \t f1: 0.41354973270764533\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.258828 seconds\n",
      "contamination: 0.365 \t tp: 92/support: 92/predicted: 6361 -> fp = 6269\n",
      "AUC : 82.1% \t precision: 0.0145 \t recall: 1.0 \t f1: 0.40504471218838467\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.492696 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 92/support: 92/predicted: 6688 -> fp = 6596\n",
      "AUC : 81.1% \t precision: 0.0138 \t recall: 1.0 \t f1: 0.3973361503208409\n",
      "--------------------\n",
      "Time for IF fitting: 124.462\n",
      "5 0.10499999999999998 0.5 200\n",
      "Finished trainning in 0:00:29.153991 seconds\n",
      "contamination: 0.020000000000000004 \t tp: 66/support: 80/predicted: 365 -> fp = 299\n",
      "AUC : 90.4% \t precision: 0.181 \t recall: 0.825 \t f1: 0.6438056897459812\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.310238 seconds\n",
      "contamination: 0.04000000000000001 \t tp: 70/support: 80/predicted: 722 -> fp = 652\n",
      "AUC : 91.9% \t precision: 0.097 \t recall: 0.875 \t f1: 0.5776462575512779\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.190590 seconds\n",
      "contamination: 0.06000000000000001 \t tp: 70/support: 80/predicted: 1034 -> fp = 964\n",
      "AUC : 91.0% \t precision: 0.0677 \t recall: 0.875 \t f1: 0.5485299267732333\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.173785 seconds\n",
      "contamination: 0.08000000000000002 \t tp: 70/support: 80/predicted: 1405 -> fp = 1335\n",
      "AUC : 89.9% \t precision: 0.0498 \t recall: 0.875 \t f1: 0.527164183940447\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.770646 seconds\n",
      "contamination: 0.10000000000000002 \t tp: 70/support: 80/predicted: 1724 -> fp = 1654\n",
      "AUC : 89.0% \t precision: 0.0406 \t recall: 0.875 \t f1: 0.5138551345169987\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.486572 seconds\n",
      "contamination: 0.12000000000000002 \t tp: 79/support: 80/predicted: 2069 -> fp = 1990\n",
      "AUC : 93.7% \t precision: 0.0382 \t recall: 0.988 \t f1: 0.5065991876662651\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.173960 seconds\n",
      "contamination: 0.14 \t tp: 79/support: 80/predicted: 2461 -> fp = 2382\n",
      "AUC : 92.6% \t precision: 0.0321 \t recall: 0.988 \t f1: 0.49455561122130226\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.703480 seconds\n",
      "contamination: 0.16000000000000003 \t tp: 79/support: 80/predicted: 2814 -> fp = 2735\n",
      "AUC : 91.6% \t precision: 0.0281 \t recall: 0.988 \t f1: 0.4848924019638297\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.891629 seconds\n",
      "contamination: 0.18000000000000005 \t tp: 79/support: 80/predicted: 3164 -> fp = 3085\n",
      "AUC : 90.6% \t precision: 0.025 \t recall: 0.988 \t f1: 0.4759979033201038\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.716733 seconds\n",
      "contamination: 0.20000000000000007 \t tp: 79/support: 80/predicted: 3542 -> fp = 3463\n",
      "AUC : 89.5% \t precision: 0.0223 \t recall: 0.988 \t f1: 0.4668828272793862\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.072466 seconds\n",
      "contamination: 0.22000000000000003 \t tp: 79/support: 80/predicted: 3885 -> fp = 3806\n",
      "AUC : 88.5% \t precision: 0.0203 \t recall: 0.988 \t f1: 0.4588932051859555\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.199756 seconds\n",
      "contamination: 0.24000000000000005 \t tp: 80/support: 80/predicted: 4237 -> fp = 4157\n",
      "AUC : 88.1% \t precision: 0.0189 \t recall: 1.0 \t f1: 0.4511285921943854\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.181276 seconds\n",
      "contamination: 0.26000000000000006 \t tp: 80/support: 80/predicted: 4587 -> fp = 4507\n",
      "AUC : 87.1% \t precision: 0.0174 \t recall: 1.0 \t f1: 0.44322488133828153\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.945386 seconds\n",
      "contamination: 0.2800000000000001 \t tp: 80/support: 80/predicted: 4924 -> fp = 4844\n",
      "AUC : 86.2% \t precision: 0.0162 \t recall: 1.0 \t f1: 0.43565553527327394\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.797799 seconds\n",
      "contamination: 0.30000000000000004 \t tp: 80/support: 80/predicted: 5268 -> fp = 5188\n",
      "AUC : 85.2% \t precision: 0.0152 \t recall: 1.0 \t f1: 0.42792940597012513\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.715545 seconds\n",
      "contamination: 0.32000000000000006 \t tp: 80/support: 80/predicted: 5602 -> fp = 5522\n",
      "AUC : 84.2% \t precision: 0.0143 \t recall: 1.0 \t f1: 0.42039741047504725\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.633993 seconds\n",
      "contamination: 0.3400000000000001 \t tp: 80/support: 80/predicted: 5967 -> fp = 5887\n",
      "AUC : 83.2% \t precision: 0.0134 \t recall: 1.0 \t f1: 0.4121028239816948\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.471360 seconds\n",
      "contamination: 0.3600000000000001 \t tp: 80/support: 80/predicted: 6319 -> fp = 6239\n",
      "AUC : 82.2% \t precision: 0.0127 \t recall: 1.0 \t f1: 0.4040164726442732\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.771088 seconds\n",
      "contamination: 0.3800000000000001 \t tp: 80/support: 80/predicted: 6688 -> fp = 6608\n",
      "AUC : 81.1% \t precision: 0.012 \t recall: 1.0 \t f1: 0.3954249247831191\n",
      "--------------------\n",
      "Time for IF fitting: 577.869\n",
      "6 0.12000000000000002 0.25 1000\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.1\n",
    "\n",
    "dfsf_frac = dfsf_normal.sample(frac = frac_normal, random_state = 1).append(dfsf_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsf_frac.loc[dfsf_frac[\"target\"]=='normal.'])/len(dfsf_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsf_frac)} records\")\n",
    "\n",
    "dfsf_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsf_frac[\"target\"]]\n",
    "toDecode = toDecodeSF\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsf_frac[f] = leSF.fit_transform(dfsf_frac[f])\n",
    "    \n",
    "    \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),\n",
    "                           (2, 0.25, 200),\n",
    "                           (3, 0.25, 500),\n",
    "                           (4, 0.5, 100),\n",
    "                           (5, 0.5, 200),\n",
    "                           (6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsf_frac.drop([\"target\", \"binary_target\"], axis=1), dfsf_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False)\n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.03        97\n",
      "           1       1.00      0.62      0.77     17480\n",
      "\n",
      "    accuracy                           0.63     17577\n",
      "   macro avg       0.51      0.81      0.40     17577\n",
      "weighted avg       0.99      0.63      0.76     17577\n",
      "\n",
      "---0.7639359711599744, 0.39832129353397283\n",
      "---0.8116990846681922\n",
      "---0.8116990846681922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.03        86\n",
      "           1       1.00      0.63      0.77     17491\n",
      "\n",
      "    accuracy                           0.63     17577\n",
      "   macro avg       0.51      0.81      0.40     17577\n",
      "weighted avg       1.00      0.63      0.77     17577\n",
      "\n",
      "---0.7660715317659224, 0.39765377716817896\n",
      "---0.8128180206963581\n",
      "---0.8128180206963581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.02        84\n",
      "           1       1.00      0.61      0.76     17493\n",
      "\n",
      "    accuracy                           0.62     17577\n",
      "   macro avg       0.51      0.81      0.39     17577\n",
      "weighted avg       1.00      0.62      0.76     17577\n",
      "\n",
      "---0.7575977354605927, 0.39270875245119935\n",
      "---0.8071800148630881\n",
      "---0.8071800148630881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.02        65\n",
      "           1       1.00      0.61      0.76     17512\n",
      "\n",
      "    accuracy                           0.61     17577\n",
      "   macro avg       0.50      0.80      0.39     17577\n",
      "weighted avg       1.00      0.61      0.75     17577\n",
      "\n",
      "---0.7539620943845996, 0.38765274529824445\n",
      "---0.8043056190041115\n",
      "---0.8043056190041115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.03        92\n",
      "           1       1.00      0.62      0.77     17485\n",
      "\n",
      "    accuracy                           0.62     17577\n",
      "   macro avg       0.51      0.81      0.40     17577\n",
      "weighted avg       0.99      0.62      0.76     17577\n",
      "\n",
      "---0.7636583465802327, 0.3973361503208409\n",
      "---0.8113811838718902\n",
      "---0.8113811838718902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.02        80\n",
      "           1       1.00      0.62      0.77     17497\n",
      "\n",
      "    accuracy                           0.62     17577\n",
      "   macro avg       0.51      0.81      0.40     17577\n",
      "weighted avg       1.00      0.62      0.76     17577\n",
      "\n",
      "---0.7638249080546747, 0.3954249247831191\n",
      "---0.8111676287363547\n",
      "---0.8111676287363547\n",
      "0.8097585919733324 \\pm 0.0032902212447014183\n",
      "0.7615084312343328 \\pm 0.004667842728500686\n",
      "0.8097585919733324 \\pm 0.0032902212447014183\n"
     ]
    }
   ],
   "source": [
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 0.2% out of 140276 records\n",
      "Finished trainning in 0:00:05.843321 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 80/support: 97/predicted: 1571 -> fp = 1491\n",
      "AUC : 89.1% \t precision: 0.0509 \t recall: 0.825 \t f1: 0.5369495085981747\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.284387 seconds\n",
      "contamination: 0.065 \t tp: 80/support: 97/predicted: 2253 -> fp = 2173\n",
      "AUC : 88.1% \t precision: 0.0355 \t recall: 0.825 \t f1: 0.5178892517222028\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.826262 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 97/support: 97/predicted: 2922 -> fp = 2825\n",
      "AUC : 96.0% \t precision: 0.0332 \t recall: 1.0 \t f1: 0.5110851326877313\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.931318 seconds\n",
      "contamination: 0.105 \t tp: 97/support: 97/predicted: 3579 -> fp = 3482\n",
      "AUC : 95.0% \t precision: 0.0271 \t recall: 1.0 \t f1: 0.5001919576451174\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.819113 seconds\n",
      "contamination: 0.125 \t tp: 97/support: 97/predicted: 4296 -> fp = 4199\n",
      "AUC : 94.0% \t precision: 0.0226 \t recall: 1.0 \t f1: 0.49014659536981076\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.834491 seconds\n",
      "contamination: 0.145 \t tp: 97/support: 97/predicted: 5023 -> fp = 4926\n",
      "AUC : 93.0% \t precision: 0.0193 \t recall: 1.0 \t f1: 0.4810634951571103\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.779919 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 97/support: 97/predicted: 5716 -> fp = 5619\n",
      "AUC : 92.0% \t precision: 0.017 \t recall: 1.0 \t f1: 0.4730100945727272\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.560013 seconds\n",
      "contamination: 0.185 \t tp: 97/support: 97/predicted: 6431 -> fp = 6334\n",
      "AUC : 90.9% \t precision: 0.0151 \t recall: 1.0 \t f1: 0.4650712994087746\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.775832 seconds\n",
      "contamination: 0.205 \t tp: 97/support: 97/predicted: 7119 -> fp = 7022\n",
      "AUC : 90.0% \t precision: 0.0136 \t recall: 1.0 \t f1: 0.4576431068247591\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.097149 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 97/support: 97/predicted: 7861 -> fp = 7764\n",
      "AUC : 88.9% \t precision: 0.0123 \t recall: 1.0 \t f1: 0.4497573421608508\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.465899 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 97/support: 97/predicted: 8571 -> fp = 8474\n",
      "AUC : 87.9% \t precision: 0.0113 \t recall: 1.0 \t f1: 0.4422626537389713\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.133902 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 97/support: 97/predicted: 9230 -> fp = 9133\n",
      "AUC : 86.9% \t precision: 0.0105 \t recall: 1.0 \t f1: 0.4353065922956242\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.820395 seconds\n",
      "contamination: 0.285 \t tp: 97/support: 97/predicted: 9913 -> fp = 9816\n",
      "AUC : 86.0% \t precision: 0.00979 \t recall: 1.0 \t f1: 0.428064444868596\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.105823 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 97/support: 97/predicted: 10642 -> fp = 10545\n",
      "AUC : 84.9% \t precision: 0.00911 \t recall: 1.0 \t f1: 0.42026837776233456\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.844116 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 97/support: 97/predicted: 11394 -> fp = 11297\n",
      "AUC : 83.8% \t precision: 0.00851 \t recall: 1.0 \t f1: 0.41212785198875257\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.004674 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 97/support: 97/predicted: 12061 -> fp = 11964\n",
      "AUC : 82.9% \t precision: 0.00804 \t recall: 1.0 \t f1: 0.404804777796043\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.822506 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 97/support: 97/predicted: 12749 -> fp = 12652\n",
      "AUC : 81.9% \t precision: 0.00761 \t recall: 1.0 \t f1: 0.39713417651422855\n",
      "--------------------\n",
      "Finished trainning in 0:00:05.988439 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 97/support: 97/predicted: 13473 -> fp = 13376\n",
      "AUC : 80.9% \t precision: 0.0072 \t recall: 1.0 \t f1: 0.3889187332151719\n",
      "--------------------\n",
      "Time for IF fitting: 108.791\n",
      "1 0.08499999999999999 0.25 100\n",
      "Finished trainning in 0:00:11.656375 seconds\n",
      "contamination: 0.04 \t tp: 60/support: 70/predicted: 1369 -> fp = 1309\n",
      "AUC : 91.0% \t precision: 0.0438 \t recall: 0.857 \t f1: 0.5320957733447218\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.249754 seconds\n",
      "contamination: 0.06 \t tp: 60/support: 70/predicted: 2123 -> fp = 2063\n",
      "AUC : 89.9% \t precision: 0.0283 \t recall: 0.857 \t f1: 0.5121047954715927\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.795808 seconds\n",
      "contamination: 0.07999999999999999 \t tp: 60/support: 70/predicted: 2813 -> fp = 2753\n",
      "AUC : 88.9% \t precision: 0.0213 \t recall: 0.857 \t f1: 0.5002704308256948\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.913757 seconds\n",
      "contamination: 0.09999999999999999 \t tp: 70/support: 70/predicted: 3584 -> fp = 3514\n",
      "AUC : 95.0% \t precision: 0.0195 \t recall: 1.0 \t f1: 0.4927296770161737\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.208999 seconds\n",
      "contamination: 0.12 \t tp: 70/support: 70/predicted: 4313 -> fp = 4243\n",
      "AUC : 93.9% \t precision: 0.0162 \t recall: 1.0 \t f1: 0.48370709007623114\n",
      "--------------------\n",
      "Finished trainning in 0:00:13.204865 seconds\n",
      "contamination: 0.13999999999999999 \t tp: 70/support: 70/predicted: 4977 -> fp = 4907\n",
      "AUC : 93.0% \t precision: 0.0141 \t recall: 1.0 \t f1: 0.4761762424103108\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.532577 seconds\n",
      "contamination: 0.15999999999999998 \t tp: 70/support: 70/predicted: 5671 -> fp = 5601\n",
      "AUC : 92.0% \t precision: 0.0123 \t recall: 1.0 \t f1: 0.46870494704999516\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.106620 seconds\n",
      "contamination: 0.18 \t tp: 70/support: 70/predicted: 6348 -> fp = 6278\n",
      "AUC : 91.0% \t precision: 0.011 \t recall: 1.0 \t f1: 0.4616444265647249\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.224525 seconds\n",
      "contamination: 0.19999999999999998 \t tp: 70/support: 70/predicted: 7022 -> fp = 6952\n",
      "AUC : 90.1% \t precision: 0.00997 \t recall: 1.0 \t f1: 0.4547359300174544\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.585879 seconds\n",
      "contamination: 0.21999999999999997 \t tp: 70/support: 70/predicted: 7642 -> fp = 7572\n",
      "AUC : 89.2% \t precision: 0.00916 \t recall: 1.0 \t f1: 0.44842895648198505\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.345828 seconds\n",
      "contamination: 0.23999999999999996 \t tp: 70/support: 70/predicted: 8363 -> fp = 8293\n",
      "AUC : 88.2% \t precision: 0.00837 \t recall: 1.0 \t f1: 0.4411019550155507\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.821276 seconds\n",
      "contamination: 0.25999999999999995 \t tp: 70/support: 70/predicted: 9061 -> fp = 8991\n",
      "AUC : 87.2% \t precision: 0.00773 \t recall: 1.0 \t f1: 0.4339779268118371\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.911509 seconds\n",
      "contamination: 0.27999999999999997 \t tp: 70/support: 70/predicted: 9676 -> fp = 9606\n",
      "AUC : 86.3% \t precision: 0.00723 \t recall: 1.0 \t f1: 0.42765203244133676\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.905379 seconds\n",
      "contamination: 0.29999999999999993 \t tp: 70/support: 70/predicted: 10358 -> fp = 10288\n",
      "AUC : 85.3% \t precision: 0.00676 \t recall: 1.0 \t f1: 0.42056297292173644\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.842465 seconds\n",
      "contamination: 0.31999999999999995 \t tp: 70/support: 70/predicted: 11089 -> fp = 11019\n",
      "AUC : 84.3% \t precision: 0.00631 \t recall: 1.0 \t f1: 0.41285835832873724\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.377759 seconds\n",
      "contamination: 0.3399999999999999 \t tp: 70/support: 70/predicted: 11749 -> fp = 11679\n",
      "AUC : 83.3% \t precision: 0.00596 \t recall: 1.0 \t f1: 0.4057923491570771\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.853611 seconds\n",
      "contamination: 0.35999999999999993 \t tp: 70/support: 70/predicted: 12435 -> fp = 12365\n",
      "AUC : 82.3% \t precision: 0.00563 \t recall: 1.0 \t f1: 0.3983241502906064\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.865624 seconds\n",
      "contamination: 0.37999999999999995 \t tp: 70/support: 70/predicted: 13140 -> fp = 13070\n",
      "AUC : 81.3% \t precision: 0.00533 \t recall: 1.0 \t f1: 0.39050488998361316\n",
      "--------------------\n",
      "Time for IF fitting: 216.232\n",
      "2 0.09999999999999999 0.25 200\n",
      "Finished trainning in 0:00:28.876662 seconds\n",
      "contamination: 0.035 \t tp: 63/support: 76/predicted: 1190 -> fp = 1127\n",
      "AUC : 89.8% \t precision: 0.0529 \t recall: 0.829 \t f1: 0.5414868106175671\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:00:29.238364 seconds\n",
      "contamination: 0.05500000000000001 \t tp: 63/support: 76/predicted: 1862 -> fp = 1799\n",
      "AUC : 88.9% \t precision: 0.0338 \t recall: 0.829 \t f1: 0.5192232824600747\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.809307 seconds\n",
      "contamination: 0.07500000000000001 \t tp: 63/support: 76/predicted: 2536 -> fp = 2473\n",
      "AUC : 87.9% \t precision: 0.0248 \t recall: 0.829 \t f1: 0.5057117242662449\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.198834 seconds\n",
      "contamination: 0.09500000000000001 \t tp: 74/support: 76/predicted: 3187 -> fp = 3113\n",
      "AUC : 94.2% \t precision: 0.0232 \t recall: 0.974 \t f1: 0.49938879707625283\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.256191 seconds\n",
      "contamination: 0.11500000000000002 \t tp: 74/support: 76/predicted: 4003 -> fp = 3929\n",
      "AUC : 93.1% \t precision: 0.0185 \t recall: 0.974 \t f1: 0.4883879963761325\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.832460 seconds\n",
      "contamination: 0.135 \t tp: 75/support: 76/predicted: 4736 -> fp = 4661\n",
      "AUC : 92.7% \t precision: 0.0158 \t recall: 0.987 \t f1: 0.4799034582969756\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.030486 seconds\n",
      "contamination: 0.15500000000000003 \t tp: 75/support: 76/predicted: 5458 -> fp = 5383\n",
      "AUC : 91.7% \t precision: 0.0137 \t recall: 0.987 \t f1: 0.47188333753973527\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.062525 seconds\n",
      "contamination: 0.17500000000000002 \t tp: 75/support: 76/predicted: 6140 -> fp = 6065\n",
      "AUC : 90.7% \t precision: 0.0122 \t recall: 0.987 \t f1: 0.4646171842637848\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.035577 seconds\n",
      "contamination: 0.19500000000000003 \t tp: 75/support: 76/predicted: 6831 -> fp = 6756\n",
      "AUC : 89.7% \t precision: 0.011 \t recall: 0.987 \t f1: 0.45742747909490705\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.300789 seconds\n",
      "contamination: 0.21500000000000005 \t tp: 75/support: 76/predicted: 7508 -> fp = 7433\n",
      "AUC : 88.7% \t precision: 0.00999 \t recall: 0.987 \t f1: 0.45046857995704365\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.010865 seconds\n",
      "contamination: 0.23500000000000004 \t tp: 76/support: 76/predicted: 8190 -> fp = 8114\n",
      "AUC : 88.4% \t precision: 0.00928 \t recall: 1.0 \t f1: 0.44362343390139264\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.142280 seconds\n",
      "contamination: 0.255 \t tp: 76/support: 76/predicted: 8895 -> fp = 8819\n",
      "AUC : 87.4% \t precision: 0.00854 \t recall: 1.0 \t f1: 0.43638221688300044\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.873131 seconds\n",
      "contamination: 0.275 \t tp: 76/support: 76/predicted: 9585 -> fp = 9509\n",
      "AUC : 86.4% \t precision: 0.00793 \t recall: 1.0 \t f1: 0.4292500162814756\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.080108 seconds\n",
      "contamination: 0.29500000000000004 \t tp: 76/support: 76/predicted: 10261 -> fp = 10185\n",
      "AUC : 85.4% \t precision: 0.00741 \t recall: 1.0 \t f1: 0.42219479101510743\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.119323 seconds\n",
      "contamination: 0.31500000000000006 \t tp: 76/support: 76/predicted: 10964 -> fp = 10888\n",
      "AUC : 84.4% \t precision: 0.00693 \t recall: 1.0 \t f1: 0.4147658813829743\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.539432 seconds\n",
      "contamination: 0.3350000000000001 \t tp: 76/support: 76/predicted: 11690 -> fp = 11614\n",
      "AUC : 83.4% \t precision: 0.0065 \t recall: 1.0 \t f1: 0.4069766608205818\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.407474 seconds\n",
      "contamination: 0.3550000000000001 \t tp: 76/support: 76/predicted: 12365 -> fp = 12289\n",
      "AUC : 82.4% \t precision: 0.00615 \t recall: 1.0 \t f1: 0.3996128287034466\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.800356 seconds\n",
      "contamination: 0.3750000000000001 \t tp: 76/support: 76/predicted: 12998 -> fp = 12922\n",
      "AUC : 81.5% \t precision: 0.00585 \t recall: 1.0 \t f1: 0.39258931532337327\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.489305 seconds\n",
      "contamination: 0.39500000000000013 \t tp: 76/support: 76/predicted: 13748 -> fp = 13672\n",
      "AUC : 80.5% \t precision: 0.00553 \t recall: 1.0 \t f1: 0.3841069120204304\n",
      "--------------------\n",
      "Time for IF fitting: 562.994\n",
      "3 0.09500000000000001 0.25 500\n",
      "Finished trainning in 0:00:06.253381 seconds\n",
      "contamination: 0.030000000000000002 \t tp: 59/support: 81/predicted: 1070 -> fp = 1011\n",
      "AUC : 85.0% \t precision: 0.0551 \t recall: 0.728 \t f1: 0.5437728562843724\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.525025 seconds\n",
      "contamination: 0.05 \t tp: 59/support: 81/predicted: 1789 -> fp = 1730\n",
      "AUC : 83.9% \t precision: 0.033 \t recall: 0.728 \t f1: 0.5187190215097528\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.258807 seconds\n",
      "contamination: 0.07 \t tp: 79/support: 81/predicted: 2575 -> fp = 2496\n",
      "AUC : 95.2% \t precision: 0.0307 \t recall: 0.975 \t f1: 0.5112353365627532\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.245569 seconds\n",
      "contamination: 0.09 \t tp: 80/support: 81/predicted: 3280 -> fp = 3200\n",
      "AUC : 94.8% \t precision: 0.0244 \t recall: 0.988 \t f1: 0.49983460651407996\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.046789 seconds\n",
      "contamination: 0.11 \t tp: 80/support: 81/predicted: 3934 -> fp = 3854\n",
      "AUC : 93.9% \t precision: 0.0203 \t recall: 0.988 \t f1: 0.4907750601547903\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.417722 seconds\n",
      "contamination: 0.13 \t tp: 80/support: 81/predicted: 4606 -> fp = 4526\n",
      "AUC : 92.9% \t precision: 0.0174 \t recall: 0.988 \t f1: 0.4824853640528031\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.815787 seconds\n",
      "contamination: 0.15 \t tp: 81/support: 81/predicted: 5316 -> fp = 5235\n",
      "AUC : 92.5% \t precision: 0.0152 \t recall: 1.0 \t f1: 0.47457800788104587\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.642746 seconds\n",
      "contamination: 0.17 \t tp: 81/support: 81/predicted: 6073 -> fp = 5992\n",
      "AUC : 91.4% \t precision: 0.0133 \t recall: 1.0 \t f1: 0.4663379648942135\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.717997 seconds\n",
      "contamination: 0.19 \t tp: 81/support: 81/predicted: 6817 -> fp = 6736\n",
      "AUC : 90.4% \t precision: 0.0119 \t recall: 1.0 \t f1: 0.45848510206278564\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.316104 seconds\n",
      "contamination: 0.21 \t tp: 81/support: 81/predicted: 7483 -> fp = 7402\n",
      "AUC : 89.4% \t precision: 0.0108 \t recall: 1.0 \t f1: 0.45156264860776074\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.161975 seconds\n",
      "contamination: 0.23 \t tp: 81/support: 81/predicted: 8198 -> fp = 8117\n",
      "AUC : 88.4% \t precision: 0.00988 \t recall: 1.0 \t f1: 0.4441749055911339\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.898772 seconds\n",
      "contamination: 0.25 \t tp: 81/support: 81/predicted: 8857 -> fp = 8776\n",
      "AUC : 87.5% \t precision: 0.00915 \t recall: 1.0 \t f1: 0.43736308366861326\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.240849 seconds\n",
      "contamination: 0.27 \t tp: 81/support: 81/predicted: 9613 -> fp = 9532\n",
      "AUC : 86.4% \t precision: 0.00843 \t recall: 1.0 \t f1: 0.4295058394440524\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.941858 seconds\n",
      "contamination: 0.29000000000000004 \t tp: 81/support: 81/predicted: 10284 -> fp = 10203\n",
      "AUC : 85.4% \t precision: 0.00788 \t recall: 1.0 \t f1: 0.4224668616623195\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.288722 seconds\n",
      "contamination: 0.31000000000000005 \t tp: 81/support: 81/predicted: 10984 -> fp = 10903\n",
      "AUC : 84.4% \t precision: 0.00737 \t recall: 1.0 \t f1: 0.4150362565410254\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.430621 seconds\n",
      "contamination: 0.33 \t tp: 81/support: 81/predicted: 11690 -> fp = 11609\n",
      "AUC : 83.4% \t precision: 0.00693 \t recall: 1.0 \t f1: 0.40743300009551003\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.399984 seconds\n",
      "contamination: 0.35000000000000003 \t tp: 81/support: 81/predicted: 12362 -> fp = 12281\n",
      "AUC : 82.4% \t precision: 0.00655 \t recall: 1.0 \t f1: 0.40007931757687576\n",
      "--------------------\n",
      "Finished trainning in 0:00:06.110612 seconds\n",
      "contamination: 0.37000000000000005 \t tp: 81/support: 81/predicted: 13080 -> fp = 12999\n",
      "AUC : 81.4% \t precision: 0.00619 \t recall: 1.0 \t f1: 0.3920822025454754\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.263234 seconds\n",
      "contamination: 0.39 \t tp: 81/support: 81/predicted: 13753 -> fp = 13672\n",
      "AUC : 80.5% \t precision: 0.00589 \t recall: 1.0 \t f1: 0.3844428064621872\n",
      "--------------------\n",
      "Time for IF fitting: 124.866\n",
      "4 0.07 0.5 100\n",
      "Finished trainning in 0:00:11.941788 seconds\n",
      "contamination: 0.025 \t tp: 69/support: 84/predicted: 868 -> fp = 799\n",
      "AUC : 89.9% \t precision: 0.0795 \t recall: 0.821 \t f1: 0.5665962985662568\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:00:12.436685 seconds\n",
      "contamination: 0.045 \t tp: 69/support: 84/predicted: 1600 -> fp = 1531\n",
      "AUC : 88.9% \t precision: 0.0431 \t recall: 0.821 \t f1: 0.5296816170812072\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.622790 seconds\n",
      "contamination: 0.065 \t tp: 69/support: 84/predicted: 2340 -> fp = 2271\n",
      "AUC : 87.8% \t precision: 0.0295 \t recall: 0.821 \t f1: 0.5115855284763494\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.587101 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 83/support: 84/predicted: 3067 -> fp = 2984\n",
      "AUC : 95.1% \t precision: 0.0271 \t recall: 0.988 \t f1: 0.5040604017025391\n",
      "--------------------\n",
      "Finished trainning in 0:00:13.202455 seconds\n",
      "contamination: 0.10499999999999998 \t tp: 83/support: 84/predicted: 3784 -> fp = 3701\n",
      "AUC : 94.1% \t precision: 0.0219 \t recall: 0.988 \t f1: 0.49352692730640796\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.927269 seconds\n",
      "contamination: 0.12499999999999997 \t tp: 83/support: 84/predicted: 4465 -> fp = 4382\n",
      "AUC : 93.1% \t precision: 0.0186 \t recall: 0.988 \t f1: 0.48483315338054067\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.935329 seconds\n",
      "contamination: 0.145 \t tp: 83/support: 84/predicted: 5125 -> fp = 5042\n",
      "AUC : 92.2% \t precision: 0.0162 \t recall: 0.988 \t f1: 0.4770992332895449\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.568600 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 84/support: 84/predicted: 5867 -> fp = 5783\n",
      "AUC : 91.7% \t precision: 0.0143 \t recall: 1.0 \t f1: 0.4690672120519182\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.883630 seconds\n",
      "contamination: 0.18499999999999997 \t tp: 84/support: 84/predicted: 6557 -> fp = 6473\n",
      "AUC : 90.7% \t precision: 0.0128 \t recall: 1.0 \t f1: 0.4616777854737274\n",
      "--------------------\n",
      "Finished trainning in 0:00:11.952677 seconds\n",
      "contamination: 0.20499999999999996 \t tp: 84/support: 84/predicted: 7293 -> fp = 7209\n",
      "AUC : 89.7% \t precision: 0.0115 \t recall: 1.0 \t f1: 0.45395457929216665\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.271663 seconds\n",
      "contamination: 0.22499999999999995 \t tp: 84/support: 84/predicted: 7969 -> fp = 7885\n",
      "AUC : 88.7% \t precision: 0.0105 \t recall: 1.0 \t f1: 0.4469292443561246\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.453137 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 84/support: 84/predicted: 8665 -> fp = 8581\n",
      "AUC : 87.7% \t precision: 0.00969 \t recall: 1.0 \t f1: 0.43971072602911215\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.501612 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 84/support: 84/predicted: 9402 -> fp = 9318\n",
      "AUC : 86.7% \t precision: 0.00893 \t recall: 1.0 \t f1: 0.4320398809429208\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.494027 seconds\n",
      "contamination: 0.285 \t tp: 84/support: 84/predicted: 10143 -> fp = 10059\n",
      "AUC : 85.6% \t precision: 0.00828 \t recall: 1.0 \t f1: 0.42426402723245504\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.316118 seconds\n",
      "contamination: 0.305 \t tp: 84/support: 84/predicted: 10852 -> fp = 10768\n",
      "AUC : 84.6% \t precision: 0.00774 \t recall: 1.0 \t f1: 0.41673817985004014\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.615961 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 84/support: 84/predicted: 11593 -> fp = 11509\n",
      "AUC : 83.6% \t precision: 0.00725 \t recall: 1.0 \t f1: 0.40876048503730755\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.503975 seconds\n",
      "contamination: 0.345 \t tp: 84/support: 84/predicted: 12293 -> fp = 12209\n",
      "AUC : 82.6% \t precision: 0.00683 \t recall: 1.0 \t f1: 0.4011012847994879\n",
      "--------------------\n",
      "Finished trainning in 0:00:12.111980 seconds\n",
      "contamination: 0.365 \t tp: 84/support: 84/predicted: 12977 -> fp = 12893\n",
      "AUC : 81.6% \t precision: 0.00647 \t recall: 1.0 \t f1: 0.3934874426736694\n",
      "--------------------\n",
      "Finished trainning in 0:00:13.983578 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 84/support: 84/predicted: 13645 -> fp = 13561\n",
      "AUC : 80.6% \t precision: 0.00616 \t recall: 1.0 \t f1: 0.3859159854649964\n",
      "--------------------\n",
      "Time for IF fitting: 240.192\n",
      "5 0.08499999999999999 0.5 200\n",
      "Finished trainning in 0:00:58.429449 seconds\n",
      "contamination: 0.020000000000000004 \t tp: 74/support: 87/predicted: 723 -> fp = 649\n",
      "AUC : 91.6% \t precision: 0.102 \t recall: 0.851 \t f1: 0.5865836189678408\n",
      "--------------------\n",
      "Finished trainning in 0:00:58.311631 seconds\n",
      "contamination: 0.04000000000000001 \t tp: 78/support: 87/predicted: 1417 -> fp = 1339\n",
      "AUC : 92.9% \t precision: 0.055 \t recall: 0.897 \t f1: 0.5420414963987206\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.604937 seconds\n",
      "contamination: 0.06000000000000001 \t tp: 78/support: 87/predicted: 2087 -> fp = 2009\n",
      "AUC : 92.0% \t precision: 0.0374 \t recall: 0.897 \t f1: 0.5210324698659395\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.529225 seconds\n",
      "contamination: 0.08000000000000002 \t tp: 79/support: 87/predicted: 2759 -> fp = 2680\n",
      "AUC : 91.6% \t precision: 0.0286 \t recall: 0.908 \t f1: 0.5077856007208951\n",
      "--------------------\n",
      "Finished trainning in 0:00:56.886869 seconds\n",
      "contamination: 0.10000000000000002 \t tp: 87/support: 87/predicted: 3421 -> fp = 3334\n",
      "AUC : 95.2% \t precision: 0.0254 \t recall: 1.0 \t f1: 0.4997816957821671\n",
      "--------------------\n",
      "Finished trainning in 0:00:58.596633 seconds\n",
      "contamination: 0.12000000000000002 \t tp: 87/support: 87/predicted: 4140 -> fp = 4053\n",
      "AUC : 94.2% \t precision: 0.021 \t recall: 1.0 \t f1: 0.4898359670527602\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.829620 seconds\n",
      "contamination: 0.14 \t tp: 87/support: 87/predicted: 4841 -> fp = 4754\n",
      "AUC : 93.2% \t precision: 0.018 \t recall: 1.0 \t f1: 0.4812027562799108\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.469374 seconds\n",
      "contamination: 0.16000000000000003 \t tp: 87/support: 87/predicted: 5524 -> fp = 5437\n",
      "AUC : 92.2% \t precision: 0.0157 \t recall: 1.0 \t f1: 0.47337560637607146\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.396560 seconds\n",
      "contamination: 0.18000000000000005 \t tp: 87/support: 87/predicted: 6297 -> fp = 6210\n",
      "AUC : 91.1% \t precision: 0.0138 \t recall: 1.0 \t f1: 0.4649249930595538\n",
      "--------------------\n",
      "Finished trainning in 0:00:59.009831 seconds\n",
      "contamination: 0.20000000000000007 \t tp: 87/support: 87/predicted: 7003 -> fp = 6916\n",
      "AUC : 90.1% \t precision: 0.0124 \t recall: 1.0 \t f1: 0.45742370332747573\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.508794 seconds\n",
      "contamination: 0.22000000000000003 \t tp: 87/support: 87/predicted: 7667 -> fp = 7580\n",
      "AUC : 89.2% \t precision: 0.0113 \t recall: 1.0 \t f1: 0.4504672583586739\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.604062 seconds\n",
      "contamination: 0.24000000000000005 \t tp: 87/support: 87/predicted: 8318 -> fp = 8231\n",
      "AUC : 88.2% \t precision: 0.0105 \t recall: 1.0 \t f1: 0.4436848548516485\n",
      "--------------------\n",
      "Finished trainning in 0:00:58.071809 seconds\n",
      "contamination: 0.26000000000000006 \t tp: 87/support: 87/predicted: 9073 -> fp = 8986\n",
      "AUC : 87.2% \t precision: 0.00959 \t recall: 1.0 \t f1: 0.4358155049405033\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.596207 seconds\n",
      "contamination: 0.2800000000000001 \t tp: 87/support: 87/predicted: 9761 -> fp = 9674\n",
      "AUC : 86.2% \t precision: 0.00891 \t recall: 1.0 \t f1: 0.4286053873917549\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.765556 seconds\n",
      "contamination: 0.30000000000000004 \t tp: 87/support: 87/predicted: 10406 -> fp = 10319\n",
      "AUC : 85.3% \t precision: 0.00836 \t recall: 1.0 \t f1: 0.4217877628633093\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.580942 seconds\n",
      "contamination: 0.32000000000000006 \t tp: 87/support: 87/predicted: 11111 -> fp = 11024\n",
      "AUC : 84.2% \t precision: 0.00783 \t recall: 1.0 \t f1: 0.4142504117967161\n",
      "--------------------\n",
      "Finished trainning in 0:00:56.839890 seconds\n",
      "contamination: 0.3400000000000001 \t tp: 87/support: 87/predicted: 11804 -> fp = 11717\n",
      "AUC : 83.3% \t precision: 0.00737 \t recall: 1.0 \t f1: 0.40673617042847016\n",
      "--------------------\n",
      "Finished trainning in 0:00:57.999154 seconds\n",
      "contamination: 0.3600000000000001 \t tp: 87/support: 87/predicted: 12517 -> fp = 12430\n",
      "AUC : 82.2% \t precision: 0.00695 \t recall: 1.0 \t f1: 0.39887948860881917\n",
      "--------------------\n",
      "Finished trainning in 0:00:58.054516 seconds\n",
      "contamination: 0.3800000000000001 \t tp: 87/support: 87/predicted: 13216 -> fp = 13129\n",
      "AUC : 81.2% \t precision: 0.00658 \t recall: 1.0 \t f1: 0.3910388665224206\n",
      "--------------------\n",
      "Time for IF fitting: 1098.964\n",
      "6 0.10000000000000002 0.25 1000\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.2\n",
    "\n",
    "dfsf_frac = dfsf_normal.sample(frac = frac_normal, random_state = 1).append(dfsf_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsf_frac.loc[dfsf_frac[\"target\"]=='normal.'])/len(dfsf_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsf_frac)} records\")\n",
    "\n",
    "dfsf_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsf_frac[\"target\"]]\n",
    "toDecode = toDecodeSF\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsf_frac[f] = leSF.fit_transform(dfsf_frac[f])\n",
    "        \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),(2, 0.25, 200),(3, 0.25, 500),(4, 0.5, 100),(5, 0.5, 200),(6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsf_frac.drop([\"target\", \"binary_target\"], axis=1), dfsf_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    \n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False)\n",
    "    \n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.01        97\n",
      "           1       1.00      0.62      0.76     34972\n",
      "\n",
      "    accuracy                           0.62     35069\n",
      "   macro avg       0.50      0.81      0.39     35069\n",
      "weighted avg       1.00      0.62      0.76     35069\n",
      "\n",
      "---0.7614688313432894, 0.3889187332151719\n",
      "---0.8087612947500857\n",
      "---0.8087612947500857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.01        70\n",
      "           1       1.00      0.63      0.77     34999\n",
      "\n",
      "    accuracy                           0.63     35069\n",
      "   macro avg       0.50      0.81      0.39     35069\n",
      "weighted avg       1.00      0.63      0.77     35069\n",
      "\n",
      "---0.7688951106828538, 0.39050488998361316\n",
      "---0.8132803794394126\n",
      "---0.8132803794394126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.01        76\n",
      "           1       1.00      0.61      0.76     34993\n",
      "\n",
      "    accuracy                           0.61     35069\n",
      "   macro avg       0.50      0.80      0.38     35069\n",
      "weighted avg       1.00      0.61      0.76     35069\n",
      "\n",
      "---0.7556012717054842, 0.3841069120204304\n",
      "---0.8046466436144372\n",
      "---0.8046466436144372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.01        81\n",
      "           1       1.00      0.61      0.76     34988\n",
      "\n",
      "    accuracy                           0.61     35069\n",
      "   macro avg       0.50      0.80      0.38     35069\n",
      "weighted avg       1.00      0.61      0.76     35069\n",
      "\n",
      "---0.7554535092290258, 0.3844428064621872\n",
      "---0.804618726420487\n",
      "---0.804618726420487\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.01        84\n",
      "           1       1.00      0.61      0.76     34985\n",
      "\n",
      "    accuracy                           0.61     35069\n",
      "   macro avg       0.50      0.81      0.39     35069\n",
      "weighted avg       1.00      0.61      0.76     35069\n",
      "\n",
      "---0.7578049694372478, 0.3859159854649964\n",
      "---0.8061883664427612\n",
      "---0.8061883664427612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.01      1.00      0.01        87\n",
      "           1       1.00      0.62      0.77     34982\n",
      "\n",
      "    accuracy                           0.63     35069\n",
      "   macro avg       0.50      0.81      0.39     35069\n",
      "weighted avg       1.00      0.63      0.77     35069\n",
      "\n",
      "---0.767122676899668, 0.3910388665224206\n",
      "---0.8123463495511978\n",
      "---0.8123463495511978\n",
      "0.8083069600363969 \\pm 0.003814378339180022\n",
      "0.7610577282162615 \\pm 0.005833314667089402\n",
      "0.8083069600363969 \\pm 0.003814378339180022\n"
     ]
    }
   ],
   "source": [
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 0.1% out of 350182 records\n",
      "Finished trainning in 0:00:14.700027 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 79/support: 93/predicted: 3935 -> fp = 3856\n",
      "AUC : 90.3% \t precision: 0.0201 \t recall: 0.849 \t f1: 0.5083011551139405\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.634352 seconds\n",
      "contamination: 0.065 \t tp: 79/support: 93/predicted: 5626 -> fp = 5547\n",
      "AUC : 89.3% \t precision: 0.014 \t recall: 0.849 \t f1: 0.49739717376737846\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.563358 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 92/support: 93/predicted: 7368 -> fp = 7276\n",
      "AUC : 95.3% \t precision: 0.0125 \t recall: 0.989 \t f1: 0.4906253742744361\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.913528 seconds\n",
      "contamination: 0.105 \t tp: 93/support: 93/predicted: 9157 -> fp = 9064\n",
      "AUC : 94.8% \t precision: 0.0102 \t recall: 1.0 \t f1: 0.48272683899393665\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.821801 seconds\n",
      "contamination: 0.125 \t tp: 93/support: 93/predicted: 10894 -> fp = 10801\n",
      "AUC : 93.8% \t precision: 0.00854 \t recall: 1.0 \t f1: 0.4755557406275938\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.369323 seconds\n",
      "contamination: 0.145 \t tp: 93/support: 93/predicted: 12755 -> fp = 12662\n",
      "AUC : 92.8% \t precision: 0.00729 \t recall: 1.0 \t f1: 0.4682170068678441\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.556380 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 93/support: 93/predicted: 14495 -> fp = 14402\n",
      "AUC : 91.8% \t precision: 0.00642 \t recall: 1.0 \t f1: 0.46151017733951594\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.741460 seconds\n",
      "contamination: 0.185 \t tp: 93/support: 93/predicted: 16179 -> fp = 16086\n",
      "AUC : 90.8% \t precision: 0.00575 \t recall: 1.0 \t f1: 0.45507310273889406\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.999390 seconds\n",
      "contamination: 0.205 \t tp: 93/support: 93/predicted: 17998 -> fp = 17905\n",
      "AUC : 89.8% \t precision: 0.00517 \t recall: 1.0 \t f1: 0.4481187478884112\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.155315 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 93/support: 93/predicted: 19784 -> fp = 19691\n",
      "AUC : 88.7% \t precision: 0.0047 \t recall: 1.0 \t f1: 0.44124740507210214\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.482846 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 93/support: 93/predicted: 21540 -> fp = 21447\n",
      "AUC : 87.7% \t precision: 0.00432 \t recall: 1.0 \t f1: 0.43442038816211437\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.735685 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 93/support: 93/predicted: 23285 -> fp = 23192\n",
      "AUC : 86.7% \t precision: 0.00399 \t recall: 1.0 \t f1: 0.4275448101159194\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.122878 seconds\n",
      "contamination: 0.285 \t tp: 93/support: 93/predicted: 25078 -> fp = 24985\n",
      "AUC : 85.7% \t precision: 0.00371 \t recall: 1.0 \t f1: 0.4203675090580615\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.877522 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 93/support: 93/predicted: 26820 -> fp = 26727\n",
      "AUC : 84.7% \t precision: 0.00347 \t recall: 1.0 \t f1: 0.4132707350819373\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.604803 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 93/support: 93/predicted: 28556 -> fp = 28463\n",
      "AUC : 83.7% \t precision: 0.00326 \t recall: 1.0 \t f1: 0.40606503079531\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.828256 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 93/support: 93/predicted: 30225 -> fp = 30132\n",
      "AUC : 82.8% \t precision: 0.00308 \t recall: 1.0 \t f1: 0.39900183751598955\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.656508 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 93/support: 93/predicted: 31950 -> fp = 31857\n",
      "AUC : 81.8% \t precision: 0.00291 \t recall: 1.0 \t f1: 0.39155239295949296\n",
      "--------------------\n",
      "Finished trainning in 0:00:14.616301 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 93/support: 93/predicted: 33766 -> fp = 33673\n",
      "AUC : 80.7% \t precision: 0.00275 \t recall: 1.0 \t f1: 0.3835358771085758\n",
      "--------------------\n",
      "Time for IF fitting: 268.301\n",
      "1 0.08499999999999999 0.25 100\n",
      "Finished trainning in 0:00:30.467966 seconds\n",
      "contamination: 0.04 \t tp: 69/support: 87/predicted: 3667 -> fp = 3598\n",
      "AUC : 87.6% \t precision: 0.0188 \t recall: 0.793 \t f1: 0.5078281524784034\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.484703 seconds\n",
      "contamination: 0.06 \t tp: 69/support: 87/predicted: 5466 -> fp = 5397\n",
      "AUC : 86.6% \t precision: 0.0126 \t recall: 0.793 \t f1: 0.4964559389637815\n",
      "--------------------\n",
      "Finished trainning in 0:00:28.975451 seconds\n",
      "contamination: 0.07999999999999999 \t tp: 69/support: 87/predicted: 7194 -> fp = 7125\n",
      "AUC : 85.6% \t precision: 0.00959 \t recall: 0.793 \t f1: 0.48819384842853153\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.335962 seconds\n",
      "contamination: 0.09999999999999999 \t tp: 86/support: 87/predicted: 8938 -> fp = 8852\n",
      "AUC : 94.4% \t precision: 0.00962 \t recall: 0.989 \t f1: 0.48287418152673983\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.355413 seconds\n",
      "contamination: 0.12 \t tp: 87/support: 87/predicted: 10674 -> fp = 10587\n",
      "AUC : 93.9% \t precision: 0.00815 \t recall: 1.0 \t f1: 0.47587232556500375\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.216763 seconds\n",
      "contamination: 0.13999999999999999 \t tp: 87/support: 87/predicted: 12292 -> fp = 12205\n",
      "AUC : 93.0% \t precision: 0.00708 \t recall: 1.0 \t f1: 0.46952334517819294\n",
      "--------------------\n",
      "Finished trainning in 0:00:30.153509 seconds\n",
      "contamination: 0.15999999999999998 \t tp: 87/support: 87/predicted: 14104 -> fp = 14017\n",
      "AUC : 92.0% \t precision: 0.00617 \t recall: 1.0 \t f1: 0.46257280627021685\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.040837 seconds\n",
      "contamination: 0.18 \t tp: 87/support: 87/predicted: 15803 -> fp = 15716\n",
      "AUC : 91.0% \t precision: 0.00551 \t recall: 1.0 \t f1: 0.4561164651999519\n",
      "--------------------\n",
      "Finished trainning in 0:00:28.613058 seconds\n",
      "contamination: 0.19999999999999998 \t tp: 87/support: 87/predicted: 17427 -> fp = 17340\n",
      "AUC : 90.1% \t precision: 0.00499 \t recall: 1.0 \t f1: 0.4499470837437893\n",
      "--------------------\n",
      "Finished trainning in 0:00:28.566805 seconds\n",
      "contamination: 0.21999999999999997 \t tp: 87/support: 87/predicted: 19209 -> fp = 19122\n",
      "AUC : 89.1% \t precision: 0.00453 \t recall: 1.0 \t f1: 0.44313999353536565\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.013935 seconds\n",
      "contamination: 0.23999999999999996 \t tp: 87/support: 87/predicted: 20912 -> fp = 20825\n",
      "AUC : 88.1% \t precision: 0.00416 \t recall: 1.0 \t f1: 0.43657022503592796\n",
      "--------------------\n",
      "Finished trainning in 0:00:28.871569 seconds\n",
      "contamination: 0.25999999999999995 \t tp: 87/support: 87/predicted: 22603 -> fp = 22516\n",
      "AUC : 87.1% \t precision: 0.00385 \t recall: 1.0 \t f1: 0.4299638665846918\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.109478 seconds\n",
      "contamination: 0.27999999999999997 \t tp: 87/support: 87/predicted: 24349 -> fp = 24262\n",
      "AUC : 86.1% \t precision: 0.00357 \t recall: 1.0 \t f1: 0.423039133497411\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.756319 seconds\n",
      "contamination: 0.29999999999999993 \t tp: 87/support: 87/predicted: 26167 -> fp = 26080\n",
      "AUC : 85.1% \t precision: 0.00332 \t recall: 1.0 \t f1: 0.4157017461961515\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.244532 seconds\n",
      "contamination: 0.31999999999999995 \t tp: 87/support: 87/predicted: 27933 -> fp = 27846\n",
      "AUC : 84.1% \t precision: 0.00311 \t recall: 1.0 \t f1: 0.40843700729896404\n",
      "--------------------\n",
      "Finished trainning in 0:00:35.151835 seconds\n",
      "contamination: 0.3399999999999999 \t tp: 87/support: 87/predicted: 29616 -> fp = 29529\n",
      "AUC : 83.1% \t precision: 0.00294 \t recall: 1.0 \t f1: 0.40137729783653536\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.291372 seconds\n",
      "contamination: 0.35999999999999993 \t tp: 87/support: 87/predicted: 31366 -> fp = 31279\n",
      "AUC : 82.1% \t precision: 0.00277 \t recall: 1.0 \t f1: 0.39388543536167575\n",
      "--------------------\n",
      "Finished trainning in 0:00:29.462486 seconds\n",
      "contamination: 0.37999999999999995 \t tp: 87/support: 87/predicted: 33147 -> fp = 33060\n",
      "AUC : 81.1% \t precision: 0.00262 \t recall: 1.0 \t f1: 0.3860928253672151\n",
      "--------------------\n",
      "Time for IF fitting: 535.192\n",
      "2 0.09999999999999999 0.25 200\n",
      "Finished trainning in 0:01:14.981597 seconds\n",
      "contamination: 0.035 \t tp: 70/support: 84/predicted: 3031 -> fp = 2961\n",
      "AUC : 90.0% \t precision: 0.0231 \t recall: 0.833 \t f1: 0.5138224976909311\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:01:15.004228 seconds\n",
      "contamination: 0.05500000000000001 \t tp: 70/support: 84/predicted: 4895 -> fp = 4825\n",
      "AUC : 88.9% \t precision: 0.0143 \t recall: 0.833 \t f1: 0.49983614910499097\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.015099 seconds\n",
      "contamination: 0.07500000000000001 \t tp: 70/support: 84/predicted: 6615 -> fp = 6545\n",
      "AUC : 87.9% \t precision: 0.0106 \t recall: 0.833 \t f1: 0.49097404569363945\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.184343 seconds\n",
      "contamination: 0.09500000000000001 \t tp: 83/support: 84/predicted: 8445 -> fp = 8362\n",
      "AUC : 94.6% \t precision: 0.00983 \t recall: 0.988 \t f1: 0.48462688920894303\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.017868 seconds\n",
      "contamination: 0.11500000000000002 \t tp: 83/support: 84/predicted: 10210 -> fp = 10127\n",
      "AUC : 93.6% \t precision: 0.00813 \t recall: 0.988 \t f1: 0.4773344210320109\n",
      "--------------------\n",
      "Finished trainning in 0:01:17.497367 seconds\n",
      "contamination: 0.135 \t tp: 84/support: 84/predicted: 12043 -> fp = 11959\n",
      "AUC : 93.2% \t precision: 0.00698 \t recall: 1.0 \t f1: 0.47023476478978926\n",
      "--------------------\n",
      "Finished trainning in 0:01:16.705354 seconds\n",
      "contamination: 0.15500000000000003 \t tp: 84/support: 84/predicted: 13697 -> fp = 13613\n",
      "AUC : 92.2% \t precision: 0.00613 \t recall: 1.0 \t f1: 0.4639004580534334\n",
      "--------------------\n",
      "Finished trainning in 0:01:19.481015 seconds\n",
      "contamination: 0.17500000000000002 \t tp: 84/support: 84/predicted: 15515 -> fp = 15431\n",
      "AUC : 91.2% \t precision: 0.00541 \t recall: 1.0 \t f1: 0.45700979677410364\n",
      "--------------------\n",
      "Finished trainning in 0:01:17.154562 seconds\n",
      "contamination: 0.19500000000000003 \t tp: 84/support: 84/predicted: 17254 -> fp = 17170\n",
      "AUC : 90.2% \t precision: 0.00487 \t recall: 1.0 \t f1: 0.4504246762825773\n",
      "--------------------\n",
      "Finished trainning in 0:01:17.055359 seconds\n",
      "contamination: 0.21500000000000005 \t tp: 84/support: 84/predicted: 18994 -> fp = 18910\n",
      "AUC : 89.2% \t precision: 0.00442 \t recall: 1.0 \t f1: 0.44379944167114393\n",
      "--------------------\n",
      "Finished trainning in 0:01:16.918786 seconds\n",
      "contamination: 0.23500000000000004 \t tp: 84/support: 84/predicted: 20775 -> fp = 20691\n",
      "AUC : 88.2% \t precision: 0.00404 \t recall: 1.0 \t f1: 0.43694995401774017\n",
      "--------------------\n",
      "Finished trainning in 0:01:16.863384 seconds\n",
      "contamination: 0.255 \t tp: 84/support: 84/predicted: 22508 -> fp = 22424\n",
      "AUC : 87.2% \t precision: 0.00373 \t recall: 1.0 \t f1: 0.43019681883620486\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.918090 seconds\n",
      "contamination: 0.275 \t tp: 84/support: 84/predicted: 24309 -> fp = 24225\n",
      "AUC : 86.2% \t precision: 0.00346 \t recall: 1.0 \t f1: 0.4230681604708408\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.862959 seconds\n",
      "contamination: 0.29500000000000004 \t tp: 84/support: 84/predicted: 26094 -> fp = 26010\n",
      "AUC : 85.1% \t precision: 0.00322 \t recall: 1.0 \t f1: 0.41587651553469906\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.422238 seconds\n",
      "contamination: 0.31500000000000006 \t tp: 84/support: 84/predicted: 27842 -> fp = 27758\n",
      "AUC : 84.1% \t precision: 0.00302 \t recall: 1.0 \t f1: 0.40869948159250563\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.070125 seconds\n",
      "contamination: 0.3350000000000001 \t tp: 84/support: 84/predicted: 29611 -> fp = 29527\n",
      "AUC : 83.1% \t precision: 0.00284 \t recall: 1.0 \t f1: 0.40128952509091\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.262349 seconds\n",
      "contamination: 0.3550000000000001 \t tp: 84/support: 84/predicted: 31323 -> fp = 31239\n",
      "AUC : 82.1% \t precision: 0.00268 \t recall: 1.0 \t f1: 0.3939680174270796\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.535715 seconds\n",
      "contamination: 0.3750000000000001 \t tp: 84/support: 84/predicted: 33026 -> fp = 32942\n",
      "AUC : 81.2% \t precision: 0.00254 \t recall: 1.0 \t f1: 0.38652933494264513\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.578015 seconds\n",
      "contamination: 0.39500000000000013 \t tp: 84/support: 84/predicted: 34718 -> fp = 34634\n",
      "AUC : 80.2% \t precision: 0.00242 \t recall: 1.0 \t f1: 0.3789764885169824\n",
      "--------------------\n",
      "Time for IF fitting: 1442.642\n",
      "3 0.09500000000000001 0.25 500\n",
      "Finished trainning in 0:00:16.077404 seconds\n",
      "contamination: 0.030000000000000002 \t tp: 55/support: 69/predicted: 2628 -> fp = 2573\n",
      "AUC : 88.4% \t precision: 0.0209 \t recall: 0.797 \t f1: 0.5128899114519612\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.395590 seconds\n",
      "contamination: 0.05 \t tp: 55/support: 69/predicted: 4359 -> fp = 4304\n",
      "AUC : 87.4% \t precision: 0.0126 \t recall: 0.797 \t f1: 0.49977036925246676\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.731659 seconds\n",
      "contamination: 0.07 \t tp: 67/support: 69/predicted: 5940 -> fp = 5873\n",
      "AUC : 95.2% \t precision: 0.0113 \t recall: 0.971 \t f1: 0.4937768173121934\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.078303 seconds\n",
      "contamination: 0.09 \t tp: 68/support: 69/predicted: 7726 -> fp = 7658\n",
      "AUC : 94.9% \t precision: 0.0088 \t recall: 0.986 \t f1: 0.48583311233144605\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.267869 seconds\n",
      "contamination: 0.11 \t tp: 68/support: 69/predicted: 9533 -> fp = 9465\n",
      "AUC : 93.9% \t precision: 0.00713 \t recall: 0.986 \t f1: 0.47848194254351784\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.565027 seconds\n",
      "contamination: 0.13 \t tp: 68/support: 69/predicted: 11249 -> fp = 11181\n",
      "AUC : 92.9% \t precision: 0.00604 \t recall: 0.986 \t f1: 0.471869620700763\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.466984 seconds\n",
      "contamination: 0.15 \t tp: 68/support: 69/predicted: 12939 -> fp = 12871\n",
      "AUC : 91.9% \t precision: 0.00526 \t recall: 0.986 \t f1: 0.46551974644644645\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.920264 seconds\n",
      "contamination: 0.17 \t tp: 68/support: 69/predicted: 14641 -> fp = 14573\n",
      "AUC : 90.9% \t precision: 0.00464 \t recall: 0.986 \t f1: 0.4591874323573882\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.651205 seconds\n",
      "contamination: 0.19 \t tp: 68/support: 69/predicted: 16509 -> fp = 16441\n",
      "AUC : 89.9% \t precision: 0.00412 \t recall: 0.986 \t f1: 0.4522388947574996\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.681803 seconds\n",
      "contamination: 0.21 \t tp: 68/support: 69/predicted: 18215 -> fp = 18147\n",
      "AUC : 88.9% \t precision: 0.00373 \t recall: 0.986 \t f1: 0.44585215310149806\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.940401 seconds\n",
      "contamination: 0.23 \t tp: 69/support: 69/predicted: 20041 -> fp = 19972\n",
      "AUC : 88.6% \t precision: 0.00344 \t recall: 1.0 \t f1: 0.4389978397645331\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.734776 seconds\n",
      "contamination: 0.25 \t tp: 69/support: 69/predicted: 21747 -> fp = 21678\n",
      "AUC : 87.6% \t precision: 0.00317 \t recall: 1.0 \t f1: 0.4324472443721316\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.949927 seconds\n",
      "contamination: 0.27 \t tp: 69/support: 69/predicted: 23486 -> fp = 23417\n",
      "AUC : 86.6% \t precision: 0.00294 \t recall: 1.0 \t f1: 0.42566435597762214\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.990864 seconds\n",
      "contamination: 0.29000000000000004 \t tp: 69/support: 69/predicted: 25184 -> fp = 25115\n",
      "AUC : 85.6% \t precision: 0.00274 \t recall: 1.0 \t f1: 0.4189257295273402\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.442699 seconds\n",
      "contamination: 0.31000000000000005 \t tp: 69/support: 69/predicted: 26905 -> fp = 26836\n",
      "AUC : 84.7% \t precision: 0.00256 \t recall: 1.0 \t f1: 0.4119680837811672\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.763230 seconds\n",
      "contamination: 0.33 \t tp: 69/support: 69/predicted: 28643 -> fp = 28574\n",
      "AUC : 83.7% \t precision: 0.00241 \t recall: 1.0 \t f1: 0.4048010449335274\n",
      "--------------------\n",
      "Finished trainning in 0:00:18.134677 seconds\n",
      "contamination: 0.35000000000000003 \t tp: 69/support: 69/predicted: 30503 -> fp = 30434\n",
      "AUC : 82.6% \t precision: 0.00226 \t recall: 1.0 \t f1: 0.3969635821608763\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.665159 seconds\n",
      "contamination: 0.37000000000000005 \t tp: 69/support: 69/predicted: 32262 -> fp = 32193\n",
      "AUC : 81.6% \t precision: 0.00214 \t recall: 1.0 \t f1: 0.38938279295128836\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.951246 seconds\n",
      "contamination: 0.39 \t tp: 69/support: 69/predicted: 33989 -> fp = 33920\n",
      "AUC : 80.6% \t precision: 0.00203 \t recall: 1.0 \t f1: 0.3817712653642376\n",
      "--------------------\n",
      "Time for IF fitting: 306.547\n",
      "4 0.07 0.5 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:00:32.490890 seconds\n",
      "contamination: 0.025 \t tp: 63/support: 73/predicted: 2211 -> fp = 2148\n",
      "AUC : 91.9% \t precision: 0.0285 \t recall: 0.863 \t f1: 0.5213392634981305\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.271574 seconds\n",
      "contamination: 0.045 \t tp: 63/support: 73/predicted: 3967 -> fp = 3904\n",
      "AUC : 90.9% \t precision: 0.0159 \t recall: 0.863 \t f1: 0.5041530940854533\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.553663 seconds\n",
      "contamination: 0.065 \t tp: 64/support: 73/predicted: 5746 -> fp = 5682\n",
      "AUC : 90.6% \t precision: 0.0111 \t recall: 0.877 \t f1: 0.49418833005053836\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.092253 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 73/support: 73/predicted: 7372 -> fp = 7299\n",
      "AUC : 95.8% \t precision: 0.0099 \t recall: 1.0 \t f1: 0.4880362834083927\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.830387 seconds\n",
      "contamination: 0.10499999999999998 \t tp: 73/support: 73/predicted: 9116 -> fp = 9043\n",
      "AUC : 94.8% \t precision: 0.00801 \t recall: 1.0 \t f1: 0.4806904039401584\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.505106 seconds\n",
      "contamination: 0.12499999999999997 \t tp: 73/support: 73/predicted: 10950 -> fp = 10877\n",
      "AUC : 93.8% \t precision: 0.00667 \t recall: 1.0 \t f1: 0.4734748774532311\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.957800 seconds\n",
      "contamination: 0.145 \t tp: 73/support: 73/predicted: 12643 -> fp = 12570\n",
      "AUC : 92.8% \t precision: 0.00577 \t recall: 1.0 \t f1: 0.4670343399107711\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.961097 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 73/support: 73/predicted: 14435 -> fp = 14362\n",
      "AUC : 91.8% \t precision: 0.00506 \t recall: 1.0 \t f1: 0.46031367745116597\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.620040 seconds\n",
      "contamination: 0.18499999999999997 \t tp: 73/support: 73/predicted: 16146 -> fp = 16073\n",
      "AUC : 90.8% \t precision: 0.00452 \t recall: 1.0 \t f1: 0.4539164649409166\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.339981 seconds\n",
      "contamination: 0.20499999999999996 \t tp: 73/support: 73/predicted: 17980 -> fp = 17907\n",
      "AUC : 89.8% \t precision: 0.00406 \t recall: 1.0 \t f1: 0.44702914967206525\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.616920 seconds\n",
      "contamination: 0.22499999999999995 \t tp: 73/support: 73/predicted: 19730 -> fp = 19657\n",
      "AUC : 88.8% \t precision: 0.0037 \t recall: 1.0 \t f1: 0.440394641073508\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.662781 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 73/support: 73/predicted: 21504 -> fp = 21431\n",
      "AUC : 87.7% \t precision: 0.00339 \t recall: 1.0 \t f1: 0.4335822355000609\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.213583 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 73/support: 73/predicted: 23321 -> fp = 23248\n",
      "AUC : 86.7% \t precision: 0.00313 \t recall: 1.0 \t f1: 0.4264945304068604\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.105581 seconds\n",
      "contamination: 0.285 \t tp: 73/support: 73/predicted: 25087 -> fp = 25014\n",
      "AUC : 85.7% \t precision: 0.00291 \t recall: 1.0 \t f1: 0.4194836147659859\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.401725 seconds\n",
      "contamination: 0.305 \t tp: 73/support: 73/predicted: 26853 -> fp = 26780\n",
      "AUC : 84.7% \t precision: 0.00272 \t recall: 1.0 \t f1: 0.4123395239987449\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.930025 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 73/support: 73/predicted: 28560 -> fp = 28487\n",
      "AUC : 83.7% \t precision: 0.00256 \t recall: 1.0 \t f1: 0.40529703242651194\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.803227 seconds\n",
      "contamination: 0.345 \t tp: 73/support: 73/predicted: 30371 -> fp = 30298\n",
      "AUC : 82.7% \t precision: 0.0024 \t recall: 1.0 \t f1: 0.39766774180053466\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.840116 seconds\n",
      "contamination: 0.365 \t tp: 73/support: 73/predicted: 32065 -> fp = 31992\n",
      "AUC : 81.7% \t precision: 0.00228 \t recall: 1.0 \t f1: 0.39037531993223956\n",
      "--------------------\n",
      "Finished trainning in 0:00:31.562526 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 73/support: 73/predicted: 33807 -> fp = 33734\n",
      "AUC : 80.7% \t precision: 0.00216 \t recall: 1.0 \t f1: 0.3827101403899539\n",
      "--------------------\n",
      "Time for IF fitting: 608.852\n",
      "5 0.08499999999999999 0.5 200\n",
      "Finished trainning in 0:02:28.120871 seconds\n",
      "contamination: 0.020000000000000004 \t tp: 60/support: 73/predicted: 1703 -> fp = 1643\n",
      "AUC : 90.2% \t precision: 0.0352 \t recall: 0.822 \t f1: 0.529006382966779\n",
      "--------------------\n",
      "Finished trainning in 0:02:27.214826 seconds\n",
      "contamination: 0.04000000000000001 \t tp: 60/support: 73/predicted: 3521 -> fp = 3461\n",
      "AUC : 89.1% \t precision: 0.017 \t recall: 0.822 \t f1: 0.5065660928192196\n",
      "--------------------\n",
      "Finished trainning in 0:02:24.276052 seconds\n",
      "contamination: 0.06000000000000001 \t tp: 60/support: 73/predicted: 5226 -> fp = 5166\n",
      "AUC : 88.1% \t precision: 0.0115 \t recall: 0.822 \t f1: 0.4960719679285959\n",
      "--------------------\n",
      "Finished trainning in 0:02:27.566435 seconds\n",
      "contamination: 0.08000000000000002 \t tp: 60/support: 73/predicted: 6960 -> fp = 6900\n",
      "AUC : 87.2% \t precision: 0.00862 \t recall: 0.822 \t f1: 0.4879640282464058\n",
      "--------------------\n",
      "Finished trainning in 0:02:26.911617 seconds\n",
      "contamination: 0.10000000000000002 \t tp: 72/support: 73/predicted: 8713 -> fp = 8641\n",
      "AUC : 94.4% \t precision: 0.00826 \t recall: 0.986 \t f1: 0.48221262991579517\n",
      "--------------------\n",
      "Finished trainning in 0:02:29.607904 seconds\n",
      "contamination: 0.12000000000000002 \t tp: 72/support: 73/predicted: 10426 -> fp = 10354\n",
      "AUC : 93.4% \t precision: 0.00691 \t recall: 0.986 \t f1: 0.47540141569708244\n",
      "--------------------\n",
      "Finished trainning in 0:02:28.526221 seconds\n",
      "contamination: 0.14 \t tp: 73/support: 73/predicted: 12221 -> fp = 12148\n",
      "AUC : 93.1% \t precision: 0.00597 \t recall: 1.0 \t f1: 0.46862781520075913\n",
      "--------------------\n",
      "Finished trainning in 0:02:30.801131 seconds\n",
      "contamination: 0.16000000000000003 \t tp: 73/support: 73/predicted: 13975 -> fp = 13902\n",
      "AUC : 92.1% \t precision: 0.00522 \t recall: 1.0 \t f1: 0.46203435206292615\n",
      "--------------------\n",
      "Finished trainning in 0:02:32.092717 seconds\n",
      "contamination: 0.18000000000000005 \t tp: 73/support: 73/predicted: 15711 -> fp = 15638\n",
      "AUC : 91.1% \t precision: 0.00465 \t recall: 1.0 \t f1: 0.4555439112096971\n",
      "--------------------\n",
      "Finished trainning in 0:02:31.916832 seconds\n",
      "contamination: 0.20000000000000007 \t tp: 73/support: 73/predicted: 17443 -> fp = 17370\n",
      "AUC : 90.1% \t precision: 0.00419 \t recall: 1.0 \t f1: 0.4490513568180683\n",
      "--------------------\n",
      "Finished trainning in 0:02:32.204492 seconds\n",
      "contamination: 0.22000000000000003 \t tp: 73/support: 73/predicted: 19236 -> fp = 19163\n",
      "AUC : 89.0% \t precision: 0.00379 \t recall: 1.0 \t f1: 0.4422751930145888\n",
      "--------------------\n",
      "Finished trainning in 0:02:34.223493 seconds\n",
      "contamination: 0.24000000000000005 \t tp: 73/support: 73/predicted: 21014 -> fp = 20941\n",
      "AUC : 88.0% \t precision: 0.00347 \t recall: 1.0 \t f1: 0.43547379619630794\n",
      "--------------------\n",
      "Finished trainning in 0:02:34.789539 seconds\n",
      "contamination: 0.26000000000000006 \t tp: 73/support: 73/predicted: 22731 -> fp = 22658\n",
      "AUC : 87.0% \t precision: 0.00321 \t recall: 1.0 \t f1: 0.4288092511888313\n",
      "--------------------\n",
      "Finished trainning in 0:02:33.859520 seconds\n",
      "contamination: 0.2800000000000001 \t tp: 73/support: 73/predicted: 24483 -> fp = 24410\n",
      "AUC : 86.0% \t precision: 0.00298 \t recall: 1.0 \t f1: 0.42189584517983636\n",
      "--------------------\n",
      "Finished trainning in 0:02:29.918070 seconds\n",
      "contamination: 0.30000000000000004 \t tp: 73/support: 73/predicted: 26207 -> fp = 26134\n",
      "AUC : 85.1% \t precision: 0.00279 \t recall: 1.0 \t f1: 0.41496899891585803\n",
      "--------------------\n",
      "Finished trainning in 0:02:33.826863 seconds\n",
      "contamination: 0.32000000000000006 \t tp: 73/support: 73/predicted: 27893 -> fp = 27820\n",
      "AUC : 84.1% \t precision: 0.00262 \t recall: 1.0 \t f1: 0.4080655005924381\n",
      "--------------------\n",
      "Finished trainning in 0:02:37.082568 seconds\n",
      "contamination: 0.3400000000000001 \t tp: 73/support: 73/predicted: 29726 -> fp = 29653\n",
      "AUC : 83.1% \t precision: 0.00246 \t recall: 1.0 \t f1: 0.40040422482813554\n",
      "--------------------\n",
      "Finished trainning in 0:02:42.978981 seconds\n",
      "contamination: 0.3600000000000001 \t tp: 73/support: 73/predicted: 31465 -> fp = 31392\n",
      "AUC : 82.1% \t precision: 0.00232 \t recall: 1.0 \t f1: 0.3929760219351317\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:02:34.649594 seconds\n",
      "contamination: 0.3800000000000001 \t tp: 73/support: 73/predicted: 33195 -> fp = 33122\n",
      "AUC : 81.1% \t precision: 0.0022 \t recall: 1.0 \t f1: 0.38542280940363327\n",
      "--------------------\n",
      "Time for IF fitting: 2882.852\n",
      "6 0.10000000000000002 0.25 1000\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.5\n",
    "\n",
    "dfsf_frac = dfsf_normal.sample(frac = frac_normal, random_state = 1).append(dfsf_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsf_frac.loc[dfsf_frac[\"target\"]=='normal.'])/len(dfsf_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsf_frac)} records\")\n",
    "\n",
    "dfsf_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsf_frac[\"target\"]]\n",
    "toDecode = toDecodeSF\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsf_frac[f] = leSF.fit_transform(dfsf_frac[f])\n",
    "        \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),(2, 0.25, 200),(3, 0.25, 500),(4, 0.5, 100),(5, 0.5, 200),(6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsf_frac.drop([\"target\", \"binary_target\"], axis=1), dfsf_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    \n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False)\n",
    "    \n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.01        93\n",
      "           1       1.00      0.61      0.76     87453\n",
      "\n",
      "    accuracy                           0.62     87546\n",
      "   macro avg       0.50      0.81      0.38     87546\n",
      "weighted avg       1.00      0.62      0.76     87546\n",
      "\n",
      "---0.7607751965437096, 0.3835358771085758\n",
      "---0.8074794461024779\n",
      "---0.8074794461024779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.01        87\n",
      "           1       1.00      0.62      0.77     87459\n",
      "\n",
      "    accuracy                           0.62     87546\n",
      "   macro avg       0.50      0.81      0.39     87546\n",
      "weighted avg       1.00      0.62      0.77     87546\n",
      "\n",
      "---0.7661930847943312, 0.3860928253672151\n",
      "---0.8109971529516689\n",
      "---0.8109971529516689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        84\n",
      "           1       1.00      0.60      0.75     87462\n",
      "\n",
      "    accuracy                           0.60     87546\n",
      "   macro avg       0.50      0.80      0.38     87546\n",
      "weighted avg       1.00      0.60      0.75     87546\n",
      "\n",
      "---0.7524076792905606, 0.3789764885169824\n",
      "---0.8020054423635408\n",
      "---0.8020054423635408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        69\n",
      "           1       1.00      0.61      0.76     87477\n",
      "\n",
      "    accuracy                           0.61     87546\n",
      "   macro avg       0.50      0.81      0.38     87546\n",
      "weighted avg       1.00      0.61      0.76     87546\n",
      "\n",
      "---0.7588952149148376, 0.3817712653642376\n",
      "---0.8061204659510499\n",
      "---0.8061204659510499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        73\n",
      "           1       1.00      0.61      0.76     87473\n",
      "\n",
      "    accuracy                           0.61     87546\n",
      "   macro avg       0.50      0.81      0.38     87546\n",
      "weighted avg       1.00      0.61      0.76     87546\n",
      "\n",
      "---0.7604798967132941, 0.3827101403899539\n",
      "---0.8071747853623403\n",
      "---0.8071747853623403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        73\n",
      "           1       1.00      0.62      0.77     87473\n",
      "\n",
      "    accuracy                           0.62     87546\n",
      "   macro avg       0.50      0.81      0.39     87546\n",
      "weighted avg       1.00      0.62      0.77     87546\n",
      "\n",
      "---0.7658215684201379, 0.38542280940363327\n",
      "---0.8106730076709385\n",
      "---0.8106730076709385\n",
      "0.807408383400336 \\pm 0.0032999139284239994\n",
      "0.7607621067794785 \\pm 0.005068633584238468\n",
      "0.807408383400336 \\pm 0.0032999139284239994\n"
     ]
    }
   ],
   "source": [
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 0.1% out of 490120 records\n",
      "Finished trainning in 0:00:21.395905 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 82/support: 101/predicted: 5463 -> fp = 5381\n",
      "AUC : 88.4% \t precision: 0.015 \t recall: 0.812 \t f1: 0.5034639241328429\n",
      "--------------------\n",
      "Finished trainning in 0:00:21.953904 seconds\n",
      "contamination: 0.065 \t tp: 82/support: 101/predicted: 7789 -> fp = 7707\n",
      "AUC : 87.4% \t precision: 0.0105 \t recall: 0.812 \t f1: 0.49410500764907783\n",
      "--------------------\n",
      "Finished trainning in 0:00:21.920602 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 100/support: 101/predicted: 10303 -> fp = 10203\n",
      "AUC : 95.3% \t precision: 0.00971 \t recall: 0.99 \t f1: 0.4878692222457632\n",
      "--------------------\n",
      "Finished trainning in 0:00:25.705481 seconds\n",
      "contamination: 0.105 \t tp: 100/support: 101/predicted: 12805 -> fp = 12705\n",
      "AUC : 94.3% \t precision: 0.00781 \t recall: 0.99 \t f1: 0.4803828784192706\n",
      "--------------------\n",
      "Finished trainning in 0:00:21.603303 seconds\n",
      "contamination: 0.125 \t tp: 100/support: 101/predicted: 15158 -> fp = 15058\n",
      "AUC : 93.4% \t precision: 0.0066 \t recall: 0.99 \t f1: 0.4737882037702809\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.511286 seconds\n",
      "contamination: 0.145 \t tp: 100/support: 101/predicted: 17689 -> fp = 17589\n",
      "AUC : 92.3% \t precision: 0.00565 \t recall: 0.99 \t f1: 0.4669226710877923\n",
      "--------------------\n",
      "Finished trainning in 0:00:25.323803 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 100/support: 101/predicted: 20076 -> fp = 19976\n",
      "AUC : 91.3% \t precision: 0.00498 \t recall: 0.99 \t f1: 0.46053970830026303\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.106938 seconds\n",
      "contamination: 0.185 \t tp: 100/support: 101/predicted: 22481 -> fp = 22381\n",
      "AUC : 90.4% \t precision: 0.00445 \t recall: 0.99 \t f1: 0.45412670287511386\n",
      "--------------------\n",
      "Finished trainning in 0:00:21.892621 seconds\n",
      "contamination: 0.205 \t tp: 100/support: 101/predicted: 25011 -> fp = 24911\n",
      "AUC : 89.3% \t precision: 0.004 \t recall: 0.99 \t f1: 0.4473505924621425\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.012777 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 100/support: 101/predicted: 27461 -> fp = 27361\n",
      "AUC : 88.3% \t precision: 0.00364 \t recall: 0.99 \t f1: 0.4407264558992441\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.057059 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 101/support: 101/predicted: 29983 -> fp = 29882\n",
      "AUC : 87.8% \t precision: 0.00337 \t recall: 1.0 \t f1: 0.4338564848383838\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.667476 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 101/support: 101/predicted: 32486 -> fp = 32385\n",
      "AUC : 86.8% \t precision: 0.00311 \t recall: 1.0 \t f1: 0.4268897123517712\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.558535 seconds\n",
      "contamination: 0.285 \t tp: 101/support: 101/predicted: 34868 -> fp = 34767\n",
      "AUC : 85.8% \t precision: 0.0029 \t recall: 1.0 \t f1: 0.42014555621837285\n",
      "--------------------\n",
      "Finished trainning in 0:00:25.488453 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 101/support: 101/predicted: 37358 -> fp = 37257\n",
      "AUC : 84.8% \t precision: 0.0027 \t recall: 1.0 \t f1: 0.4129640545441411\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.164368 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 101/support: 101/predicted: 39764 -> fp = 39663\n",
      "AUC : 83.8% \t precision: 0.00254 \t recall: 1.0 \t f1: 0.4058864589429907\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.026149 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 101/support: 101/predicted: 42083 -> fp = 41982\n",
      "AUC : 82.9% \t precision: 0.0024 \t recall: 1.0 \t f1: 0.3989271302190525\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.612497 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 101/support: 101/predicted: 44627 -> fp = 44526\n",
      "AUC : 81.8% \t precision: 0.00226 \t recall: 1.0 \t f1: 0.3911275700330654\n",
      "--------------------\n",
      "Finished trainning in 0:00:22.049512 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 101/support: 101/predicted: 47047 -> fp = 46946\n",
      "AUC : 80.8% \t precision: 0.00215 \t recall: 1.0 \t f1: 0.3835389729572529\n",
      "--------------------\n",
      "Time for IF fitting: 413.240\n",
      "1 0.08499999999999999 0.25 100\n",
      "Finished trainning in 0:00:44.706945 seconds\n",
      "contamination: 0.04 \t tp: 69/support: 76/predicted: 4802 -> fp = 4733\n",
      "AUC : 93.5% \t precision: 0.0144 \t recall: 0.908 \t f1: 0.5042776243185736\n",
      "--------------------\n",
      "Finished trainning in 0:00:43.967202 seconds\n",
      "contamination: 0.06 \t tp: 69/support: 76/predicted: 7272 -> fp = 7203\n",
      "AUC : 92.5% \t precision: 0.00949 \t recall: 0.908 \t f1: 0.4942249000441846\n",
      "--------------------\n",
      "Finished trainning in 0:00:43.082819 seconds\n",
      "contamination: 0.07999999999999999 \t tp: 69/support: 76/predicted: 9687 -> fp = 9618\n",
      "AUC : 91.5% \t precision: 0.00712 \t recall: 0.908 \t f1: 0.4866146252916432\n",
      "--------------------\n",
      "Finished trainning in 0:00:43.296290 seconds\n",
      "contamination: 0.09999999999999999 \t tp: 75/support: 76/predicted: 12113 -> fp = 12038\n",
      "AUC : 94.4% \t precision: 0.00619 \t recall: 0.987 \t f1: 0.4803040136115221\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.289155 seconds\n",
      "contamination: 0.12 \t tp: 76/support: 76/predicted: 14432 -> fp = 14356\n",
      "AUC : 94.1% \t precision: 0.00527 \t recall: 1.0 \t f1: 0.47410451499515727\n",
      "--------------------\n",
      "Finished trainning in 0:00:45.080819 seconds\n",
      "contamination: 0.13999999999999999 \t tp: 76/support: 76/predicted: 16886 -> fp = 16810\n",
      "AUC : 93.1% \t precision: 0.0045 \t recall: 1.0 \t f1: 0.46763240687471425\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.316388 seconds\n",
      "contamination: 0.15999999999999998 \t tp: 76/support: 76/predicted: 19405 -> fp = 19329\n",
      "AUC : 92.1% \t precision: 0.00392 \t recall: 1.0 \t f1: 0.4610581533051242\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.245073 seconds\n",
      "contamination: 0.18 \t tp: 76/support: 76/predicted: 21869 -> fp = 21793\n",
      "AUC : 91.1% \t precision: 0.00348 \t recall: 1.0 \t f1: 0.45462516030160516\n",
      "--------------------\n",
      "Finished trainning in 0:00:45.541908 seconds\n",
      "contamination: 0.19999999999999998 \t tp: 76/support: 76/predicted: 24262 -> fp = 24186\n",
      "AUC : 90.1% \t precision: 0.00313 \t recall: 1.0 \t f1: 0.448334312470814\n",
      "--------------------\n",
      "Finished trainning in 0:00:45.238661 seconds\n",
      "contamination: 0.21999999999999997 \t tp: 76/support: 76/predicted: 26757 -> fp = 26681\n",
      "AUC : 89.1% \t precision: 0.00284 \t recall: 1.0 \t f1: 0.44170103426075785\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.186760 seconds\n",
      "contamination: 0.23999999999999996 \t tp: 76/support: 76/predicted: 29170 -> fp = 29094\n",
      "AUC : 88.1% \t precision: 0.00261 \t recall: 1.0 \t f1: 0.43519338032326255\n",
      "--------------------\n",
      "Finished trainning in 0:00:43.625496 seconds\n",
      "contamination: 0.25999999999999995 \t tp: 76/support: 76/predicted: 31528 -> fp = 31452\n",
      "AUC : 87.2% \t precision: 0.00241 \t recall: 1.0 \t f1: 0.4287314960174321\n",
      "--------------------\n",
      "Finished trainning in 0:00:50.340904 seconds\n",
      "contamination: 0.27999999999999997 \t tp: 76/support: 76/predicted: 33941 -> fp = 33865\n",
      "AUC : 86.2% \t precision: 0.00224 \t recall: 1.0 \t f1: 0.42200171255506796\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.237914 seconds\n",
      "contamination: 0.29999999999999993 \t tp: 76/support: 76/predicted: 36428 -> fp = 36352\n",
      "AUC : 85.2% \t precision: 0.00209 \t recall: 1.0 \t f1: 0.41493031130641844\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.252605 seconds\n",
      "contamination: 0.31999999999999995 \t tp: 76/support: 76/predicted: 38857 -> fp = 38781\n",
      "AUC : 84.2% \t precision: 0.00196 \t recall: 1.0 \t f1: 0.4078814257405314\n",
      "--------------------\n",
      "Finished trainning in 0:00:43.801738 seconds\n",
      "contamination: 0.3399999999999999 \t tp: 76/support: 76/predicted: 41341 -> fp = 41265\n",
      "AUC : 83.2% \t precision: 0.00184 \t recall: 1.0 \t f1: 0.4005179846407962\n",
      "--------------------\n",
      "Finished trainning in 0:00:45.698588 seconds\n",
      "contamination: 0.35999999999999993 \t tp: 76/support: 76/predicted: 43862 -> fp = 43786\n",
      "AUC : 82.1% \t precision: 0.00173 \t recall: 1.0 \t f1: 0.39287538282170203\n",
      "--------------------\n",
      "Finished trainning in 0:00:44.635921 seconds\n",
      "contamination: 0.37999999999999995 \t tp: 76/support: 76/predicted: 46322 -> fp = 46246\n",
      "AUC : 81.1% \t precision: 0.00164 \t recall: 1.0 \t f1: 0.3852443279611032\n",
      "--------------------\n",
      "Time for IF fitting: 807.604\n",
      "2 0.09999999999999999 0.25 200\n",
      "Finished trainning in 0:01:51.676002 seconds\n",
      "contamination: 0.035 \t tp: 58/support: 75/predicted: 4340 -> fp = 4282\n",
      "AUC : 86.9% \t precision: 0.0134 \t recall: 0.773 \t f1: 0.5042047882499248\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:01:51.699347 seconds\n",
      "contamination: 0.05500000000000001 \t tp: 58/support: 75/predicted: 6698 -> fp = 6640\n",
      "AUC : 86.0% \t precision: 0.00866 \t recall: 0.773 \t f1: 0.494594963743294\n",
      "--------------------\n",
      "Finished trainning in 0:01:53.538074 seconds\n",
      "contamination: 0.07500000000000001 \t tp: 58/support: 75/predicted: 9143 -> fp = 9085\n",
      "AUC : 85.0% \t precision: 0.00634 \t recall: 0.773 \t f1: 0.4869952199575148\n",
      "--------------------\n",
      "Finished trainning in 0:01:53.726190 seconds\n",
      "contamination: 0.09500000000000001 \t tp: 75/support: 75/predicted: 11551 -> fp = 11476\n",
      "AUC : 95.3% \t precision: 0.00649 \t recall: 1.0 \t f1: 0.48187023427173326\n",
      "--------------------\n",
      "Finished trainning in 0:01:54.012638 seconds\n",
      "contamination: 0.11500000000000002 \t tp: 75/support: 75/predicted: 14017 -> fp = 13942\n",
      "AUC : 94.3% \t precision: 0.00535 \t recall: 1.0 \t f1: 0.4751404984182235\n",
      "--------------------\n",
      "Finished trainning in 0:01:52.454247 seconds\n",
      "contamination: 0.135 \t tp: 75/support: 75/predicted: 16501 -> fp = 16426\n",
      "AUC : 93.3% \t precision: 0.00455 \t recall: 1.0 \t f1: 0.4685789896983569\n",
      "--------------------\n",
      "Finished trainning in 0:01:52.235033 seconds\n",
      "contamination: 0.15500000000000003 \t tp: 75/support: 75/predicted: 18933 -> fp = 18858\n",
      "AUC : 92.3% \t precision: 0.00396 \t recall: 1.0 \t f1: 0.46223406550151064\n",
      "--------------------\n",
      "Finished trainning in 0:01:54.703691 seconds\n",
      "contamination: 0.17500000000000002 \t tp: 75/support: 75/predicted: 21421 -> fp = 21346\n",
      "AUC : 91.3% \t precision: 0.0035 \t recall: 1.0 \t f1: 0.45574877680896203\n",
      "--------------------\n",
      "Finished trainning in 0:01:56.123197 seconds\n",
      "contamination: 0.19500000000000003 \t tp: 75/support: 75/predicted: 23926 -> fp = 23851\n",
      "AUC : 90.3% \t precision: 0.00313 \t recall: 1.0 \t f1: 0.4491777335122086\n",
      "--------------------\n",
      "Finished trainning in 0:01:59.254875 seconds\n",
      "contamination: 0.21500000000000005 \t tp: 75/support: 75/predicted: 26310 -> fp = 26235\n",
      "AUC : 89.3% \t precision: 0.00285 \t recall: 1.0 \t f1: 0.44285624315082317\n",
      "--------------------\n",
      "Finished trainning in 0:01:54.950118 seconds\n",
      "contamination: 0.23500000000000004 \t tp: 75/support: 75/predicted: 28788 -> fp = 28713\n",
      "AUC : 88.3% \t precision: 0.00261 \t recall: 1.0 \t f1: 0.43619376826725176\n",
      "--------------------\n",
      "Finished trainning in 0:01:52.428901 seconds\n",
      "contamination: 0.255 \t tp: 75/support: 75/predicted: 31289 -> fp = 31214\n",
      "AUC : 87.3% \t precision: 0.0024 \t recall: 1.0 \t f1: 0.429357621336866\n",
      "--------------------\n",
      "Finished trainning in 0:01:53.827185 seconds\n",
      "contamination: 0.275 \t tp: 75/support: 75/predicted: 33625 -> fp = 33550\n",
      "AUC : 86.3% \t precision: 0.00223 \t recall: 1.0 \t f1: 0.4228585624369633\n",
      "--------------------\n",
      "Finished trainning in 0:01:55.695281 seconds\n",
      "contamination: 0.29500000000000004 \t tp: 75/support: 75/predicted: 36247 -> fp = 36172\n",
      "AUC : 85.2% \t precision: 0.00207 \t recall: 1.0 \t f1: 0.41542036254972936\n",
      "--------------------\n",
      "Finished trainning in 0:01:55.342516 seconds\n",
      "contamination: 0.31500000000000006 \t tp: 75/support: 75/predicted: 38688 -> fp = 38613\n",
      "AUC : 84.2% \t precision: 0.00194 \t recall: 1.0 \t f1: 0.40834888828988364\n",
      "--------------------\n",
      "Finished trainning in 0:01:54.566942 seconds\n",
      "contamination: 0.3350000000000001 \t tp: 75/support: 75/predicted: 41171 -> fp = 41096\n",
      "AUC : 83.2% \t precision: 0.00182 \t recall: 1.0 \t f1: 0.4010009461897835\n",
      "--------------------\n",
      "Finished trainning in 0:01:55.298127 seconds\n",
      "contamination: 0.3550000000000001 \t tp: 75/support: 75/predicted: 43688 -> fp = 43613\n",
      "AUC : 82.2% \t precision: 0.00172 \t recall: 1.0 \t f1: 0.3933837963986601\n",
      "--------------------\n",
      "Finished trainning in 0:01:50.688880 seconds\n",
      "contamination: 0.3750000000000001 \t tp: 75/support: 75/predicted: 46126 -> fp = 46051\n",
      "AUC : 81.2% \t precision: 0.00163 \t recall: 1.0 \t f1: 0.3858352705413753\n",
      "--------------------\n",
      "Finished trainning in 0:01:49.683251 seconds\n",
      "contamination: 0.39500000000000013 \t tp: 75/support: 75/predicted: 48575 -> fp = 48500\n",
      "AUC : 80.2% \t precision: 0.00154 \t recall: 1.0 \t f1: 0.3780754052194758\n",
      "--------------------\n",
      "Time for IF fitting: 2165.107\n",
      "3 0.09500000000000001 0.25 500\n",
      "Finished trainning in 0:00:26.947973 seconds\n",
      "contamination: 0.030000000000000002 \t tp: 59/support: 76/predicted: 3623 -> fp = 3564\n",
      "AUC : 87.4% \t precision: 0.0163 \t recall: 0.776 \t f1: 0.5085319083771654\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.539553 seconds\n",
      "contamination: 0.05 \t tp: 59/support: 76/predicted: 6020 -> fp = 5961\n",
      "AUC : 86.4% \t precision: 0.0098 \t recall: 0.776 \t f1: 0.4971703174653176\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.005287 seconds\n",
      "contamination: 0.07 \t tp: 59/support: 76/predicted: 8413 -> fp = 8354\n",
      "AUC : 85.4% \t precision: 0.00701 \t recall: 0.776 \t f1: 0.489257807840026\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.471903 seconds\n",
      "contamination: 0.09 \t tp: 74/support: 76/predicted: 10762 -> fp = 10688\n",
      "AUC : 94.3% \t precision: 0.00688 \t recall: 0.974 \t f1: 0.48400759763282325\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.809496 seconds\n",
      "contamination: 0.11 \t tp: 74/support: 76/predicted: 13285 -> fp = 13211\n",
      "AUC : 93.3% \t precision: 0.00557 \t recall: 0.974 \t f1: 0.4770252209619218\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.033508 seconds\n",
      "contamination: 0.13 \t tp: 76/support: 76/predicted: 15779 -> fp = 15703\n",
      "AUC : 93.6% \t precision: 0.00482 \t recall: 1.0 \t f1: 0.47053807963358407\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.462239 seconds\n",
      "contamination: 0.15 \t tp: 76/support: 76/predicted: 18254 -> fp = 18178\n",
      "AUC : 92.6% \t precision: 0.00416 \t recall: 1.0 \t f1: 0.4640588798609727\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.274966 seconds\n",
      "contamination: 0.17 \t tp: 76/support: 76/predicted: 20665 -> fp = 20589\n",
      "AUC : 91.6% \t precision: 0.00368 \t recall: 1.0 \t f1: 0.4577720060835683\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.698528 seconds\n",
      "contamination: 0.19 \t tp: 76/support: 76/predicted: 23075 -> fp = 22999\n",
      "AUC : 90.6% \t precision: 0.00329 \t recall: 1.0 \t f1: 0.45146200415410104\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.375644 seconds\n",
      "contamination: 0.21 \t tp: 76/support: 76/predicted: 25479 -> fp = 25403\n",
      "AUC : 89.6% \t precision: 0.00298 \t recall: 1.0 \t f1: 0.4451096921435853\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.942464 seconds\n",
      "contamination: 0.23 \t tp: 76/support: 76/predicted: 27990 -> fp = 27914\n",
      "AUC : 88.6% \t precision: 0.00272 \t recall: 1.0 \t f1: 0.4383881520240224\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.157437 seconds\n",
      "contamination: 0.25 \t tp: 76/support: 76/predicted: 30419 -> fp = 30343\n",
      "AUC : 87.6% \t precision: 0.0025 \t recall: 1.0 \t f1: 0.4317840348287083\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.843719 seconds\n",
      "contamination: 0.27 \t tp: 76/support: 76/predicted: 32775 -> fp = 32699\n",
      "AUC : 86.6% \t precision: 0.00232 \t recall: 1.0 \t f1: 0.42526914705782065\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.131752 seconds\n",
      "contamination: 0.29000000000000004 \t tp: 76/support: 76/predicted: 35292 -> fp = 35216\n",
      "AUC : 85.6% \t precision: 0.00215 \t recall: 1.0 \t f1: 0.4181780589191546\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.828200 seconds\n",
      "contamination: 0.31000000000000005 \t tp: 76/support: 76/predicted: 37769 -> fp = 37693\n",
      "AUC : 84.6% \t precision: 0.00201 \t recall: 1.0 \t f1: 0.4110567640451056\n",
      "--------------------\n",
      "Finished trainning in 0:00:23.540305 seconds\n",
      "contamination: 0.33 \t tp: 76/support: 76/predicted: 40198 -> fp = 40122\n",
      "AUC : 83.6% \t precision: 0.00189 \t recall: 1.0 \t f1: 0.40392627544477583\n",
      "--------------------\n",
      "Finished trainning in 0:00:27.067071 seconds\n",
      "contamination: 0.35000000000000003 \t tp: 76/support: 76/predicted: 42614 -> fp = 42538\n",
      "AUC : 82.6% \t precision: 0.00178 \t recall: 1.0 \t f1: 0.39668070631695596\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.771480 seconds\n",
      "contamination: 0.37000000000000005 \t tp: 76/support: 76/predicted: 45104 -> fp = 45028\n",
      "AUC : 81.6% \t precision: 0.00168 \t recall: 1.0 \t f1: 0.3890445776983676\n",
      "--------------------\n",
      "Finished trainning in 0:00:24.011346 seconds\n",
      "contamination: 0.39 \t tp: 76/support: 76/predicted: 47547 -> fp = 47471\n",
      "AUC : 80.6% \t precision: 0.0016 \t recall: 1.0 \t f1: 0.3813777726570303\n",
      "--------------------\n",
      "Time for IF fitting: 464.986\n",
      "4 0.09 0.5 100\n",
      "Finished trainning in 0:00:48.669467 seconds\n",
      "contamination: 0.025 \t tp: 72/support: 85/predicted: 3132 -> fp = 3060\n",
      "AUC : 91.1% \t precision: 0.023 \t recall: 0.847 \t f1: 0.5160278050844124\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:00:47.081605 seconds\n",
      "contamination: 0.045 \t tp: 72/support: 85/predicted: 5619 -> fp = 5547\n",
      "AUC : 90.1% \t precision: 0.0128 \t recall: 0.847 \t f1: 0.5010082219922195\n",
      "--------------------\n",
      "Finished trainning in 0:00:53.876839 seconds\n",
      "contamination: 0.065 \t tp: 72/support: 85/predicted: 8112 -> fp = 8040\n",
      "AUC : 89.1% \t precision: 0.00888 \t recall: 0.847 \t f1: 0.4917844232904631\n",
      "--------------------\n",
      "Finished trainning in 0:00:48.512213 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 72/support: 85/predicted: 10644 -> fp = 10572\n",
      "AUC : 88.0% \t precision: 0.00676 \t recall: 0.847 \t f1: 0.4841252104585239\n",
      "--------------------\n",
      "Finished trainning in 0:00:46.603446 seconds\n",
      "contamination: 0.10499999999999998 \t tp: 84/support: 85/predicted: 13078 -> fp = 12994\n",
      "AUC : 94.1% \t precision: 0.00642 \t recall: 0.988 \t f1: 0.4783626190238323\n",
      "--------------------\n",
      "Finished trainning in 0:00:49.602393 seconds\n",
      "contamination: 0.12499999999999997 \t tp: 85/support: 85/predicted: 15510 -> fp = 15425\n",
      "AUC : 93.7% \t precision: 0.00548 \t recall: 1.0 \t f1: 0.47183967457598774\n",
      "--------------------\n",
      "Finished trainning in 0:00:47.896671 seconds\n",
      "contamination: 0.145 \t tp: 85/support: 85/predicted: 18070 -> fp = 17985\n",
      "AUC : 92.7% \t precision: 0.0047 \t recall: 1.0 \t f1: 0.46505078265380284\n",
      "--------------------\n",
      "Finished trainning in 0:00:49.223527 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 85/support: 85/predicted: 20469 -> fp = 20384\n",
      "AUC : 91.7% \t precision: 0.00415 \t recall: 1.0 \t f1: 0.45873799768574697\n",
      "--------------------\n",
      "Finished trainning in 0:00:50.562797 seconds\n",
      "contamination: 0.18499999999999997 \t tp: 85/support: 85/predicted: 22903 -> fp = 22818\n",
      "AUC : 90.7% \t precision: 0.00371 \t recall: 1.0 \t f1: 0.45232235169154267\n",
      "--------------------\n",
      "Finished trainning in 0:00:50.387457 seconds\n",
      "contamination: 0.20499999999999996 \t tp: 85/support: 85/predicted: 25367 -> fp = 25282\n",
      "AUC : 89.7% \t precision: 0.00335 \t recall: 1.0 \t f1: 0.44577796436315004\n",
      "--------------------\n",
      "Finished trainning in 0:00:48.256750 seconds\n",
      "contamination: 0.22499999999999995 \t tp: 85/support: 85/predicted: 27857 -> fp = 27772\n",
      "AUC : 88.7% \t precision: 0.00305 \t recall: 1.0 \t f1: 0.43908601011364845\n",
      "--------------------\n",
      "Finished trainning in 0:00:50.569372 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 85/support: 85/predicted: 30310 -> fp = 30225\n",
      "AUC : 87.7% \t precision: 0.0028 \t recall: 1.0 \t f1: 0.43239612127692073\n",
      "--------------------\n",
      "Finished trainning in 0:00:49.257099 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 85/support: 85/predicted: 32835 -> fp = 32750\n",
      "AUC : 86.6% \t precision: 0.00259 \t recall: 1.0 \t f1: 0.4253924252319217\n",
      "--------------------\n",
      "Finished trainning in 0:00:49.283390 seconds\n",
      "contamination: 0.285 \t tp: 85/support: 85/predicted: 35176 -> fp = 35091\n",
      "AUC : 85.7% \t precision: 0.00242 \t recall: 1.0 \t f1: 0.41878054937415654\n",
      "--------------------\n",
      "Finished trainning in 0:00:48.731170 seconds\n",
      "contamination: 0.305 \t tp: 85/support: 85/predicted: 37712 -> fp = 37627\n",
      "AUC : 84.6% \t precision: 0.00225 \t recall: 1.0 \t f1: 0.4114777098904289\n",
      "--------------------\n",
      "Finished trainning in 0:00:47.686774 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 85/support: 85/predicted: 40087 -> fp = 40002\n",
      "AUC : 83.7% \t precision: 0.00212 \t recall: 1.0 \t f1: 0.40449671455496433\n",
      "--------------------\n",
      "Finished trainning in 0:00:49.453604 seconds\n",
      "contamination: 0.345 \t tp: 85/support: 85/predicted: 42545 -> fp = 42460\n",
      "AUC : 82.7% \t precision: 0.002 \t recall: 1.0 \t f1: 0.3971181414868694\n",
      "--------------------\n",
      "Finished trainning in 0:00:48.575515 seconds\n",
      "contamination: 0.365 \t tp: 85/support: 85/predicted: 45039 -> fp = 44954\n",
      "AUC : 81.6% \t precision: 0.00189 \t recall: 1.0 \t f1: 0.3894627235417931\n",
      "--------------------\n",
      "Finished trainning in 0:00:50.993150 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 85/support: 85/predicted: 47509 -> fp = 47424\n",
      "AUC : 80.6% \t precision: 0.00179 \t recall: 1.0 \t f1: 0.3817045076639789\n",
      "--------------------\n",
      "Time for IF fitting: 938.511\n",
      "5 0.10499999999999998 0.5 200\n",
      "Finished trainning in 0:03:47.113724 seconds\n",
      "contamination: 0.020000000000000004 \t tp: 67/support: 81/predicted: 2475 -> fp = 2408\n",
      "AUC : 90.4% \t precision: 0.0271 \t recall: 0.827 \t f1: 0.5212191004887092\n",
      "--------------------\n",
      "Finished trainning in 0:03:46.041052 seconds\n",
      "contamination: 0.04000000000000001 \t tp: 67/support: 81/predicted: 4893 -> fp = 4826\n",
      "AUC : 89.4% \t precision: 0.0137 \t recall: 0.827 \t f1: 0.5033903227968428\n",
      "--------------------\n",
      "Finished trainning in 0:03:40.959859 seconds\n",
      "contamination: 0.06000000000000001 \t tp: 67/support: 81/predicted: 7438 -> fp = 7371\n",
      "AUC : 88.3% \t precision: 0.00901 \t recall: 0.827 \t f1: 0.49336607449194486\n",
      "--------------------\n",
      "Finished trainning in 0:03:40.523731 seconds\n",
      "contamination: 0.08000000000000002 \t tp: 67/support: 81/predicted: 9765 -> fp = 9698\n",
      "AUC : 87.4% \t precision: 0.00686 \t recall: 0.827 \t f1: 0.48615976419231366\n",
      "--------------------\n",
      "Finished trainning in 0:03:44.363898 seconds\n",
      "contamination: 0.10000000000000002 \t tp: 81/support: 81/predicted: 12429 -> fp = 12348\n",
      "AUC : 95.0% \t precision: 0.00652 \t recall: 1.0 \t f1: 0.4799256909243622\n",
      "--------------------\n",
      "Finished trainning in 0:03:42.895694 seconds\n",
      "contamination: 0.12000000000000002 \t tp: 81/support: 81/predicted: 14847 -> fp = 14766\n",
      "AUC : 94.0% \t precision: 0.00546 \t recall: 1.0 \t f1: 0.4733444570578619\n",
      "--------------------\n",
      "Finished trainning in 0:03:43.580825 seconds\n",
      "contamination: 0.14 \t tp: 81/support: 81/predicted: 17208 -> fp = 17127\n",
      "AUC : 93.0% \t precision: 0.00471 \t recall: 1.0 \t f1: 0.4670880874669386\n",
      "--------------------\n",
      "Finished trainning in 0:03:44.443325 seconds\n",
      "contamination: 0.16000000000000003 \t tp: 81/support: 81/predicted: 19633 -> fp = 19552\n",
      "AUC : 92.0% \t precision: 0.00413 \t recall: 1.0 \t f1: 0.4607265784578066\n",
      "--------------------\n",
      "Finished trainning in 0:03:42.501042 seconds\n",
      "contamination: 0.18000000000000005 \t tp: 81/support: 81/predicted: 22037 -> fp = 21956\n",
      "AUC : 91.0% \t precision: 0.00368 \t recall: 1.0 \t f1: 0.45442066884397514\n",
      "--------------------\n",
      "Finished trainning in 0:03:40.639899 seconds\n",
      "contamination: 0.20000000000000007 \t tp: 81/support: 81/predicted: 24397 -> fp = 24316\n",
      "AUC : 90.1% \t precision: 0.00332 \t recall: 1.0 \t f1: 0.4481912692163752\n",
      "--------------------\n",
      "Finished trainning in 0:03:35.557408 seconds\n",
      "contamination: 0.22000000000000003 \t tp: 81/support: 81/predicted: 26897 -> fp = 26816\n",
      "AUC : 89.1% \t precision: 0.00301 \t recall: 1.0 \t f1: 0.44152098533605083\n",
      "--------------------\n",
      "Finished trainning in 0:03:40.456646 seconds\n",
      "contamination: 0.24000000000000005 \t tp: 81/support: 81/predicted: 29386 -> fp = 29305\n",
      "AUC : 88.0% \t precision: 0.00276 \t recall: 1.0 \t f1: 0.4347851282859588\n",
      "--------------------\n",
      "Finished trainning in 0:03:50.514535 seconds\n",
      "contamination: 0.26000000000000006 \t tp: 81/support: 81/predicted: 31844 -> fp = 31763\n",
      "AUC : 87.0% \t precision: 0.00254 \t recall: 1.0 \t f1: 0.42802339075059115\n",
      "--------------------\n",
      "Finished trainning in 0:03:49.738776 seconds\n",
      "contamination: 0.2800000000000001 \t tp: 81/support: 81/predicted: 34322 -> fp = 34241\n",
      "AUC : 86.0% \t precision: 0.00236 \t recall: 1.0 \t f1: 0.42108252038093674\n",
      "--------------------\n",
      "Finished trainning in 0:03:51.161889 seconds\n",
      "contamination: 0.30000000000000004 \t tp: 81/support: 81/predicted: 36823 -> fp = 36742\n",
      "AUC : 85.0% \t precision: 0.0022 \t recall: 1.0 \t f1: 0.4139389605813783\n",
      "--------------------\n",
      "Finished trainning in 0:03:51.879369 seconds\n",
      "contamination: 0.32000000000000006 \t tp: 81/support: 81/predicted: 39236 -> fp = 39155\n",
      "AUC : 84.0% \t precision: 0.00206 \t recall: 1.0 \t f1: 0.4069050568225023\n",
      "--------------------\n",
      "Finished trainning in 0:03:56.917388 seconds\n",
      "contamination: 0.3400000000000001 \t tp: 81/support: 81/predicted: 41608 -> fp = 41527\n",
      "AUC : 83.0% \t precision: 0.00195 \t recall: 1.0 \t f1: 0.39984629779169345\n",
      "--------------------\n",
      "Finished trainning in 0:03:47.099800 seconds\n",
      "contamination: 0.3600000000000001 \t tp: 81/support: 81/predicted: 43984 -> fp = 43903\n",
      "AUC : 82.1% \t precision: 0.00184 \t recall: 1.0 \t f1: 0.39262403402146145\n",
      "--------------------\n",
      "Finished trainning in 0:03:47.554322 seconds\n",
      "contamination: 0.3800000000000001 \t tp: 81/support: 81/predicted: 46422 -> fp = 46341\n",
      "AUC : 81.1% \t precision: 0.00174 \t recall: 1.0 \t f1: 0.38504737264811717\n",
      "--------------------\n",
      "Time for IF fitting: 4287.205\n",
      "6 0.10000000000000002 0.25 1000\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.7\n",
    "\n",
    "dfsf_frac = dfsf_normal.sample(frac = frac_normal, random_state = 1).append(dfsf_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsf_frac.loc[dfsf_frac[\"target\"]=='normal.'])/len(dfsf_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsf_frac)} records\")\n",
    "\n",
    "dfsf_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsf_frac[\"target\"]]\n",
    "toDecode = toDecodeSF\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsf_frac[f] = leSF.fit_transform(dfsf_frac[f])\n",
    "        \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),(2, 0.25, 200),(3, 0.25, 500),(4, 0.5, 100),(5, 0.5, 200),(6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsf_frac.drop([\"target\", \"binary_target\"], axis=1), dfsf_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    \n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False)\n",
    "    \n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00       101\n",
      "           1       1.00      0.62      0.76    122429\n",
      "\n",
      "    accuracy                           0.62    122530\n",
      "   macro avg       0.50      0.81      0.38    122530\n",
      "weighted avg       1.00      0.62      0.76    122530\n",
      "\n",
      "---0.762168334852142, 0.3835389729572529\n",
      "---0.8082725498043764\n",
      "---0.8082725498043764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        76\n",
      "           1       1.00      0.62      0.77    122454\n",
      "\n",
      "    accuracy                           0.62    122530\n",
      "   macro avg       0.50      0.81      0.39    122530\n",
      "weighted avg       1.00      0.62      0.77    122530\n",
      "\n",
      "---0.7667388161543061, 0.3852443279611032\n",
      "---0.81116990870041\n",
      "---0.81116990870041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        75\n",
      "           1       1.00      0.60      0.75    122455\n",
      "\n",
      "    accuracy                           0.60    122530\n",
      "   macro avg       0.50      0.80      0.38    122530\n",
      "weighted avg       1.00      0.60      0.75    122530\n",
      "\n",
      "---0.7526085011042006, 0.3780754052194758\n",
      "---0.8019680699032298\n",
      "---0.8019680699032298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        76\n",
      "           1       1.00      0.61      0.76    122454\n",
      "\n",
      "    accuracy                           0.61    122530\n",
      "   macro avg       0.50      0.81      0.38    122530\n",
      "weighted avg       1.00      0.61      0.76    122530\n",
      "\n",
      "---0.7590946657107236, 0.3813777726570303\n",
      "---0.8061680304440851\n",
      "---0.8061680304440851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        85\n",
      "           1       1.00      0.61      0.76    122445\n",
      "\n",
      "    accuracy                           0.61    122530\n",
      "   macro avg       0.50      0.81      0.38    122530\n",
      "weighted avg       1.00      0.61      0.76    122530\n",
      "\n",
      "---0.7593125095148449, 0.3817045076639789\n",
      "---0.8063457062354527\n",
      "---0.8063457062354527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        81\n",
      "           1       1.00      0.62      0.77    122449\n",
      "\n",
      "    accuracy                           0.62    122530\n",
      "   macro avg       0.50      0.81      0.39    122530\n",
      "weighted avg       1.00      0.62      0.77    122530\n",
      "\n",
      "---0.7661066240640941, 0.38504737264811717\n",
      "---0.8107742815376198\n",
      "---0.8107742815376198\n",
      "0.8074497577708623 \\pm 0.0034199305418666334\n",
      "0.7610049085667185 \\pm 0.00523968813112115\n",
      "0.8074497577708623 \\pm 0.0034199305418666334\n"
     ]
    }
   ],
   "source": [
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 0.0% out of 700027 records\n",
      "Finished trainning in 0:00:32.983053 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 91/support: 108/predicted: 8075 -> fp = 7984\n",
      "AUC : 89.8% \t precision: 0.0113 \t recall: 0.843 \t f1: 0.49941746435368656\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.762889 seconds\n",
      "contamination: 0.065 \t tp: 91/support: 108/predicted: 11554 -> fp = 11463\n",
      "AUC : 88.9% \t precision: 0.00788 \t recall: 0.843 \t f1: 0.4908385399840175\n",
      "--------------------\n",
      "Finished trainning in 0:00:33.241434 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 91/support: 108/predicted: 15018 -> fp = 14927\n",
      "AUC : 87.9% \t precision: 0.00606 \t recall: 0.843 \t f1: 0.48370419403963383\n",
      "--------------------\n",
      "Finished trainning in 0:00:34.640285 seconds\n",
      "contamination: 0.105 \t tp: 107/support: 108/predicted: 18493 -> fp = 18386\n",
      "AUC : 94.3% \t precision: 0.00579 \t recall: 0.991 \t f1: 0.47801206696729054\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.003642 seconds\n",
      "contamination: 0.125 \t tp: 108/support: 108/predicted: 22170 -> fp = 22062\n",
      "AUC : 93.7% \t precision: 0.00487 \t recall: 1.0 \t f1: 0.47118964364392774\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.982258 seconds\n",
      "contamination: 0.145 \t tp: 108/support: 108/predicted: 25634 -> fp = 25526\n",
      "AUC : 92.7% \t precision: 0.00421 \t recall: 1.0 \t f1: 0.4648365449655919\n",
      "--------------------\n",
      "Finished trainning in 0:00:33.582783 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 108/support: 108/predicted: 29042 -> fp = 28934\n",
      "AUC : 91.7% \t precision: 0.00372 \t recall: 1.0 \t f1: 0.4586173358946282\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.546022 seconds\n",
      "contamination: 0.185 \t tp: 108/support: 108/predicted: 32642 -> fp = 32534\n",
      "AUC : 90.7% \t precision: 0.00331 \t recall: 1.0 \t f1: 0.45202495285069016\n",
      "--------------------\n",
      "Finished trainning in 0:00:34.888653 seconds\n",
      "contamination: 0.205 \t tp: 108/support: 108/predicted: 36132 -> fp = 36024\n",
      "AUC : 89.7% \t precision: 0.00299 \t recall: 1.0 \t f1: 0.44557575860163745\n",
      "--------------------\n",
      "Finished trainning in 0:00:33.366346 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 108/support: 108/predicted: 39614 -> fp = 39506\n",
      "AUC : 88.7% \t precision: 0.00273 \t recall: 1.0 \t f1: 0.4390595045307971\n",
      "--------------------\n",
      "Finished trainning in 0:00:33.607642 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 108/support: 108/predicted: 43082 -> fp = 42974\n",
      "AUC : 87.7% \t precision: 0.00251 \t recall: 1.0 \t f1: 0.4324702031174112\n",
      "--------------------\n",
      "Finished trainning in 0:00:32.705627 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 108/support: 108/predicted: 46570 -> fp = 46462\n",
      "AUC : 86.7% \t precision: 0.00232 \t recall: 1.0 \t f1: 0.4257286827993034\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.398415 seconds\n",
      "contamination: 0.285 \t tp: 108/support: 108/predicted: 50133 -> fp = 50025\n",
      "AUC : 85.7% \t precision: 0.00215 \t recall: 1.0 \t f1: 0.41871150388589323\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.707011 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 108/support: 108/predicted: 53672 -> fp = 53564\n",
      "AUC : 84.7% \t precision: 0.00201 \t recall: 1.0 \t f1: 0.4115999231437889\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.072189 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 108/support: 108/predicted: 57079 -> fp = 56971\n",
      "AUC : 83.7% \t precision: 0.00189 \t recall: 1.0 \t f1: 0.4046109676541951\n",
      "--------------------\n",
      "Finished trainning in 0:00:35.946966 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 108/support: 108/predicted: 60484 -> fp = 60376\n",
      "AUC : 82.7% \t precision: 0.00179 \t recall: 1.0 \t f1: 0.3974779722542416\n",
      "--------------------\n",
      "Finished trainning in 0:00:35.178126 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 108/support: 108/predicted: 63965 -> fp = 63857\n",
      "AUC : 81.7% \t precision: 0.00169 \t recall: 1.0 \t f1: 0.39002443050834074\n",
      "--------------------\n",
      "Finished trainning in 0:00:34.577165 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 108/support: 108/predicted: 67302 -> fp = 67194\n",
      "AUC : 80.8% \t precision: 0.0016 \t recall: 1.0 \t f1: 0.3827184685760214\n",
      "--------------------\n",
      "Time for IF fitting: 626.677\n",
      "1 0.105 0.25 100\n",
      "Finished trainning in 0:01:08.064722 seconds\n",
      "contamination: 0.04 \t tp: 71/support: 89/predicted: 6912 -> fp = 6841\n",
      "AUC : 87.9% \t precision: 0.0103 \t recall: 0.798 \t f1: 0.5001432450353155\n",
      "--------------------\n",
      "Finished trainning in 0:01:07.920790 seconds\n",
      "contamination: 0.06 \t tp: 72/support: 89/predicted: 10298 -> fp = 10226\n",
      "AUC : 87.5% \t precision: 0.00699 \t recall: 0.809 \t f1: 0.4918519629016814\n",
      "--------------------\n",
      "Finished trainning in 0:01:12.121902 seconds\n",
      "contamination: 0.07999999999999999 \t tp: 88/support: 89/predicted: 13599 -> fp = 13511\n",
      "AUC : 95.6% \t precision: 0.00647 \t recall: 0.989 \t f1: 0.48634133584447387\n",
      "--------------------\n",
      "Finished trainning in 0:01:10.777537 seconds\n",
      "contamination: 0.09999999999999999 \t tp: 89/support: 89/predicted: 17439 -> fp = 17350\n",
      "AUC : 95.0% \t precision: 0.0051 \t recall: 1.0 \t f1: 0.4789862659955088\n",
      "--------------------\n",
      "Finished trainning in 0:01:08.732086 seconds\n",
      "contamination: 0.12 \t tp: 89/support: 89/predicted: 20863 -> fp = 20774\n",
      "AUC : 94.1% \t precision: 0.00427 \t recall: 1.0 \t f1: 0.4726823244440283\n",
      "--------------------\n",
      "Finished trainning in 0:01:10.259506 seconds\n",
      "contamination: 0.13999999999999999 \t tp: 89/support: 89/predicted: 24338 -> fp = 24249\n",
      "AUC : 93.1% \t precision: 0.00366 \t recall: 1.0 \t f1: 0.46640461455827487\n",
      "--------------------\n",
      "Finished trainning in 0:01:10.392267 seconds\n",
      "contamination: 0.15999999999999998 \t tp: 89/support: 89/predicted: 27864 -> fp = 27775\n",
      "AUC : 92.1% \t precision: 0.00319 \t recall: 1.0 \t f1: 0.46006320270193857\n",
      "--------------------\n",
      "Finished trainning in 0:01:07.577385 seconds\n",
      "contamination: 0.18 \t tp: 89/support: 89/predicted: 31522 -> fp = 31433\n",
      "AUC : 91.0% \t precision: 0.00282 \t recall: 1.0 \t f1: 0.45345507387056483\n",
      "--------------------\n",
      "Finished trainning in 0:01:08.577503 seconds\n",
      "contamination: 0.19999999999999998 \t tp: 89/support: 89/predicted: 35083 -> fp = 34994\n",
      "AUC : 90.0% \t precision: 0.00254 \t recall: 1.0 \t f1: 0.446956515014494\n",
      "--------------------\n",
      "Finished trainning in 0:01:07.508229 seconds\n",
      "contamination: 0.21999999999999997 \t tp: 89/support: 89/predicted: 38474 -> fp = 38385\n",
      "AUC : 89.0% \t precision: 0.00231 \t recall: 1.0 \t f1: 0.4406850561271755\n",
      "--------------------\n",
      "Finished trainning in 0:01:11.121625 seconds\n",
      "contamination: 0.23999999999999996 \t tp: 89/support: 89/predicted: 41950 -> fp = 41861\n",
      "AUC : 88.0% \t precision: 0.00212 \t recall: 1.0 \t f1: 0.4341553965556948\n",
      "--------------------\n",
      "Finished trainning in 0:01:10.767928 seconds\n",
      "contamination: 0.25999999999999995 \t tp: 89/support: 89/predicted: 45386 -> fp = 45297\n",
      "AUC : 87.1% \t precision: 0.00196 \t recall: 1.0 \t f1: 0.4275873341456463\n",
      "--------------------\n",
      "Finished trainning in 0:01:12.194250 seconds\n",
      "contamination: 0.27999999999999997 \t tp: 89/support: 89/predicted: 48886 -> fp = 48797\n",
      "AUC : 86.1% \t precision: 0.00182 \t recall: 1.0 \t f1: 0.4207696153550056\n",
      "--------------------\n",
      "Finished trainning in 0:01:06.961619 seconds\n",
      "contamination: 0.29999999999999993 \t tp: 89/support: 89/predicted: 52432 -> fp = 52343\n",
      "AUC : 85.0% \t precision: 0.0017 \t recall: 1.0 \t f1: 0.4137210617350296\n",
      "--------------------\n",
      "Finished trainning in 0:01:06.954107 seconds\n",
      "contamination: 0.31999999999999995 \t tp: 89/support: 89/predicted: 55925 -> fp = 55836\n",
      "AUC : 84.0% \t precision: 0.00159 \t recall: 1.0 \t f1: 0.40662970481869326\n",
      "--------------------\n",
      "Finished trainning in 0:01:07.862462 seconds\n",
      "contamination: 0.3399999999999999 \t tp: 89/support: 89/predicted: 59447 -> fp = 59358\n",
      "AUC : 83.0% \t precision: 0.0015 \t recall: 1.0 \t f1: 0.3993219237757179\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.755755 seconds\n",
      "contamination: 0.35999999999999993 \t tp: 89/support: 89/predicted: 63046 -> fp = 62957\n",
      "AUC : 82.0% \t precision: 0.00141 \t recall: 1.0 \t f1: 0.39168223160871235\n",
      "--------------------\n",
      "Finished trainning in 0:01:10.608468 seconds\n",
      "contamination: 0.37999999999999995 \t tp: 89/support: 89/predicted: 66537 -> fp = 66448\n",
      "AUC : 81.0% \t precision: 0.00134 \t recall: 1.0 \t f1: 0.3840972585214536\n",
      "--------------------\n",
      "Time for IF fitting: 1257.640\n",
      "2 0.07999999999999999 0.25 200\n",
      "Finished trainning in 0:02:54.207034 seconds\n",
      "contamination: 0.035 \t tp: 69/support: 83/predicted: 6202 -> fp = 6133\n",
      "AUC : 89.8% \t precision: 0.0111 \t recall: 0.831 \t f1: 0.5020368831245624\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:02:47.571216 seconds\n",
      "contamination: 0.05500000000000001 \t tp: 69/support: 83/predicted: 9690 -> fp = 9621\n",
      "AUC : 88.8% \t precision: 0.00712 \t recall: 0.831 \t f1: 0.49290118672850364\n",
      "--------------------\n",
      "Finished trainning in 0:02:48.277550 seconds\n",
      "contamination: 0.07500000000000001 \t tp: 69/support: 83/predicted: 13302 -> fp = 13233\n",
      "AUC : 87.8% \t precision: 0.00519 \t recall: 0.831 \t f1: 0.4854790605344725\n",
      "--------------------\n",
      "Finished trainning in 0:02:47.665933 seconds\n",
      "contamination: 0.09500000000000001 \t tp: 82/support: 83/predicted: 16476 -> fp = 16394\n",
      "AUC : 94.7% \t precision: 0.00498 \t recall: 0.988 \t f1: 0.4803684628418194\n",
      "--------------------\n",
      "Finished trainning in 0:02:47.954312 seconds\n",
      "contamination: 0.11500000000000002 \t tp: 82/support: 83/predicted: 20346 -> fp = 20264\n",
      "AUC : 93.6% \t precision: 0.00403 \t recall: 0.988 \t f1: 0.4732706944394158\n",
      "--------------------\n",
      "Finished trainning in 0:02:47.247301 seconds\n",
      "contamination: 0.135 \t tp: 82/support: 83/predicted: 23824 -> fp = 23742\n",
      "AUC : 92.6% \t precision: 0.00344 \t recall: 0.988 \t f1: 0.46702626203345626\n",
      "--------------------\n",
      "Finished trainning in 0:02:46.016475 seconds\n",
      "contamination: 0.15500000000000003 \t tp: 82/support: 83/predicted: 27307 -> fp = 27225\n",
      "AUC : 91.6% \t precision: 0.003 \t recall: 0.988 \t f1: 0.4607991643133824\n",
      "--------------------\n",
      "Finished trainning in 0:02:45.972739 seconds\n",
      "contamination: 0.17500000000000002 \t tp: 82/support: 83/predicted: 30844 -> fp = 30762\n",
      "AUC : 90.6% \t precision: 0.00266 \t recall: 0.988 \t f1: 0.4544466833249617\n",
      "--------------------\n",
      "Finished trainning in 0:02:49.785179 seconds\n",
      "contamination: 0.19500000000000003 \t tp: 82/support: 83/predicted: 34330 -> fp = 34248\n",
      "AUC : 89.6% \t precision: 0.00239 \t recall: 0.988 \t f1: 0.44812285295516446\n",
      "--------------------\n",
      "Finished trainning in 0:02:56.170798 seconds\n",
      "contamination: 0.21500000000000005 \t tp: 82/support: 83/predicted: 37872 -> fp = 37790\n",
      "AUC : 88.6% \t precision: 0.00217 \t recall: 0.988 \t f1: 0.4416094035269718\n",
      "--------------------\n",
      "Finished trainning in 0:02:51.104140 seconds\n",
      "contamination: 0.23500000000000004 \t tp: 83/support: 83/predicted: 41489 -> fp = 41406\n",
      "AUC : 88.2% \t precision: 0.002 \t recall: 1.0 \t f1: 0.4348753269562396\n",
      "--------------------\n",
      "Finished trainning in 0:02:58.493736 seconds\n",
      "contamination: 0.255 \t tp: 83/support: 83/predicted: 44844 -> fp = 44761\n",
      "AUC : 87.2% \t precision: 0.00185 \t recall: 1.0 \t f1: 0.42848967788175407\n",
      "--------------------\n",
      "Finished trainning in 0:02:52.620305 seconds\n",
      "contamination: 0.275 \t tp: 83/support: 83/predicted: 48327 -> fp = 48244\n",
      "AUC : 86.2% \t precision: 0.00172 \t recall: 1.0 \t f1: 0.42173547642226694\n",
      "--------------------\n",
      "Finished trainning in 0:02:55.334236 seconds\n",
      "contamination: 0.29500000000000004 \t tp: 83/support: 83/predicted: 51840 -> fp = 51757\n",
      "AUC : 85.2% \t precision: 0.0016 \t recall: 1.0 \t f1: 0.414784427203896\n",
      "--------------------\n",
      "Finished trainning in 0:02:54.434614 seconds\n",
      "contamination: 0.31500000000000006 \t tp: 83/support: 83/predicted: 55230 -> fp = 55147\n",
      "AUC : 84.2% \t precision: 0.0015 \t recall: 1.0 \t f1: 0.4079362268886954\n",
      "--------------------\n",
      "Finished trainning in 0:02:52.241363 seconds\n",
      "contamination: 0.3350000000000001 \t tp: 83/support: 83/predicted: 58669 -> fp = 58586\n",
      "AUC : 83.3% \t precision: 0.00141 \t recall: 1.0 \t f1: 0.400840037597673\n",
      "--------------------\n",
      "Finished trainning in 0:02:47.802618 seconds\n",
      "contamination: 0.3550000000000001 \t tp: 83/support: 83/predicted: 62292 -> fp = 62209\n",
      "AUC : 82.2% \t precision: 0.00133 \t recall: 1.0 \t f1: 0.39319337813086674\n",
      "--------------------\n",
      "Finished trainning in 0:02:46.103077 seconds\n",
      "contamination: 0.3750000000000001 \t tp: 83/support: 83/predicted: 65859 -> fp = 65776\n",
      "AUC : 81.2% \t precision: 0.00126 \t recall: 1.0 \t f1: 0.38548521599005897\n",
      "--------------------\n",
      "Finished trainning in 0:02:46.690750 seconds\n",
      "contamination: 0.39500000000000013 \t tp: 83/support: 83/predicted: 69217 -> fp = 69134\n",
      "AUC : 80.2% \t precision: 0.0012 \t recall: 1.0 \t f1: 0.37805812566123775\n",
      "--------------------\n",
      "Time for IF fitting: 3240.657\n",
      "3 0.09500000000000001 0.25 500\n",
      "Finished trainning in 0:00:37.754807 seconds\n",
      "contamination: 0.030000000000000002 \t tp: 72/support: 85/predicted: 5292 -> fp = 5220\n",
      "AUC : 90.9% \t precision: 0.0136 \t recall: 0.847 \t f1: 0.5057983202514095\n",
      "--------------------\n",
      "Finished trainning in 0:00:37.065333 seconds\n",
      "contamination: 0.05 \t tp: 72/support: 85/predicted: 8723 -> fp = 8651\n",
      "AUC : 89.9% \t precision: 0.00825 \t recall: 0.847 \t f1: 0.4954782444146944\n",
      "--------------------\n",
      "Finished trainning in 0:00:38.681907 seconds\n",
      "contamination: 0.07 \t tp: 83/support: 85/predicted: 12150 -> fp = 12067\n",
      "AUC : 95.4% \t precision: 0.00683 \t recall: 0.976 \t f1: 0.48891858550997375\n",
      "--------------------\n",
      "Finished trainning in 0:00:42.152999 seconds\n",
      "contamination: 0.09 \t tp: 83/support: 85/predicted: 15635 -> fp = 15552\n",
      "AUC : 94.4% \t precision: 0.00531 \t recall: 0.976 \t f1: 0.48201594493220157\n",
      "--------------------\n",
      "Finished trainning in 0:00:35.897416 seconds\n",
      "contamination: 0.11 \t tp: 83/support: 85/predicted: 19163 -> fp = 19080\n",
      "AUC : 93.4% \t precision: 0.00433 \t recall: 0.976 \t f1: 0.4754669708614452\n",
      "--------------------\n",
      "Finished trainning in 0:00:38.156715 seconds\n",
      "contamination: 0.13 \t tp: 84/support: 85/predicted: 22694 -> fp = 22610\n",
      "AUC : 92.9% \t precision: 0.0037 \t recall: 0.988 \t f1: 0.4691390409912044\n",
      "--------------------\n",
      "Finished trainning in 0:00:37.122702 seconds\n",
      "contamination: 0.15 \t tp: 84/support: 85/predicted: 26183 -> fp = 26099\n",
      "AUC : 92.0% \t precision: 0.00321 \t recall: 0.988 \t f1: 0.4628884288780981\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.188523 seconds\n",
      "contamination: 0.17 \t tp: 84/support: 85/predicted: 29575 -> fp = 29491\n",
      "AUC : 91.0% \t precision: 0.00284 \t recall: 0.988 \t f1: 0.45680176815187135\n",
      "--------------------\n",
      "Finished trainning in 0:00:37.338115 seconds\n",
      "contamination: 0.19 \t tp: 84/support: 85/predicted: 33021 -> fp = 32937\n",
      "AUC : 90.0% \t precision: 0.00254 \t recall: 0.988 \t f1: 0.45056954090115464\n",
      "--------------------\n",
      "Finished trainning in 0:00:35.993029 seconds\n",
      "contamination: 0.21 \t tp: 84/support: 85/predicted: 36367 -> fp = 36283\n",
      "AUC : 89.0% \t precision: 0.00231 \t recall: 0.988 \t f1: 0.44444662417366576\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.640702 seconds\n",
      "contamination: 0.23 \t tp: 85/support: 85/predicted: 40160 -> fp = 40075\n",
      "AUC : 88.5% \t precision: 0.00212 \t recall: 1.0 \t f1: 0.4374267658562535\n",
      "--------------------\n",
      "Finished trainning in 0:00:34.790529 seconds\n",
      "contamination: 0.25 \t tp: 85/support: 85/predicted: 43501 -> fp = 43416\n",
      "AUC : 87.6% \t precision: 0.00195 \t recall: 1.0 \t f1: 0.4311080773365523\n",
      "--------------------\n",
      "Finished trainning in 0:00:37.182069 seconds\n",
      "contamination: 0.27 \t tp: 85/support: 85/predicted: 46885 -> fp = 46800\n",
      "AUC : 86.6% \t precision: 0.00181 \t recall: 1.0 \t f1: 0.42459315593033553\n",
      "--------------------\n",
      "Finished trainning in 0:00:37.121021 seconds\n",
      "contamination: 0.29000000000000004 \t tp: 85/support: 85/predicted: 50412 -> fp = 50327\n",
      "AUC : 85.6% \t precision: 0.00169 \t recall: 1.0 \t f1: 0.4176696730913289\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.217582 seconds\n",
      "contamination: 0.31000000000000005 \t tp: 85/support: 85/predicted: 54021 -> fp = 53936\n",
      "AUC : 84.6% \t precision: 0.00157 \t recall: 1.0 \t f1: 0.4104345559811961\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.948115 seconds\n",
      "contamination: 0.33 \t tp: 85/support: 85/predicted: 57553 -> fp = 57468\n",
      "AUC : 83.6% \t precision: 0.00148 \t recall: 1.0 \t f1: 0.40319716113619974\n",
      "--------------------\n",
      "Finished trainning in 0:00:37.698272 seconds\n",
      "contamination: 0.35000000000000003 \t tp: 85/support: 85/predicted: 61033 -> fp = 60948\n",
      "AUC : 82.6% \t precision: 0.00139 \t recall: 1.0 \t f1: 0.3959064257755391\n",
      "--------------------\n",
      "Finished trainning in 0:00:35.797680 seconds\n",
      "contamination: 0.37000000000000005 \t tp: 85/support: 85/predicted: 64554 -> fp = 64469\n",
      "AUC : 81.6% \t precision: 0.00132 \t recall: 1.0 \t f1: 0.38836011166623663\n",
      "--------------------\n",
      "Finished trainning in 0:00:36.500214 seconds\n",
      "contamination: 0.39 \t tp: 85/support: 85/predicted: 67943 -> fp = 67858\n",
      "AUC : 80.6% \t precision: 0.00125 \t recall: 1.0 \t f1: 0.380927909257502\n",
      "--------------------\n",
      "Time for IF fitting: 709.952\n",
      "4 0.07 0.5 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:01:14.918179 seconds\n",
      "contamination: 0.025 \t tp: 72/support: 84/predicted: 4380 -> fp = 4308\n",
      "AUC : 91.6% \t precision: 0.0164 \t recall: 0.857 \t f1: 0.509878127902689\n",
      "--------------------\n",
      "Finished trainning in 0:01:23.039725 seconds\n",
      "contamination: 0.045 \t tp: 72/support: 84/predicted: 7789 -> fp = 7717\n",
      "AUC : 90.7% \t precision: 0.00924 \t recall: 0.857 \t f1: 0.4978501288573451\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.786522 seconds\n",
      "contamination: 0.065 \t tp: 72/support: 84/predicted: 11229 -> fp = 11157\n",
      "AUC : 89.7% \t precision: 0.00641 \t recall: 0.857 \t f1: 0.489876365751046\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.050449 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 83/support: 84/predicted: 14419 -> fp = 14336\n",
      "AUC : 95.3% \t precision: 0.00576 \t recall: 0.988 \t f1: 0.48435703740389635\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.361963 seconds\n",
      "contamination: 0.10499999999999998 \t tp: 83/support: 84/predicted: 18434 -> fp = 18351\n",
      "AUC : 94.2% \t precision: 0.0045 \t recall: 0.988 \t f1: 0.4768015501682883\n",
      "--------------------\n",
      "Finished trainning in 0:01:12.590683 seconds\n",
      "contamination: 0.12499999999999997 \t tp: 84/support: 84/predicted: 21946 -> fp = 21862\n",
      "AUC : 93.8% \t precision: 0.00383 \t recall: 1.0 \t f1: 0.47048513703612344\n",
      "--------------------\n",
      "Finished trainning in 0:01:13.935838 seconds\n",
      "contamination: 0.145 \t tp: 84/support: 84/predicted: 25376 -> fp = 25292\n",
      "AUC : 92.8% \t precision: 0.00331 \t recall: 1.0 \t f1: 0.46433505285137905\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.690160 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 84/support: 84/predicted: 28785 -> fp = 28701\n",
      "AUC : 91.8% \t precision: 0.00292 \t recall: 1.0 \t f1: 0.4582242730484324\n",
      "--------------------\n",
      "Finished trainning in 0:01:14.717606 seconds\n",
      "contamination: 0.18499999999999997 \t tp: 84/support: 84/predicted: 32306 -> fp = 32222\n",
      "AUC : 90.8% \t precision: 0.0026 \t recall: 1.0 \t f1: 0.45186989605757294\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.958021 seconds\n",
      "contamination: 0.20499999999999996 \t tp: 84/support: 84/predicted: 35757 -> fp = 35673\n",
      "AUC : 89.8% \t precision: 0.00235 \t recall: 1.0 \t f1: 0.4455708237946594\n",
      "--------------------\n",
      "Finished trainning in 0:01:13.741861 seconds\n",
      "contamination: 0.22499999999999995 \t tp: 84/support: 84/predicted: 39313 -> fp = 39229\n",
      "AUC : 88.8% \t precision: 0.00214 \t recall: 1.0 \t f1: 0.438985244092995\n",
      "--------------------\n",
      "Finished trainning in 0:01:12.501607 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 84/support: 84/predicted: 42797 -> fp = 42713\n",
      "AUC : 87.8% \t precision: 0.00196 \t recall: 1.0 \t f1: 0.4324238872535941\n",
      "--------------------\n",
      "Finished trainning in 0:01:16.350878 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 84/support: 84/predicted: 46257 -> fp = 46173\n",
      "AUC : 86.8% \t precision: 0.00182 \t recall: 1.0 \t f1: 0.4257884394529689\n",
      "--------------------\n",
      "Finished trainning in 0:01:13.877633 seconds\n",
      "contamination: 0.285 \t tp: 84/support: 84/predicted: 49703 -> fp = 49619\n",
      "AUC : 85.8% \t precision: 0.00169 \t recall: 1.0 \t f1: 0.41905138184461993\n",
      "--------------------\n",
      "Finished trainning in 0:01:13.926187 seconds\n",
      "contamination: 0.305 \t tp: 84/support: 84/predicted: 53177 -> fp = 53093\n",
      "AUC : 84.8% \t precision: 0.00158 \t recall: 1.0 \t f1: 0.4121205875866883\n",
      "--------------------\n",
      "Finished trainning in 0:01:11.192269 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 84/support: 84/predicted: 56678 -> fp = 56594\n",
      "AUC : 83.8% \t precision: 0.00148 \t recall: 1.0 \t f1: 0.4049860627350301\n",
      "--------------------\n",
      "Finished trainning in 0:01:13.137276 seconds\n",
      "contamination: 0.345 \t tp: 84/support: 84/predicted: 60043 -> fp = 59959\n",
      "AUC : 82.9% \t precision: 0.0014 \t recall: 1.0 \t f1: 0.3979791594056768\n",
      "--------------------\n",
      "Finished trainning in 0:01:11.539113 seconds\n",
      "contamination: 0.365 \t tp: 84/support: 84/predicted: 63656 -> fp = 63572\n",
      "AUC : 81.8% \t precision: 0.00132 \t recall: 1.0 \t f1: 0.39028436837888797\n",
      "--------------------\n",
      "Finished trainning in 0:01:15.832001 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 84/support: 84/predicted: 67138 -> fp = 67054\n",
      "AUC : 80.8% \t precision: 0.00125 \t recall: 1.0 \t f1: 0.3826924888680769\n",
      "--------------------\n",
      "Time for IF fitting: 1420.670\n",
      "5 0.08499999999999999 0.5 200\n",
      "Finished trainning in 0:05:41.905716 seconds\n",
      "contamination: 0.020000000000000004 \t tp: 61/support: 71/predicted: 3488 -> fp = 3427\n",
      "AUC : 92.0% \t precision: 0.0175 \t recall: 0.859 \t f1: 0.5121794058213406\n",
      "--------------------\n",
      "Finished trainning in 0:05:37.505343 seconds\n",
      "contamination: 0.04000000000000001 \t tp: 61/support: 71/predicted: 6995 -> fp = 6934\n",
      "AUC : 91.0% \t precision: 0.00872 \t recall: 0.859 \t f1: 0.49850890608431636\n",
      "--------------------\n",
      "Finished trainning in 0:05:42.856066 seconds\n",
      "contamination: 0.06000000000000001 \t tp: 61/support: 71/predicted: 10602 -> fp = 10541\n",
      "AUC : 89.9% \t precision: 0.00575 \t recall: 0.859 \t f1: 0.4901690476319307\n",
      "--------------------\n",
      "Finished trainning in 0:05:33.282250 seconds\n",
      "contamination: 0.08000000000000002 \t tp: 70/support: 71/predicted: 14070 -> fp = 14000\n",
      "AUC : 95.3% \t precision: 0.00498 \t recall: 0.986 \t f1: 0.48410744549581386\n",
      "--------------------\n",
      "Finished trainning in 0:05:33.896201 seconds\n",
      "contamination: 0.10000000000000002 \t tp: 70/support: 71/predicted: 17537 -> fp = 17467\n",
      "AUC : 94.3% \t precision: 0.00399 \t recall: 0.986 \t f1: 0.47770036837666396\n",
      "--------------------\n",
      "Finished trainning in 0:05:48.140407 seconds\n",
      "contamination: 0.12000000000000002 \t tp: 70/support: 71/predicted: 20924 -> fp = 20854\n",
      "AUC : 93.3% \t precision: 0.00335 \t recall: 0.986 \t f1: 0.47164142857518315\n",
      "--------------------\n",
      "Finished trainning in 0:05:45.973506 seconds\n",
      "contamination: 0.14 \t tp: 70/support: 71/predicted: 24344 -> fp = 24274\n",
      "AUC : 92.4% \t precision: 0.00288 \t recall: 0.986 \t f1: 0.46558964126293495\n",
      "--------------------\n",
      "Finished trainning in 0:05:47.887442 seconds\n",
      "contamination: 0.16000000000000003 \t tp: 70/support: 71/predicted: 27889 -> fp = 27819\n",
      "AUC : 91.3% \t precision: 0.00251 \t recall: 0.986 \t f1: 0.4593120620713932\n",
      "--------------------\n",
      "Finished trainning in 0:05:49.267324 seconds\n",
      "contamination: 0.18000000000000005 \t tp: 70/support: 71/predicted: 31335 -> fp = 31265\n",
      "AUC : 90.4% \t precision: 0.00223 \t recall: 0.986 \t f1: 0.4531623089078516\n",
      "--------------------\n",
      "Finished trainning in 0:05:48.012582 seconds\n",
      "contamination: 0.20000000000000007 \t tp: 70/support: 71/predicted: 34827 -> fp = 34757\n",
      "AUC : 89.4% \t precision: 0.00201 \t recall: 0.986 \t f1: 0.44685472665417764\n",
      "--------------------\n",
      "Finished trainning in 0:05:43.252927 seconds\n",
      "contamination: 0.22000000000000003 \t tp: 71/support: 71/predicted: 38295 -> fp = 38224\n",
      "AUC : 89.1% \t precision: 0.00185 \t recall: 1.0 \t f1: 0.44052499877196755\n",
      "--------------------\n",
      "Finished trainning in 0:05:56.960549 seconds\n",
      "contamination: 0.24000000000000005 \t tp: 71/support: 71/predicted: 41768 -> fp = 41697\n",
      "AUC : 88.1% \t precision: 0.0017 \t recall: 1.0 \t f1: 0.4340454845708745\n",
      "--------------------\n",
      "Finished trainning in 0:05:49.545037 seconds\n",
      "contamination: 0.26000000000000006 \t tp: 71/support: 71/predicted: 45314 -> fp = 45243\n",
      "AUC : 87.1% \t precision: 0.00157 \t recall: 1.0 \t f1: 0.42730521268244454\n",
      "--------------------\n",
      "Finished trainning in 0:05:34.147464 seconds\n",
      "contamination: 0.2800000000000001 \t tp: 71/support: 71/predicted: 48777 -> fp = 48706\n",
      "AUC : 86.1% \t precision: 0.00146 \t recall: 1.0 \t f1: 0.42059110682835965\n",
      "--------------------\n",
      "Finished trainning in 0:05:28.406270 seconds\n",
      "contamination: 0.30000000000000004 \t tp: 71/support: 71/predicted: 52375 -> fp = 52304\n",
      "AUC : 85.1% \t precision: 0.00136 \t recall: 1.0 \t f1: 0.41346797923360984\n",
      "--------------------\n",
      "Finished trainning in 0:05:22.572972 seconds\n",
      "contamination: 0.32000000000000006 \t tp: 71/support: 71/predicted: 55800 -> fp = 55729\n",
      "AUC : 84.1% \t precision: 0.00127 \t recall: 1.0 \t f1: 0.4065396503094562\n",
      "--------------------\n",
      "Finished trainning in 0:05:29.749372 seconds\n",
      "contamination: 0.3400000000000001 \t tp: 71/support: 71/predicted: 59302 -> fp = 59231\n",
      "AUC : 83.1% \t precision: 0.0012 \t recall: 1.0 \t f1: 0.3992986438789072\n",
      "--------------------\n",
      "Finished trainning in 0:05:24.807781 seconds\n",
      "contamination: 0.3600000000000001 \t tp: 71/support: 71/predicted: 62807 -> fp = 62736\n",
      "AUC : 82.1% \t precision: 0.00113 \t recall: 1.0 \t f1: 0.3918847709088864\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished trainning in 0:05:23.744751 seconds\n",
      "contamination: 0.3800000000000001 \t tp: 71/support: 71/predicted: 66336 -> fp = 66265\n",
      "AUC : 81.1% \t precision: 0.00107 \t recall: 1.0 \t f1: 0.38424376868928994\n",
      "--------------------\n",
      "Time for IF fitting: 6446.468\n",
      "6 0.08000000000000002 0.25 1000\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 1.0\n",
    "\n",
    "dfsf_frac = dfsf_normal.sample(frac = frac_normal, random_state = 1).append(dfsf_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsf_frac.loc[dfsf_frac[\"target\"]=='normal.'])/len(dfsf_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsf_frac)} records\")\n",
    "\n",
    "dfsf_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsf_frac[\"target\"]]\n",
    "toDecode = toDecodeSF\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsf_frac[f] = leSF.fit_transform(dfsf_frac[f])\n",
    "        \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),(2, 0.25, 200),(3, 0.25, 500),(4, 0.5, 100),(5, 0.5, 200),(6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsf_frac.drop([\"target\", \"binary_target\"], axis=1), dfsf_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    \n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False)\n",
    "    \n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00       108\n",
      "           1       1.00      0.62      0.76    174899\n",
      "\n",
      "    accuracy                           0.62    175007\n",
      "   macro avg       0.50      0.81      0.38    175007\n",
      "weighted avg       1.00      0.62      0.76    175007\n",
      "\n",
      "---0.7617642545745462, 0.3827184685760214\n",
      "---0.8079062773372061\n",
      "---0.8079062773372061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        89\n",
      "           1       1.00      0.62      0.77    174918\n",
      "\n",
      "    accuracy                           0.62    175007\n",
      "   macro avg       0.50      0.81      0.38    175007\n",
      "weighted avg       1.00      0.62      0.77    175007\n",
      "\n",
      "---0.7651349385128543, 0.3840972585214536\n",
      "---0.8100595707703038\n",
      "---0.8100595707703038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        83\n",
      "           1       1.00      0.60      0.75    174924\n",
      "\n",
      "    accuracy                           0.60    175007\n",
      "   macro avg       0.50      0.80      0.38    175007\n",
      "weighted avg       1.00      0.60      0.75    175007\n",
      "\n",
      "---0.7533645402352, 0.37805812566123775\n",
      "---0.8023884658480254\n",
      "---0.8023884658480254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        85\n",
      "           1       1.00      0.61      0.76    174922\n",
      "\n",
      "    accuracy                           0.61    175007\n",
      "   macro avg       0.50      0.81      0.38    175007\n",
      "weighted avg       1.00      0.61      0.76    175007\n",
      "\n",
      "---0.7589892455242798, 0.380927909257502\n",
      "---0.8060335463806725\n",
      "---0.8060335463806725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        84\n",
      "           1       1.00      0.62      0.76    174923\n",
      "\n",
      "    accuracy                           0.62    175007\n",
      "   macro avg       0.50      0.81      0.38    175007\n",
      "weighted avg       1.00      0.62      0.76    175007\n",
      "\n",
      "---0.7625208249447452, 0.3826924888680769\n",
      "---0.8083328092932318\n",
      "---0.8083328092932318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      1.00      0.00        71\n",
      "           1       1.00      0.62      0.77    174936\n",
      "\n",
      "    accuracy                           0.62    175007\n",
      "   macro avg       0.50      0.81      0.38    175007\n",
      "weighted avg       1.00      0.62      0.77    175007\n",
      "\n",
      "---0.7660391697182631, 0.38424376868928994\n",
      "---0.8106021630767823\n",
      "---0.8106021630767823\n",
      "0.8075538054510369 \\pm 0.0030097956183714448\n",
      "0.7613021622516482 \\pm 0.0046299785905639145\n",
      "0.8075538054510369 \\pm 0.0030097956183714448\n"
     ]
    }
   ],
   "source": [
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-7ec3b3eb478a>:30: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax = plt.axes()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = []\n",
    "Y.append((0.8097585919733324, 0.0032902212447014183))\n",
    "# 0.7615084312343328 \\pm 0.004667842728500686\n",
    "# 0.8097585919733324 \\pm 0.0032902212447014183\n",
    "\n",
    "Y.append((0.8083069600363969, 0.003814378339180022))\n",
    "# 0.7610577282162615 \\pm 0.005833314667089402\n",
    "# 0.8083069600363969 \\pm 0.003814378339180022\n",
    "\n",
    "Y.append((0.807408383400336, 0.0032999139284239994))\n",
    "# 0.7607621067794785 \\pm 0.005068633584238468\n",
    "# 0.807408383400336 \\pm 0.0032999139284239994\n",
    "\n",
    "Y.append((0.8074497577708623, 0.0034199305418666334))\n",
    "# 0.7610049085667185 \\pm 0.00523968813112115\n",
    "# 0.8074497577708623 \\pm 0.0034199305418666334\n",
    "\n",
    "Y.append((0.8075538054510369, 0.0030097956183714448))\n",
    "# 0.7613021622516482 \\pm 0.0046299785905639145\n",
    "# 0.8075538054510369 \\pm 0.0030097956183714448\n",
    "\n",
    "Y_mean = np.array([a for a, b in Y])\n",
    "Y_std_dev = np.array([b for a, b in Y])\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.rc('font', size=30)\n",
    "\n",
    "plt.title('AUC score after parameter tuning')\n",
    "plt.ylabel(\"Score\")\n",
    "ax = plt.axes()\n",
    "ax.set_ylim(0.75, 0.85)\n",
    "pad = 0.005\n",
    "\n",
    "labels = [\"10%\", \"20%\", \"50%\", \"70%\", \"100%\"]\n",
    "colors = {'1': 'r', '2':'b', '3':'c', '4':'y'}\n",
    "scorer = 'AUC'\n",
    "\n",
    "\n",
    "# Y_axis = np.array([best_score_1, best_score_2, best_score_3, best_score_4])\n",
    "# \n",
    "# X_axis = np.array(labels)\n",
    "# Y_axis = [a for a,b in stat_auc]\n",
    "# Y_std_dev = [b for a,b in stat_auc]\n",
    "\n",
    "ax.plot(X_axis, Y_mean, '-', color=colors['1'],label=\"%s \" % (\"AUC\"), linewidth=5)\n",
    "ax.fill_between(X_axis, Y_mean - Y_std_dev,\n",
    "                        Y_mean + Y_std_dev,\n",
    "                        alpha=0.1, color=colors['1'])\n",
    "# ax.plot(X_axis, Y_axis_recall, '-', color=colors['2'],label=\"%s \" % (\"Recall\"), linewidth=5)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"IF_graph_v2_AUC_normal_data.png\", dpi=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3925650\n"
     ]
    }
   ],
   "source": [
    "# dfsf = df[df[\"logged_in\"]== 1]\n",
    "print(len(df)- len(df.loc[df[\"target\"]=='normal.']))\n",
    "dfsa = df[sa_columns + [\"target\"]] \n",
    "# print(dfsf.head(1))\n",
    "# Split the dataset into 2 classes for consistent anomaly_rate when sampling\n",
    "dfsa_normal = dfsa.loc[dfsa[\"target\"]=='normal.']\n",
    "\n",
    "r = 0.034\n",
    "target_anomaly_rate = r\n",
    "n_records = int(np.ceil(len(dfsa_normal)*r/(1-r)))\n",
    "\n",
    "dfsa_attack = df.loc[df[\"target\"]!='normal.'].sample(n = n_records, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 3.4% out of 100702 records\n",
      "Finished trainning in 0:00:08.475088 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 350/support: 807/predicted: 1073 -> fp = 723\n",
      "AUC : 70.2% \t precision: 0.326 \t recall: 0.434 \t f1: 0.6739982371924305\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.119673 seconds\n",
      "contamination: 0.065 \t tp: 403/support: 807/predicted: 1572 -> fp = 1169\n",
      "AUC : 72.6% \t precision: 0.256 \t recall: 0.499 \t f1: 0.6530042684529174\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.727646 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 404/support: 807/predicted: 2127 -> fp = 1723\n",
      "AUC : 71.5% \t precision: 0.19 \t recall: 0.501 \t f1: 0.6152783308798458\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.850091 seconds\n",
      "contamination: 0.105 \t tp: 404/support: 807/predicted: 2331 -> fp = 1927\n",
      "AUC : 71.1% \t precision: 0.173 \t recall: 0.501 \t f1: 0.6040695386313536\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.204702 seconds\n",
      "contamination: 0.125 \t tp: 807/support: 807/predicted: 3105 -> fp = 2298\n",
      "AUC : 95.3% \t precision: 0.26 \t recall: 1.0 \t f1: 0.6815467414910987\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.950163 seconds\n",
      "contamination: 0.145 \t tp: 807/support: 807/predicted: 3591 -> fp = 2784\n",
      "AUC : 94.3% \t precision: 0.225 \t recall: 1.0 \t f1: 0.6532013358634154\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.902384 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 807/support: 807/predicted: 4097 -> fp = 3290\n",
      "AUC : 93.2% \t precision: 0.197 \t recall: 1.0 \t f1: 0.6283643311194724\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.991187 seconds\n",
      "contamination: 0.185 \t tp: 807/support: 807/predicted: 4615 -> fp = 3808\n",
      "AUC : 92.2% \t precision: 0.175 \t recall: 1.0 \t f1: 0.6064610361968858\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.727215 seconds\n",
      "contamination: 0.205 \t tp: 807/support: 807/predicted: 5159 -> fp = 4352\n",
      "AUC : 91.1% \t precision: 0.156 \t recall: 1.0 \t f1: 0.5862420430502718\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.841684 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 807/support: 807/predicted: 5676 -> fp = 4869\n",
      "AUC : 90.0% \t precision: 0.142 \t recall: 1.0 \t f1: 0.5689846391662763\n",
      "--------------------\n",
      "Finished trainning in 0:00:09.080644 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 807/support: 807/predicted: 6200 -> fp = 5393\n",
      "AUC : 88.9% \t precision: 0.13 \t recall: 1.0 \t f1: 0.5529603695580987\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.913177 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 807/support: 807/predicted: 6704 -> fp = 5897\n",
      "AUC : 87.9% \t precision: 0.12 \t recall: 1.0 \t f1: 0.5386181606503905\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.763802 seconds\n",
      "contamination: 0.285 \t tp: 807/support: 807/predicted: 7231 -> fp = 6424\n",
      "AUC : 86.8% \t precision: 0.112 \t recall: 1.0 \t f1: 0.5244894262768464\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.130851 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 807/support: 807/predicted: 7774 -> fp = 6967\n",
      "AUC : 85.7% \t precision: 0.104 \t recall: 1.0 \t f1: 0.5106498046290993\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.169019 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 807/support: 807/predicted: 8303 -> fp = 7496\n",
      "AUC : 84.6% \t precision: 0.0972 \t recall: 1.0 \t f1: 0.49770574272568896\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.156389 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 807/support: 807/predicted: 8774 -> fp = 7967\n",
      "AUC : 83.7% \t precision: 0.092 \t recall: 1.0 \t f1: 0.48652495306193044\n",
      "--------------------\n",
      "Finished trainning in 0:00:07.989879 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 807/support: 807/predicted: 9235 -> fp = 8428\n",
      "AUC : 82.7% \t precision: 0.0874 \t recall: 1.0 \t f1: 0.4758226611713809\n",
      "--------------------\n",
      "Finished trainning in 0:00:08.275734 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 807/support: 807/predicted: 9761 -> fp = 8954\n",
      "AUC : 81.6% \t precision: 0.0827 \t recall: 1.0 \t f1: 0.4638299276349669\n",
      "--------------------\n",
      "Time for IF fitting: 148.071\n",
      "1 0.125 0.25 100\n",
      "Time for IF fitting: 297.850\n",
      "2 0.13999999999999999 0.25 200\n",
      "Time for IF fitting: 772.154\n",
      "3 0.135 0.25 500\n",
      "Time for IF fitting: 162.368\n",
      "4 0.13 0.5 100\n",
      "Time for IF fitting: 323.791\n",
      "5 0.145 0.5 200\n",
      "Time for IF fitting: 1523.364\n",
      "6 0.12000000000000002 0.25 1000\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.1\n",
    "\n",
    "dfsa_frac = dfsa_normal.sample(frac = frac_normal, random_state = 1).append(dfsa_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsa_frac.loc[dfsa_frac[\"target\"]=='normal.'])/len(dfsa_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsa_frac)} records\")\n",
    "\n",
    "dfsa_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsa_frac[\"target\"]]\n",
    "toDecode = toDecodeSA\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsa_frac[f] = leSF.fit_transform(dfsa_frac[f])\n",
    "    \n",
    "    \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),\n",
    "                           (2, 0.25, 200),\n",
    "                           (3, 0.25, 500),\n",
    "                           (4, 0.5, 100),\n",
    "                           (5, 0.5, 200),\n",
    "                           (6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsa_frac.drop([\"target\", \"binary_target\"], axis=1), dfsa_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False if rs == 1 else True)\n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      1.00      0.15       807\n",
      "           1       1.00      0.63      0.77     24369\n",
      "\n",
      "    accuracy                           0.64     25176\n",
      "   macro avg       0.54      0.82      0.46     25176\n",
      "weighted avg       0.97      0.64      0.75     25176\n",
      "\n",
      "---0.754990135765767, 0.4638299276349669\n",
      "---0.8162829824777381\n",
      "---0.8162829824777381\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      1.00      0.16       846\n",
      "           1       1.00      0.64      0.78     24330\n",
      "\n",
      "    accuracy                           0.65     25176\n",
      "   macro avg       0.54      0.82      0.47     25176\n",
      "weighted avg       0.97      0.65      0.76     25176\n",
      "\n",
      "---0.7609563528578557, 0.47215782586256116\n",
      "---0.820859021783806\n",
      "---0.820859021783806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      1.00      0.16       868\n",
      "           1       1.00      0.62      0.77     24308\n",
      "\n",
      "    accuracy                           0.63     25176\n",
      "   macro avg       0.54      0.81      0.46     25176\n",
      "weighted avg       0.97      0.63      0.75     25176\n",
      "\n",
      "---0.7453587345214268, 0.46246089598535844\n",
      "---0.8105767648510778\n",
      "---0.8105767648510778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      1.00      0.16       821\n",
      "           1       1.00      0.63      0.78     24355\n",
      "\n",
      "    accuracy                           0.64     25176\n",
      "   macro avg       0.54      0.82      0.47     25176\n",
      "weighted avg       0.97      0.64      0.75     25176\n",
      "\n",
      "---0.7548666378117821, 0.46509738307660176\n",
      "---0.8163826729624307\n",
      "---0.8163826729624307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      1.00      0.15       800\n",
      "           1       1.00      0.64      0.78     24376\n",
      "\n",
      "    accuracy                           0.65     25176\n",
      "   macro avg       0.54      0.82      0.47     25176\n",
      "weighted avg       0.97      0.65      0.76     25176\n",
      "\n",
      "---0.758493898378652, 0.4657715137911057\n",
      "---0.8185715457827372\n",
      "---0.8185715457827372\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.09      1.00      0.17       876\n",
      "           1       1.00      0.64      0.78     24300\n",
      "\n",
      "    accuracy                           0.65     25176\n",
      "   macro avg       0.55      0.82      0.47     25176\n",
      "weighted avg       0.97      0.65      0.76     25176\n",
      "\n",
      "---0.7597680694237746, 0.47416080696922724\n",
      "---0.8204320987654321\n",
      "---0.8204320987654321\n",
      "0.8171841811038703 \\pm 0.0037706956311419778\n",
      "0.7557389714598763 \\pm 0.005658893198695087\n",
      "0.8171841811038703 \\pm 0.0037706956311419778\n"
     ]
    }
   ],
   "source": [
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anomaly rate is 1.7% out of 197980 records\n",
      "Finished trainning in 0:00:17.418979 seconds\n",
      "contamination: 0.045000000000000005 \t tp: 410/support: 843/predicted: 2152 -> fp = 1742\n",
      "AUC : 72.5% \t precision: 0.191 \t recall: 0.486 \t f1: 0.6255661096706049\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.545975 seconds\n",
      "contamination: 0.065 \t tp: 843/support: 843/predicted: 3182 -> fp = 2339\n",
      "AUC : 97.6% \t precision: 0.265 \t recall: 1.0 \t f1: 0.697125930344393\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.956687 seconds\n",
      "contamination: 0.08499999999999999 \t tp: 843/support: 843/predicted: 4161 -> fp = 3318\n",
      "AUC : 96.6% \t precision: 0.203 \t recall: 1.0 \t f1: 0.6508136626910248\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.363566 seconds\n",
      "contamination: 0.105 \t tp: 843/support: 843/predicted: 5179 -> fp = 4336\n",
      "AUC : 95.5% \t precision: 0.163 \t recall: 1.0 \t f1: 0.6166668633848679\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.400438 seconds\n",
      "contamination: 0.125 \t tp: 843/support: 843/predicted: 6144 -> fp = 5301\n",
      "AUC : 94.6% \t precision: 0.137 \t recall: 1.0 \t f1: 0.5918437974283951\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.827344 seconds\n",
      "contamination: 0.145 \t tp: 843/support: 843/predicted: 7107 -> fp = 6264\n",
      "AUC : 93.6% \t precision: 0.119 \t recall: 1.0 \t f1: 0.5716352753921147\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.828714 seconds\n",
      "contamination: 0.16499999999999998 \t tp: 843/support: 843/predicted: 8136 -> fp = 7293\n",
      "AUC : 92.5% \t precision: 0.104 \t recall: 1.0 \t f1: 0.5533740181430771\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.002909 seconds\n",
      "contamination: 0.185 \t tp: 843/support: 843/predicted: 9077 -> fp = 8234\n",
      "AUC : 91.5% \t precision: 0.0929 \t recall: 1.0 \t f1: 0.5387577661824516\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.216419 seconds\n",
      "contamination: 0.205 \t tp: 843/support: 843/predicted: 10081 -> fp = 9238\n",
      "AUC : 90.5% \t precision: 0.0836 \t recall: 1.0 \t f1: 0.5247202355797813\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.992084 seconds\n",
      "contamination: 0.22499999999999998 \t tp: 843/support: 843/predicted: 11097 -> fp = 10254\n",
      "AUC : 89.5% \t precision: 0.076 \t recall: 1.0 \t f1: 0.5117058295498169\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.369359 seconds\n",
      "contamination: 0.24499999999999997 \t tp: 843/support: 843/predicted: 12061 -> fp = 11218\n",
      "AUC : 88.5% \t precision: 0.0699 \t recall: 1.0 \t f1: 0.5001728058270828\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.453371 seconds\n",
      "contamination: 0.26499999999999996 \t tp: 843/support: 843/predicted: 13028 -> fp = 12185\n",
      "AUC : 87.5% \t precision: 0.0647 \t recall: 1.0 \t f1: 0.4891980134502338\n",
      "--------------------\n",
      "Finished trainning in 0:00:15.671769 seconds\n",
      "contamination: 0.285 \t tp: 843/support: 843/predicted: 13999 -> fp = 13156\n",
      "AUC : 86.5% \t precision: 0.0602 \t recall: 1.0 \t f1: 0.47862648260909924\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.289994 seconds\n",
      "contamination: 0.30499999999999994 \t tp: 843/support: 843/predicted: 14974 -> fp = 14131\n",
      "AUC : 85.5% \t precision: 0.0563 \t recall: 1.0 \t f1: 0.4683476426866192\n",
      "--------------------\n",
      "Finished trainning in 0:00:17.102846 seconds\n",
      "contamination: 0.32499999999999996 \t tp: 843/support: 843/predicted: 16028 -> fp = 15185\n",
      "AUC : 84.4% \t precision: 0.0526 \t recall: 1.0 \t f1: 0.45751011208509224\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.712475 seconds\n",
      "contamination: 0.3449999999999999 \t tp: 843/support: 843/predicted: 17032 -> fp = 16189\n",
      "AUC : 83.4% \t precision: 0.0495 \t recall: 1.0 \t f1: 0.4473704181536272\n",
      "--------------------\n",
      "Finished trainning in 0:00:17.111973 seconds\n",
      "contamination: 0.36499999999999994 \t tp: 843/support: 843/predicted: 17950 -> fp = 17107\n",
      "AUC : 82.4% \t precision: 0.047 \t recall: 1.0 \t f1: 0.43820101832314073\n",
      "--------------------\n",
      "Finished trainning in 0:00:16.215655 seconds\n",
      "contamination: 0.38499999999999995 \t tp: 843/support: 843/predicted: 18962 -> fp = 18119\n",
      "AUC : 81.4% \t precision: 0.0445 \t recall: 1.0 \t f1: 0.42815571414650166\n",
      "--------------------\n",
      "Time for IF fitting: 291.968\n",
      "1 0.065 0.25 100\n",
      "Time for IF fitting: 576.275\n",
      "2 0.06 0.25 200\n",
      "Time for IF fitting: 1527.106\n",
      "3 0.07500000000000001 0.25 500\n",
      "Time for IF fitting: 317.316\n",
      "4 0.07 0.5 100\n",
      "Time for IF fitting: 610.978\n",
      "5 0.065 0.5 200\n",
      "Time for IF fitting: 2884.242\n",
      "6 0.06000000000000001 0.25 1000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.04      1.00      0.09       843\n",
      "           1       1.00      0.63      0.77     48652\n",
      "\n",
      "    accuracy                           0.63     49495\n",
      "   macro avg       0.52      0.81      0.43     49495\n",
      "weighted avg       0.98      0.63      0.76     49495\n",
      "\n",
      "---0.7594965672172133, 0.42815571414650166\n",
      "---0.8137897722601333\n",
      "---0.8137897722601333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.04      1.00      0.08       824\n",
      "           1       1.00      0.63      0.77     48671\n",
      "\n",
      "    accuracy                           0.64     49495\n",
      "   macro avg       0.52      0.82      0.43     49495\n",
      "weighted avg       0.98      0.64      0.76     49495\n",
      "\n",
      "---0.7620104260567825, 0.42873204789128355\n",
      "---0.8153212385198578\n",
      "---0.8153212385198578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.05      1.00      0.09       878\n",
      "           1       1.00      0.62      0.76     48617\n",
      "\n",
      "    accuracy                           0.62     49495\n",
      "   macro avg       0.52      0.81      0.43     49495\n",
      "weighted avg       0.98      0.62      0.75     49495\n",
      "\n",
      "---0.7518981560442598, 0.4251522627853456\n",
      "---0.8090071374210668\n",
      "---0.8090071374210668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.04      1.00      0.09       857\n",
      "           1       1.00      0.62      0.77     48638\n",
      "\n",
      "    accuracy                           0.63     49495\n",
      "   macro avg       0.52      0.81      0.43     49495\n",
      "weighted avg       0.98      0.63      0.75     49495\n",
      "\n",
      "---0.7543043809454874, 0.4255709297076069\n",
      "---0.8104362843866935\n",
      "---0.8104362843866935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.05      1.00      0.09       875\n",
      "           1       1.00      0.63      0.77     48620\n",
      "\n",
      "    accuracy                           0.63     49495\n",
      "   macro avg       0.52      0.81      0.43     49495\n",
      "weighted avg       0.98      0.63      0.76     49495\n",
      "\n",
      "---0.7594138846736282, 0.42985608440601447\n",
      "---0.8139962978198272\n",
      "---0.8139962978198272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.04      1.00      0.09       850\n",
      "           1       1.00      0.63      0.77     48645\n",
      "\n",
      "    accuracy                           0.63     49495\n",
      "   macro avg       0.52      0.81      0.43     49495\n",
      "weighted avg       0.98      0.63      0.76     49495\n",
      "\n",
      "---0.7587420498181094, 0.4280517139501342\n",
      "---0.8133415561722686\n",
      "---0.8133415561722686\n",
      "0.8126487144299746 \\pm 0.0024040107513679343\n",
      "0.7576442441259135 \\pm 0.0037683859887233427\n",
      "0.8126487144299746 \\pm 0.0024040107513679343\n"
     ]
    }
   ],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.2\n",
    "\n",
    "dfsa_frac = dfsa_normal.sample(frac = frac_normal, random_state = 1).append(dfsa_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsa_frac.loc[dfsa_frac[\"target\"]=='normal.'])/len(dfsa_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsa_frac)} records\")\n",
    "\n",
    "dfsa_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsa_frac[\"target\"]]\n",
    "toDecode = toDecodeSA\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsa_frac[f] = leSF.fit_transform(dfsa_frac[f])\n",
    "    \n",
    "    \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),\n",
    "                           (2, 0.25, 200),\n",
    "                           (3, 0.25, 500),\n",
    "                           (4, 0.5, 100),\n",
    "                           (5, 0.5, 200),\n",
    "                           (6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsa_frac.drop([\"target\", \"binary_target\"], axis=1), dfsa_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False if rs == 1 else True)\n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)\n",
    "    \n",
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.5\n",
    "dfsa_frac = dfsa_normal.sample(frac = frac_normal, random_state = 1).append(dfsa_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsa_frac.loc[dfsa_frac[\"target\"]=='normal.'])/len(dfsa_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsa_frac)} records\")\n",
    "\n",
    "dfsa_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsa_frac[\"target\"]]\n",
    "toDecode = toDecodeSA\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsa_frac[f] = leSF.fit_transform(dfsa_frac[f])\n",
    "    \n",
    "    \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),\n",
    "                           (2, 0.25, 200),\n",
    "                           (3, 0.25, 500),\n",
    "                           (4, 0.5, 100),\n",
    "                           (5, 0.5, 200),\n",
    "                           (6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsa_frac.drop([\"target\", \"binary_target\"], axis=1), dfsa_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False if rs == 1 else True)\n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)\n",
    "    \n",
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 0.7\n",
    "\n",
    "dfsa_frac = dfsa_normal.sample(frac = frac_normal, random_state = 1).append(dfsa_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsa_frac.loc[dfsa_frac[\"target\"]=='normal.'])/len(dfsa_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsa_frac)} records\")\n",
    "\n",
    "dfsa_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsa_frac[\"target\"]]\n",
    "toDecode = toDecodeSA\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsa_frac[f] = leSF.fit_transform(dfsa_frac[f])\n",
    "    \n",
    "    \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),\n",
    "                           (2, 0.25, 200),\n",
    "                           (3, 0.25, 500),\n",
    "                           (4, 0.5, 100),\n",
    "                           (5, 0.5, 200),\n",
    "                           (6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsa_frac.drop([\"target\", \"binary_target\"], axis=1), dfsa_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False if rs == 1 else True)\n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)\n",
    "    \n",
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_oulier = 0.1\n",
    "frac_normal = 1.0\n",
    "\n",
    "dfsa_frac = dfsa_normal.sample(frac = frac_normal, random_state = 1).append(dfsa_attack.sample(frac = frac_oulier, random_state = 1))\n",
    "\n",
    "anomaly_rate = 1.0 - len(dfsa_frac.loc[dfsa_frac[\"target\"]=='normal.'])/len(dfsa_frac)\n",
    "print(f\"anomaly rate is {anomaly_rate:.1%} out of {len(dfsa_frac)} records\")\n",
    "\n",
    "dfsa_frac['binary_target'] = [1 if x=='normal.' else -1 for x in dfsa_frac[\"target\"]]\n",
    "toDecode = toDecodeSA\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfsa_frac[f] = leSF.fit_transform(dfsa_frac[f])\n",
    "    \n",
    "    \n",
    "Y_source = []\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "Y_axis_auc = []\n",
    "best_param = []\n",
    "\n",
    "hyperparameters = [(1, 0.25, 100),\n",
    "                           (2, 0.25, 200),\n",
    "                           (3, 0.25, 500),\n",
    "                           (4, 0.5, 100),\n",
    "                           (5, 0.5, 200),\n",
    "                           (6, 0.25, 1000)]\n",
    "\n",
    "for rs, max_samples, n_estimators in hyperparameters:\n",
    "    contaminations = np.arange(0.05 - (rs * 0.005), 0.4, 0.02)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsa_frac.drop([\"target\", \"binary_target\"], axis=1), dfsa_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "    stime = time.time()\n",
    "    cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=False if rs == 1 else True)\n",
    "    print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "    Y_source.append((y_test, y_pred))\n",
    "    best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "    print(rs, cmax, max_samples, n_estimators)\n",
    "    \n",
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "\n",
    "Y_source_1 = Y_source\n",
    "for y_test, y_pred in Y_source:\n",
    "    f  = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    fm = f1_score(y_test, y_pred, average = 'macro')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"---{f}, {fm}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred, average = 'macro')\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "\n",
    "m = statistics.mean(auc_tuned)\n",
    "s = statistics.stdev(auc_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_auc.append((m, s))\n",
    "m = statistics.mean(f1_tuned)\n",
    "s = statistics.stdev(f1_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_f1.append((m, s))\n",
    "m = statistics.mean(r_tuned)\n",
    "s = statistics.stdev(r_tuned)\n",
    "print(f\"{m} \\pm {s}\")\n",
    "stat_r.append((m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,20))\n",
    "plt.rc('font', size=30)\n",
    "\n",
    "plt.title('AUC score after parameter tuning')\n",
    "plt.ylabel(\"Score\")\n",
    "ax = plt.axes()\n",
    "# ax.set_ylim(0.8, 1)\n",
    "pad = 0.005\n",
    "\n",
    "labels = [\"10%\", \"20%\", \"50%\", \"70%\", \"100%\"]\n",
    "colors = {'1': 'r', '2':'b', '3':'c', '4':'y'}\n",
    "scorer = 'AUC'\n",
    "\n",
    "\n",
    "# Y_axis = np.array([best_score_1, best_score_2, best_score_3, best_score_4])\n",
    "# \n",
    "X_axis = np.array(labels)\n",
    "Y_axis = [a for a,b in stat_auc]\n",
    "Y_std_dev = [b for a,b in stat_auc]\n",
    "\n",
    "ax.plot(X_axis, Y_axis, '-', color=colors['1'],label=\"%s \" % (\"AUC\"), linewidth=5)\n",
    "# ax.plot(X_axis, Y_axis_recall, '-', color=colors['2'],label=\"%s \" % (\"Recall\"), linewidth=5)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"IF_graph_v2_AUC_normal_data.png\", dpi=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
