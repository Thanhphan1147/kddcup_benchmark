{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'AUC': 'roc_auc',\n",
    "           'Precision': make_scorer(precision_score, pos_label=1), \n",
    "           'Recall': make_scorer(recall_score, pos_label=-1),\n",
    "           'F1': make_scorer(f1_score, average='weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SF anomaly rate is 4.5% / 73237\n"
     ]
    }
   ],
   "source": [
    "sf = datasets.fetch_kddcup99(subset='SF', percent10=True, random_state=0)\n",
    "dfsf = pd.DataFrame(sf.data, columns=sf_columns)\n",
    "dfsf[\"target\"]=sf.target\n",
    "anomaly_rate_sf = 1.0 - len(dfsf.loc[dfsf[\"target\"]==b'normal.'])/len(dfsf)\n",
    "print(f\"SF anomaly rate is {anomaly_rate_sf:.1%} / {len(dfsf)}\")\n",
    "\n",
    "dfsf['binary_target'] = [1 if x==b'normal.' else -1 for x in dfsf[\"target\"]]\n",
    "toDecodeSF = [\"service\", \"target\"]    \n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecodeSF:\n",
    "    dfsf[f] = list(map(byte_decoder, dfsf[f]))\n",
    "    dfsf[f] = leSF.fit_transform(dfsf[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for SVM fitting: 236.478\n"
     ]
    }
   ],
   "source": [
    "x_train_sf, x_test_sf, y_train_sf, y_test_sf = train_test_split(dfsf.drop([\"target\", 'binary_target'], axis=1), dfsf['binary_target'], test_size=0.25, random_state=1)\n",
    "gs_svm_1 = GridSearchCV(OneClassSVM(kernel=\"rbf\", gamma='scale'),\n",
    "                       param_grid={'nu': np.arange(0.045, 0.09, 0.005), 'kernel': [\"rbf\"], 'gamma': [\"scale\"]},\n",
    "                       scoring=scoring, refit='F1', cv=3)\n",
    "stime = time.time()\n",
    "gs_svm_1.fit(x_train_sf, y_train_sf)\n",
    "print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "results_svm_1 = gs_svm_1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for SVM fitting: 235.435\n"
     ]
    }
   ],
   "source": [
    "x_train_sf, x_test_sf, y_train_sf, y_test_sf = train_test_split(dfsf.drop([\"target\", 'binary_target'], axis=1), dfsf['binary_target'], test_size=0.25, random_state=2)\n",
    "gs_svm_2 = GridSearchCV(OneClassSVM(kernel=\"rbf\", gamma='scale'),\n",
    "                       param_grid={'nu': np.arange(0.045, 0.09, 0.005), 'kernel': [\"rbf\"], 'gamma': [\"auto\"]},\n",
    "                       scoring=scoring, refit='F1', cv=3)\n",
    "stime = time.time()\n",
    "gs_svm_2.fit(x_train_sf, y_train_sf)\n",
    "print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "results_svm_2 = gs_svm_2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for SVM fitting: 151.878\n"
     ]
    }
   ],
   "source": [
    "x_train_sf, x_test_sf, y_train_sf, y_test_sf = train_test_split(dfsf.drop([\"target\", 'binary_target'], axis=1), dfsf['binary_target'], test_size=0.25, random_state=3)\n",
    "gs_svm_3 = GridSearchCV(OneClassSVM(kernel=\"rbf\", gamma='scale'),\n",
    "                       param_grid={'nu': np.arange(0.045, 0.09, 0.005), 'kernel': [\"poly\"], 'gamma': [\"scale\"]},\n",
    "                       scoring=scoring, refit='F1', cv=3)\n",
    "stime = time.time()\n",
    "gs_svm_3.fit(x_train_sf, y_train_sf)\n",
    "print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "results_svm_3 = gs_svm_3.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-7ffd6abdfc23>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax = plt.axes()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.xlabel(\"configuration\")\n",
    "plt.ylabel(\"Score\")\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.set_ylim(0.500, 1.000)\n",
    "pad = 0.005\n",
    "\n",
    "colors = {'lof': 'r', 'if':'b', 'dbscan':'c', 'svm':'y'}\n",
    "scorer = 'F1'\n",
    "\n",
    "best_index = np.nonzero(results_svm_1['rank_test_%s' % scorer] == 1)[0][0]\n",
    "best_score_1 = results_svm_1['mean_test_%s' % scorer][best_index]\n",
    "best_param_1 = results_svm_1['params'][best_index]\n",
    "\n",
    "best_index = np.nonzero(results_svm_2['rank_test_%s' % scorer] == 1)[0][0]\n",
    "best_score_2 = results_svm_2['mean_test_%s' % scorer][best_index]\n",
    "best_param_2 = results_svm_2['params'][best_index]\n",
    "\n",
    "best_index = np.nonzero(results_svm_3['rank_test_%s' % scorer] == 1)[0][0]\n",
    "best_score_3 = results_svm_3['mean_test_%s' % scorer][best_index]\n",
    "best_param_3 = results_svm_3['params'][best_index]\n",
    "\n",
    "# best_index = np.nonzero(results_svm_sf_4['rank_test_%s' % scorer] == 1)[0][0]\n",
    "# best_score_4 = results_svm_sf_4['mean_test_%s' % scorer][best_index]\n",
    "# best_param_4 = results_svm_sf_4['params'][best_index]\n",
    "\n",
    "Y_axis = np.array([best_score_1, best_score_2, best_score_3])\n",
    "X_axis = np.array([f\"1-{best_param_1}\", f\"2-{best_param_2}\", f\"3-{best_param_3}\"])\n",
    "\n",
    "ax.plot(X_axis, Y_axis, '-', color=colors['if'],label=\"%s \" % (scorer))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"svm_figure.png\", dpi=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters: {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.05499999999999999}\n",
      "Time for SVM fitting: 17.972\n",
      "---0.9537729630584931\n",
      "---0.6876170499662896\n"
     ]
    }
   ],
   "source": [
    "x_train_sf, x_test_sf, y_train_sf, y_test_sf = train_test_split(dfsf.drop([\"target\", 'binary_target'], axis=1), dfsf['binary_target'], test_size=0.25, random_state=1)\n",
    "param = best_param_1\n",
    "print(f\"tuned parameters: {param}\")\n",
    "stime = time.time()\n",
    "y_pred = OneClassSVM(kernel=param['kernel'], gamma=param['gamma'], nu=param['nu']).fit(x_train_sf).predict(x_test_sf)\n",
    "print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "print(f\"---{f1_score(y_test_sf, y_pred)}\")\n",
    "y_pred = OneClassSVM().fit(x_train_sf).predict(x_test_sf)\n",
    "print(f\"---{f1_score(y_test_sf, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters: {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.049999999999999996}\n",
      "Time for SVM fitting: 17.934\n",
      "---0.9614221309136562\n",
      "---0.6882430151884492\n"
     ]
    }
   ],
   "source": [
    "x_train_sf, x_test_sf, y_train_sf, y_test_sf = train_test_split(dfsf.drop([\"target\", 'binary_target'], axis=1), dfsf['binary_target'], test_size=0.25, random_state=2)\n",
    "param = best_param_2\n",
    "print(f\"tuned parameters: {param}\")\n",
    "stime = time.time()\n",
    "y_pred = OneClassSVM(kernel=param['kernel'], gamma=param['gamma'], nu=param['nu']).fit(x_train_sf).predict(x_test_sf)\n",
    "print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "print(f\"---{f1_score(y_test_sf, y_pred)}\")\n",
    "y_pred = OneClassSVM().fit(x_train_sf).predict(x_test_sf)\n",
    "print(f\"---{f1_score(y_test_sf, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned parameters: {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.045}\n",
      "Time for SVM fitting: 10.396\n",
      "---0.9649308637027283\n",
      "---0.6826031219365056\n"
     ]
    }
   ],
   "source": [
    "x_train_sf, x_test_sf, y_train_sf, y_test_sf = train_test_split(dfsf.drop([\"target\", 'binary_target'], axis=1), dfsf['binary_target'], test_size=0.25, random_state=3)\n",
    "param = best_param_3\n",
    "print(f\"tuned parameters: {param}\")\n",
    "stime = time.time()\n",
    "y_pred = OneClassSVM(kernel=param['kernel'], gamma=param['gamma'], nu=param['nu']).fit(x_train_sf).predict(x_test_sf)\n",
    "print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "print(f\"---{f1_score(y_test_sf, y_pred)}\")\n",
    "y_pred = OneClassSVM().fit(x_train_sf).predict(x_test_sf)\n",
    "print(f\"---{f1_score(y_test_sf, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.6306502 , 5.11502067, 5.20066182, 6.09889436, 6.590343  ,\n",
       "        7.07237093, 7.92040881, 8.02568126, 8.48540958]),\n",
       " 'std_fit_time': array([0.12191405, 0.22227681, 0.1870071 , 0.0489273 , 0.37039363,\n",
       "        0.08951269, 0.18168845, 0.25793864, 0.13073613]),\n",
       " 'mean_score_time': array([1.18210196, 1.27119819, 1.39359395, 1.61965378, 1.68481922,\n",
       "        1.7856245 , 2.04110018, 2.14700691, 2.24029295]),\n",
       " 'std_score_time': array([0.026891  , 0.0758545 , 0.06915264, 0.08317724, 0.09403544,\n",
       "        0.06901534, 0.16078243, 0.02095035, 0.08943702]),\n",
       " 'param_gamma': masked_array(data=['scale', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'scale'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_nu': masked_array(data=[0.045, 0.049999999999999996, 0.05499999999999999,\n",
       "                    0.05999999999999999, 0.06499999999999999,\n",
       "                    0.06999999999999998, 0.07499999999999998,\n",
       "                    0.07999999999999999, 0.08499999999999998],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.045},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.049999999999999996},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.05499999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.05999999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.06499999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.06999999999999998},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.07499999999999998},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.07999999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'rbf', 'nu': 0.08499999999999998}],\n",
       " 'split0_test_AUC': array([0.92579599, 0.92346443, 0.92180005, 0.91931429, 0.91735684,\n",
       "        0.92229029, 0.92383022, 0.92225048, 0.92108994]),\n",
       " 'split1_test_AUC': array([0.92547718, 0.92143388, 0.91888692, 0.91738411, 0.91456231,\n",
       "        0.92009938, 0.92250211, 0.92199016, 0.92068339]),\n",
       " 'split2_test_AUC': array([0.92849908, 0.92452615, 0.92195426, 0.91776253, 0.91723117,\n",
       "        0.91524081, 0.9230399 , 0.92148774, 0.92002164]),\n",
       " 'mean_test_AUC': array([0.92659075, 0.92314148, 0.92088041, 0.91815364, 0.91638344,\n",
       "        0.91921016, 0.92312408, 0.92190946, 0.92059832]),\n",
       " 'std_test_AUC': array([0.00135566, 0.0012829 , 0.00141102, 0.00083512, 0.00128875,\n",
       "        0.00294582, 0.00054546, 0.00031657, 0.00044026]),\n",
       " 'rank_test_AUC': array([1, 2, 5, 8, 9, 7, 3, 4, 6], dtype=int32),\n",
       " 'split0_test_Precision': array([0.9577096 , 0.95750643, 0.9851725 , 0.95724082, 0.98574751,\n",
       "        0.98567747, 0.98560848, 0.98561934, 0.99407199]),\n",
       " 'split1_test_Precision': array([0.98534001, 0.98533412, 0.98527491, 0.98521698, 0.95441612,\n",
       "        0.95478119, 0.9855746 , 0.95458275, 0.95443857]),\n",
       " 'split2_test_Precision': array([0.98578561, 0.95554032, 0.98576006, 0.95500347, 0.95495913,\n",
       "        0.95515512, 0.95501933, 0.96285985, 0.98607395]),\n",
       " 'mean_test_Precision': array([0.97627841, 0.96612696, 0.98540249, 0.96582042, 0.96504092,\n",
       "        0.96520459, 0.9754008 , 0.96768731, 0.97819484]),\n",
       " 'std_test_Precision': array([0.01313139, 0.01360521, 0.00025627, 0.01374581, 0.01464345,\n",
       "        0.01447732, 0.01441189, 0.01312239, 0.01711262]),\n",
       " 'rank_test_Precision': array([3, 6, 1, 7, 9, 8, 4, 5, 2], dtype=int32),\n",
       " 'split0_test_Recall': array([0.0838471 , 0.0838471 , 0.69050555, 0.08508015, 0.7053021 ,\n",
       "        0.7053021 , 0.7053021 , 0.70653514, 0.88039457]),\n",
       " 'split1_test_Recall': array([0.70671378, 0.70789164, 0.70789164, 0.70789164, 0.0753828 ,\n",
       "        0.08598351, 0.71849234, 0.08716137, 0.08716137]),\n",
       " 'split2_test_Recall': array([0.71428571, 0.08146399, 0.71664699, 0.08264463, 0.08264463,\n",
       "        0.09208973, 0.09327037, 0.25974026, 0.729634  ]),\n",
       " 'mean_test_Recall': array([0.50161553, 0.29106758, 0.70501473, 0.29187214, 0.28777651,\n",
       "        0.29445844, 0.50568827, 0.35114559, 0.56572998]),\n",
       " 'std_test_Recall': array([0.29542306, 0.29474073, 0.01086435, 0.29417189, 0.29525006,\n",
       "        0.29052103, 0.29167321, 0.26098808, 0.3439507 ]),\n",
       " 'rank_test_Recall': array([4, 8, 1, 7, 9, 6, 3, 5, 2], dtype=int32),\n",
       " 'split0_test_F1': array([0.92102492, 0.91843797, 0.94857747, 0.91449282, 0.94359576,\n",
       "        0.94049611, 0.93750675, 0.93548595, 0.94113754]),\n",
       " 'split1_test_F1': array([0.95229865, 0.94940133, 0.94672535, 0.94416042, 0.90695123,\n",
       "        0.90603403, 0.93707787, 0.90315392, 0.90149338]),\n",
       " 'split2_test_F1': array([0.95453595, 0.91615296, 0.94789676, 0.90916626, 0.90864507,\n",
       "        0.90629754, 0.90411655, 0.91175931, 0.93330407]),\n",
       " 'mean_test_F1': array([0.94261984, 0.92799742, 0.94773319, 0.9226065 , 0.91973069,\n",
       "        0.91760923, 0.92623372, 0.91679973, 0.92531167]),\n",
       " 'std_test_F1': array([0.01529721, 0.01516357, 0.00076492, 0.01539527, 0.01688932,\n",
       "        0.01618383, 0.01564018, 0.01367222, 0.017143  ]),\n",
       " 'rank_test_F1': array([2, 3, 1, 6, 7, 8, 4, 9, 5], dtype=int32)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.59648132, 5.10838811, 5.67701538, 5.86032565, 6.59282756,\n",
       "        6.96126294, 7.53370476, 8.07009157, 8.47928754]),\n",
       " 'std_fit_time': array([0.10980449, 0.2139683 , 0.35016906, 0.29160383, 0.1102881 ,\n",
       "        0.16288381, 0.11754453, 0.27698292, 0.16672213]),\n",
       " 'mean_score_time': array([1.31376219, 1.46560884, 1.4736646 , 1.62724376, 1.6411465 ,\n",
       "        1.69198505, 1.80740054, 2.07927044, 2.43644476]),\n",
       " 'std_score_time': array([0.16308041, 0.09698267, 0.04602325, 0.24108478, 0.10895652,\n",
       "        0.04540636, 0.09736413, 0.13887866, 0.23257621]),\n",
       " 'param_gamma': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
       "                    'rbf'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_nu': masked_array(data=[0.045, 0.049999999999999996, 0.05499999999999999,\n",
       "                    0.05999999999999999, 0.06499999999999999,\n",
       "                    0.06999999999999998, 0.07499999999999998,\n",
       "                    0.07999999999999999, 0.08499999999999998],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.045},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.049999999999999996},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.05499999999999999},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.05999999999999999},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.06499999999999999},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.06999999999999998},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.07499999999999998},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.07999999999999999},\n",
       "  {'gamma': 'auto', 'kernel': 'rbf', 'nu': 0.08499999999999998}],\n",
       " 'split0_test_AUC': array([0.9630625 , 0.96156136, 0.95680919, 0.95422058, 0.94926026,\n",
       "        0.94602903, 0.94011357, 0.93782381, 0.93277049]),\n",
       " 'split1_test_AUC': array([0.96219666, 0.95655061, 0.95611029, 0.95118483, 0.94778386,\n",
       "        0.94669071, 0.94093935, 0.93564614, 0.93330858]),\n",
       " 'split2_test_AUC': array([0.95774768, 0.95812353, 0.95559361, 0.95153636, 0.95037847,\n",
       "        0.94285125, 0.94028283, 0.93531165, 0.93023574]),\n",
       " 'mean_test_AUC': array([0.96100228, 0.95874517, 0.95617103, 0.95231392, 0.94914086,\n",
       "        0.94519033, 0.94044525, 0.93626054, 0.93210494]),\n",
       " 'std_test_AUC': array([0.00232834, 0.00209232, 0.00049811, 0.00135583, 0.0010626 ,\n",
       "        0.0016759 , 0.00035615, 0.0011138 , 0.00133985]),\n",
       " 'rank_test_AUC': array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " 'split0_test_Precision': array([0.95859909, 0.99050501, 0.95915542, 0.9593336 , 0.99119421,\n",
       "        0.95898095, 0.95875133, 0.99143993, 0.99145036]),\n",
       " 'split1_test_Precision': array([0.96720368, 0.98976816, 0.99006189, 0.95938675, 0.99045504,\n",
       "        0.99091183, 0.99086012, 0.95950652, 0.99091297]),\n",
       " 'split2_test_Precision': array([0.97016395, 0.97065489, 0.99059971, 0.96408615, 0.96438149,\n",
       "        0.96418279, 0.99125736, 0.96389613, 0.99116293]),\n",
       " 'mean_test_Precision': array([0.96532224, 0.98364269, 0.97993901, 0.9609355 , 0.98201024,\n",
       "        0.97135852, 0.9802896 , 0.97161419, 0.99117542]),\n",
       " 'std_test_Precision': array([0.00490519, 0.00918869, 0.01469786, 0.00222795, 0.01246907,\n",
       "        0.01398841, 0.01523072, 0.01413299, 0.00021957]),\n",
       " 'rank_test_Precision': array([8, 2, 5, 9, 3, 7, 4, 6, 1], dtype=int32),\n",
       " 'split0_test_Recall': array([0.1662844 , 0.81651376, 0.18807339, 0.19380734, 0.83256881,\n",
       "        0.19495413, 0.1983945 , 0.83944954, 0.84059633]),\n",
       " 'split1_test_Recall': array([0.30572473, 0.78928136, 0.79658952, 0.14494519, 0.80633374,\n",
       "        0.81607795, 0.81607795, 0.16443362, 0.81851401]),\n",
       " 'split2_test_Recall': array([0.34311224, 0.35586735, 0.79846939, 0.2130102 , 0.22066327,\n",
       "        0.22321429, 0.81632653, 0.22321429, 0.81632653]),\n",
       " 'mean_test_Recall': array([0.27170712, 0.65388749, 0.59437744, 0.18392091, 0.61985527,\n",
       "        0.41141546, 0.61026633, 0.40903248, 0.82514562]),\n",
       " 'std_test_Recall': array([0.0760917 , 0.21102513, 0.28730137, 0.0286533 , 0.2824745 ,\n",
       "        0.28637209, 0.29123738, 0.3052954 , 0.01096174]),\n",
       " 'rank_test_Recall': array([8, 2, 5, 9, 3, 6, 4, 7, 1], dtype=int32),\n",
       " 'split0_test_F1': array([0.92467319, 0.95631594, 0.91922577, 0.91819623, 0.94679216,\n",
       "        0.91260377, 0.90742293, 0.9386603 , 0.93507849]),\n",
       " 'split1_test_F1': array([0.93383456, 0.95559822, 0.95201963, 0.91680136, 0.94706287,\n",
       "        0.94614081, 0.94254902, 0.90745104, 0.9380567 ]),\n",
       " 'split2_test_F1': array([0.93414854, 0.93332088, 0.95184247, 0.92110623, 0.92085192,\n",
       "        0.91611443, 0.94029861, 0.91173287, 0.93380589]),\n",
       " 'mean_test_F1': array([0.93088543, 0.94841168, 0.94102929, 0.91870127, 0.93823565,\n",
       "        0.924953  , 0.93009019, 0.9192814 , 0.93564702]),\n",
       " 'std_test_F1': array([0.00439459, 0.01067483, 0.01541759, 0.00179337, 0.01229265,\n",
       "        0.01505044, 0.01605448, 0.013814  , 0.00178134]),\n",
       " 'rank_test_F1': array([5, 1, 2, 9, 3, 7, 6, 8, 4], dtype=int32)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.84116864, 3.43034482, 3.33127761, 4.02551603, 4.21886738,\n",
       "        4.59731992, 4.5762527 , 5.40818008, 6.09977253]),\n",
       " 'std_fit_time': array([0.08761936, 0.01190946, 0.24330537, 0.05426051, 0.30080873,\n",
       "        0.15267119, 0.07230954, 0.26394836, 0.06843346]),\n",
       " 'mean_score_time': array([0.79572002, 0.90075803, 0.88710984, 1.06110128, 1.08314888,\n",
       "        1.18822233, 1.19186632, 1.30830622, 1.42885693]),\n",
       " 'std_score_time': array([0.07283431, 0.01779197, 0.01052747, 0.0812991 , 0.03019581,\n",
       "        0.0330685 , 0.0280622 , 0.05398656, 0.02785504]),\n",
       " 'param_gamma': masked_array(data=['scale', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'scale'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['poly', 'poly', 'poly', 'poly', 'poly', 'poly', 'poly',\n",
       "                    'poly', 'poly'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_nu': masked_array(data=[0.045, 0.049999999999999996, 0.05499999999999999,\n",
       "                    0.05999999999999999, 0.06499999999999999,\n",
       "                    0.06999999999999998, 0.07499999999999998,\n",
       "                    0.07999999999999999, 0.08499999999999998],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'gamma': 'scale', 'kernel': 'poly', 'nu': 0.045},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.049999999999999996},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.05499999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.05999999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.06499999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.06999999999999998},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.07499999999999998},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.07999999999999999},\n",
       "  {'gamma': 'scale', 'kernel': 'poly', 'nu': 0.08499999999999998}],\n",
       " 'split0_test_AUC': array([0.38608301, 0.38661564, 0.38722921, 0.3875308 , 0.38756166,\n",
       "        0.38763481, 0.38758586, 0.38766189, 0.38755906]),\n",
       " 'split1_test_AUC': array([0.39533693, 0.39576189, 0.39579965, 0.39594251, 0.3960117 ,\n",
       "        0.3960442 , 0.39592803, 0.39581391, 0.39577978]),\n",
       " 'split2_test_AUC': array([0.3878268 , 0.38846679, 0.38898719, 0.38935862, 0.38935213,\n",
       "        0.3892393 , 0.38918015, 0.38917933, 0.38902626]),\n",
       " 'mean_test_AUC': array([0.38974891, 0.39028144, 0.39067201, 0.39094398, 0.39097516,\n",
       "        0.39097277, 0.39089801, 0.39088504, 0.39078837]),\n",
       " 'std_test_AUC': array([0.00401494, 0.00394827, 0.00369613, 0.00361241, 0.00363561,\n",
       "        0.00364538, 0.00361582, 0.00353987, 0.00357992]),\n",
       " 'rank_test_AUC': array([9, 8, 7, 3, 1, 2, 4, 5, 6], dtype=int32),\n",
       " 'split0_test_Precision': array([0.9655764 , 0.96650745, 0.96636174, 0.96618554, 0.96616123,\n",
       "        0.96628154, 0.96611374, 0.96590774, 0.96568862]),\n",
       " 'split1_test_Precision': array([0.96702353, 0.96774935, 0.9676637 , 0.96752305, 0.96741855,\n",
       "        0.96723521, 0.96710991, 0.96691525, 0.9667956 ]),\n",
       " 'split2_test_Precision': array([0.96545215, 0.96575697, 0.96554515, 0.96536696, 0.96563815,\n",
       "        0.96554153, 0.96535033, 0.9651632 , 0.96497822]),\n",
       " 'mean_test_Precision': array([0.96601736, 0.96667126, 0.96652353, 0.96635852, 0.96640598,\n",
       "        0.96635276, 0.96619133, 0.9659954 , 0.96582081]),\n",
       " 'std_test_Precision': array([0.00071328, 0.00082159, 0.00087243, 0.00088868, 0.00074716,\n",
       "        0.00069327, 0.00072044, 0.00071795, 0.0007478 ]),\n",
       " 'rank_test_Precision': array([7, 1, 2, 4, 3, 5, 6, 8, 9], dtype=int32),\n",
       " 'split0_test_Recall': array([0.26134969, 0.28588957, 0.28711656, 0.28711656, 0.29079755,\n",
       "        0.29815951, 0.29815951, 0.29815951, 0.29693252]),\n",
       " 'split1_test_Recall': array([0.28447205, 0.30310559, 0.30434783, 0.30434783, 0.30559006,\n",
       "        0.30559006, 0.30559006, 0.30559006, 0.3068323 ]),\n",
       " 'split2_test_Recall': array([0.27923628, 0.28878282, 0.28878282, 0.28878282, 0.29832936,\n",
       "        0.29952267, 0.29952267, 0.29952267, 0.29952267]),\n",
       " 'mean_test_Recall': array([0.27501934, 0.29259266, 0.29341574, 0.29341574, 0.29823899,\n",
       "        0.30109075, 0.30109075, 0.30109075, 0.30109583]),\n",
       " 'std_test_Recall': array([0.00989942, 0.00752702, 0.00776003, 0.00776003, 0.00603936,\n",
       "        0.0032298 , 0.0032298 , 0.0032298 , 0.00419186]),\n",
       " 'rank_test_Recall': array([9, 8, 6, 6, 5, 2, 2, 2, 1], dtype=int32),\n",
       " 'split0_test_F1': array([0.9340278 , 0.9322599 , 0.92869799, 0.92559804, 0.92245446,\n",
       "        0.91908357, 0.91626029, 0.91285199, 0.91016479]),\n",
       " 'split1_test_F1': array([0.93575436, 0.93479195, 0.9321721 , 0.9295503 , 0.92667802,\n",
       "        0.92339366, 0.92118772, 0.9178171 , 0.91486356]),\n",
       " 'split2_test_F1': array([0.93445261, 0.93252722, 0.92874879, 0.92565358, 0.92312139,\n",
       "        0.92058617, 0.9173944 , 0.91432641, 0.91134263]),\n",
       " 'mean_test_F1': array([0.93474492, 0.93319302, 0.92987296, 0.92693398, 0.92408462,\n",
       "        0.92102113, 0.91828081, 0.9149985 , 0.91212366]),\n",
       " 'std_test_F1': array([0.00073454, 0.00113587, 0.00162587, 0.00185016, 0.00185391,\n",
       "        0.00178626, 0.002107  , 0.00208196, 0.00199618]),\n",
       " 'rank_test_F1': array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_svm_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_svm(contamination, kernel, gamma, random_state, silent=True):\n",
    "    highest_score = 0\n",
    "    highest_score_c = 0\n",
    "    for c in contamination:\n",
    "        s = datetime.datetime.now()\n",
    "        y_pred = OneClassSVM(kernel = kernel, gamma = gamma, nu = c).fit(x_train).predict(x_test)\n",
    "        t = datetime.datetime.now() - s\n",
    "        p, r, f, s = map(lambda x: x[0], precision_recall_fscore_support(y_test, y_pred, pos_label = -1))\n",
    "        # p = tp / (tp + fp)\n",
    "        a = roc_auc_score(y_test, y_pred)\n",
    "        if f > highest_score: highest_score = f; highest_score_c = c\n",
    "        \n",
    "        yp = np.array(y_pred)\n",
    "        yt = np.array(y_test)\n",
    "        \n",
    "        prediction = yp[np.where(yt == -1)]\n",
    "\n",
    "        tp = len(yp[np.where(prediction == -1)])\n",
    "        \n",
    "        fp = tp / p - tp\n",
    "        # predicted true\n",
    "        positives = yp[np.where(yp == -1)]\n",
    "        if not silent:\n",
    "            print(f\"Finished trainning in {t} seconds\")\n",
    "            print(f\"contamination: {c} \\t tp: {tp}/support: {s}/predicted: {len(positives)} -> fp = {len(positives) - tp}\")\n",
    "            print(f\"AUC : {a:.1%} \\t precision: {p:.3} \\t recall: {r:.3} \\t f1: {f}\")\n",
    "            print(\"--------------------\")\n",
    "    return (highest_score_c, y_pred, f, len(positives) - tp, tp, p, r, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"target\"\n",
    "sf = datasets.fetch_kddcup99(subset='SF', percent10=True)\n",
    "dfSF=pd.DataFrame(sf.data, \n",
    "                  columns=[\"duration\", \"service\", \"src_bytes\", \"dst_bytes\"])\n",
    "assert len(dfSF)>0, \"SF dataset no loaded.\"\n",
    "\n",
    "dfSF[target]=sf.target\n",
    "anomaly_rateSF = 1.0 - len(dfSF.loc[dfSF[target]==b'normal.'])/len(dfSF)\n",
    "\n",
    "print(\"SF Anomaly Rate is:\"+\"{:.1%}\".format(anomaly_rateSF))\n",
    "\n",
    "dfSF['binary_target'] = [1 if x==b'normal.' else -1 for x in dfSF[target]]\n",
    "\n",
    "toDecode = toDecodeSF\n",
    "leSF = preprocessing.LabelEncoder()\n",
    "for f in toDecode:\n",
    "    dfSF[f] = list(map(byte_decoder, dfSF[f]))\n",
    "    dfSF[f] = leSF.fit_transform(dfSF[f])\n",
    "\n",
    "Y_axis_f1 = []\n",
    "Y_axis_recall = []\n",
    "best_param = []\n",
    "\n",
    "rs = 1\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfSF.drop([\"target\", \"binary_target\"], axis=1), dfSF['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "contaminations = np.arange(0.05, 0.4, 0.02)\n",
    "kernel = \"rbf\"\n",
    "gamma = \"scale\"\n",
    "\n",
    "stime = time.time()\n",
    "cmax, y_pred, f, fp, tp, p, r, t = cross_validation_svm(contaminations, max_samples, n_estimators, rs, silent=False)\n",
    "print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "Y_axis_f1.append(f)\n",
    "Y_axis_recall.append(r)\n",
    "best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "\n",
    "rs = 2\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfSF.drop([\"target\", \"binary_target\"], axis=1), dfSF['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "contaminations = np.arange(0.05, 0.4, 0.02)\n",
    "kernel = \"rbf\"\n",
    "gamma = \"auto\"\n",
    "\n",
    "stime = time.time()\n",
    "cmax, y_pred, f, fp, tp, p, r, t = cross_validation_svm(contaminations, max_samples, n_estimators, rs, silent=True)\n",
    "print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "Y_axis_f1.append(f)\n",
    "Y_axis_recall.append(r)\n",
    "best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "\n",
    "rs = 3\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfSF.drop([\"target\", \"binary_target\"], axis=1), dfSF['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "contaminations = np.arange(0.05, 0.4, 0.02)\n",
    "kernel = \"poly\"\n",
    "gamma = \"scale\"\n",
    "\n",
    "stime = time.time()\n",
    "cmax, y_pred, f, fp, tp, p, r, t = cross_validation_svm(contaminations, max_samples, n_estimators, rs, silent=True)\n",
    "print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "Y_axis_f1.append(f)\n",
    "Y_axis_recall.append(r)\n",
    "best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "\n",
    "rs = 4\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfSF.drop([\"target\", \"binary_target\"], axis=1), dfSF['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "contaminations = np.arange(0.05, 0.4, 0.02)\n",
    "kernel = \"linear\"\n",
    "gamma = \"scale\"\n",
    "\n",
    "stime = time.time()\n",
    "cmax, y_pred, f, fp, tp, p, r, t = cross_validation_svm(contaminations, max_samples, n_estimators, rs, silent=True)\n",
    "print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "Y_axis_f1.append(f)\n",
    "Y_axis_recall.append(r)\n",
    "best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "\n",
    "rs = 5\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfSF.drop([\"target\", \"binary_target\"], axis=1), dfSF['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "contaminations = np.arange(0.05, 0.4, 0.02)\n",
    "max_samples = 0.5\n",
    "n_estimators = 500\n",
    "\n",
    "stime = time.time()\n",
    "cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=True)\n",
    "print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "Y_axis_f1.append(f)\n",
    "Y_axis_recall.append(r)\n",
    "best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "\n",
    "rs = 6\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfSF.drop([\"target\", \"binary_target\"], axis=1), dfSF['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "contaminations = np.arange(0.05, 0.4, 0.02)\n",
    "max_samples = 0.1\n",
    "n_estimators = 100\n",
    "\n",
    "stime = time.time()\n",
    "cmax, y_pred, f, fp, tp, p, r, t = cross_validation(contaminations, max_samples, n_estimators, rs, silent=True)\n",
    "print(\"Time for IF fitting: %.3f\" % (time.time() - stime))\n",
    "Y_axis_f1.append(f)\n",
    "Y_axis_recall.append(r)\n",
    "best_param.append((rs, cmax, max_samples, n_estimators))\n",
    "\n",
    "plt.figure(figsize=(40,20))\n",
    "plt.title('f1 score after parameter tuning')\n",
    "plt.xlabel(\"configuration\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.rc('font', size=30)\n",
    "ax = plt.axes()\n",
    "# ax.set_ylim(0.99, 0.992)\n",
    "pad = 0.005\n",
    "\n",
    "labels = [f\"{i}-{p}\" for i,p in enumerate(best_param)]\n",
    "colors = {'1': 'r', '2':'b', '3':'c', '4':'y'}\n",
    "scorer = 'F1'\n",
    "\n",
    "\n",
    "# Y_axis = np.array([best_score_1, best_score_2, best_score_3, best_score_4])\n",
    "# \n",
    "X_axis = np.array(labels)\n",
    "\n",
    "ax.plot(X_axis, Y_axis_f1, '-', color=colors['1'],label=\"%s \" % (\"F1\"), linewidth=5)\n",
    "# ax.plot(X_axis, Y_axis_recall, '-', color=colors['2'],label=\"%s \" % (\"Recall\"), linewidth=5)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"IF_graph_v2.png\", dpi=100)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Comparison against default values\n",
    "\n",
    "f1_tuned = []\n",
    "auc_tuned = []\n",
    "r_tuned = []\n",
    "f1_not_tuned = []\n",
    "\n",
    "for rs, c, ms, ne in best_param:\n",
    "    print(f\"---{[rs, c, ms, ne]}\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dfsf_normed, dfsf_frac['binary_target'], test_size=0.25, random_state=rs)\n",
    "\n",
    "    stime = time.time()\n",
    "    y_pred = OneClassSVM(kernel=\"rbf\", gamma='scale', nu = c).fit(x_train).predict(x_test)\n",
    "    print(\"Time for SVM fitting: %.3f\" % (time.time() - stime))\n",
    "    f = f1_score(y_test, y_pred)\n",
    "    print(f\"---{f}\")\n",
    "    f1_tuned.append(f)\n",
    "    a = roc_auc_score(y_test, y_pred)\n",
    "    print(f\"---{a}\")\n",
    "    auc_tuned.append(a)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    print(f\"---{r}\")\n",
    "    r_tuned.append(r)\n",
    "    y_pred = IsolationForest(random_state= rs, n_jobs = -1).fit.(x_train).predict(x_test)\n",
    "    f = f1_score(y_test, y_pred)\n",
    "    print(f\"---{f}\")\n",
    "    f1_not_tuned.append(f)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30,20))\n",
    "plt.rc('font', size=30)\n",
    "\n",
    "width = 1\n",
    "labels = [f\"{rs}-c: {c:.2}\\n ms: {ms:.2}\\n ne: {ne}\" for rs, c, ms, ne in best_param]\n",
    "ax.set_xticks([i*5 + width/2 for i in range(len(f1_tuned))])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel('f1-score')\n",
    "\n",
    "ax.set_title('f1 score before and after parameter tuning using cross validation search')\n",
    "\n",
    "ax.bar([i*5 for i in range(len(f1_tuned))], f1_tuned, width=width)\n",
    "ax.bar([i*5 + width for i in range(len(f1_not_tuned))], f1_not_tuned, width=width)\n",
    "fig.tight_layout()\n",
    "ax.legend(['f1 score tuned', 'f1 score not tuned'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
